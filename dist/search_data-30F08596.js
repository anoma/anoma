searchData={"items":[{"type":"module","title":"Anoma","doc":"Documentation for `Anoma`.","ref":"Anoma.html"},{"type":"function","title":"Anoma.hello/0","doc":"Hello world.","ref":"Anoma.html#hello/0"},{"type":"function","title":"Examples - Anoma.hello/0","doc":"iex> Anoma.hello()\n    :world","ref":"Anoma.html#hello/0-examples"},{"type":"function","title":"Anoma.start/2","doc":"","ref":"Anoma.html#start/2"},{"type":"function","title":"Anoma.start_logic/1","doc":"I start the Anoma application.\n\nGiven environment `env` I search for a configuration file\n`anoma_env.toml` in the appropriate configuration direction. If the\nconfiguration refers to a dumped session, we launch it directly.\nOtherwise we launch it with minimal settings.\n\nIf no configuration was found, I provide basic setup for a new Node and\nstart it under supervision.","ref":"Anoma.html#start_logic/1"},{"type":"module","title":"Anoma.Block","doc":"I represent a block that will be stored and gossiped around the\nnetwork.","ref":"Anoma.Block.html"},{"type":"module","title":"Fields - Anoma.Block","doc":"- `:id` - Identification number derived from the serialization of my:\n      + digest(block)\n      + round\n      + pub_key\n   - `:block` - The block I contain\n   - `:round` - The round I come from\n   - `:pub_key` - Public key\n   - `:signature` - Id signed with the private_key related to my public_key","ref":"Anoma.Block.html#module-fields"},{"type":"function","title":"Anoma.Block.create/3","doc":"I create a block, if a private key is passed in my second parameter,\nthen I also contain a signature of myself.\n\nThe signature (if created), represents that my `:pub_key` signed my\n`:id`. This can be cryptography verified with `Serializer.verify`","ref":"Anoma.Block.html#create/3"},{"type":"function","title":"Parameters - Anoma.Block.create/3","doc":"- `block` - the base block that I am structured around\n  - `key` - Either a public key or a public private key paring\n  - `round` - The round that I represent","ref":"Anoma.Block.html#create/3-parameters"},{"type":"function","title":"Anoma.Block.create_table/0","doc":"I create a `:mnesia` table for `Anoma.Block`. This table is backed\nby rocksdb, and thus persists across IEX sessions.\n\nI will only ever needed to be called once upon Configuration start,\n`Anoma.Mnesia.init/0` will likely set me up as is.","ref":"Anoma.Block.html#create_table/0"},{"type":"function","title":"Anoma.Block.create_table/2","doc":"I am like `create_table/0`, however I am given a special\ntable_key. This overrides the default table key of `Anoma.Block`.\n\nI am useful when trying to spawn many solvers/validators/etc, who\nall want their own tables.","ref":"Anoma.Block.html#create_table/2"},{"type":"function","title":"Parameters - Anoma.Block.create_table/2","doc":"- `table_key` - the name of the table\n  - `rocks?` - should we persist as a rocksdb table?","ref":"Anoma.Block.html#create_table/2-parameters"},{"type":"function","title":"Anoma.Block.decode/1","doc":"","ref":"Anoma.Block.html#decode/1"},{"type":"function","title":"Anoma.Block.encode/1","doc":"","ref":"Anoma.Block.html#encode/1"},{"type":"function","title":"Anoma.Block.encode/2","doc":"","ref":"Anoma.Block.html#encode/2"},{"type":"function","title":"Anoma.Block.sign/2","doc":"I sign my id given a private key. I do no validation checking if the\n`id` is derived properly.","ref":"Anoma.Block.html#sign/2"},{"type":"type","title":"Anoma.Block.private_key/0","doc":"","ref":"Anoma.Block.html#t:private_key/0"},{"type":"type","title":"Anoma.Block.public_key/0","doc":"","ref":"Anoma.Block.html#t:public_key/0"},{"type":"type","title":"Anoma.Block.t/0","doc":"","ref":"Anoma.Block.html#t:t/0"},{"type":"module","title":"Anoma.Block.Base","doc":"I represent the Base part of a block.","ref":"Anoma.Block.Base.html"},{"type":"module","title":"Type - Anoma.Block.Base","doc":"- `:transactions` - A list of transactions.","ref":"Anoma.Block.Base.html#module-type"},{"type":"function","title":"Anoma.Block.Base.default/0","doc":"","ref":"Anoma.Block.Base.html#default/0"},{"type":"function","title":"Anoma.Block.Base.digest/1","doc":"","ref":"Anoma.Block.Base.html#digest/1"},{"type":"function","title":"Anoma.Block.Base.new/1","doc":"","ref":"Anoma.Block.Base.html#new/1"},{"type":"type","title":"Anoma.Block.Base.t/0","doc":"","ref":"Anoma.Block.Base.html#t:t/0"},{"type":"module","title":"Anoma.Cli","doc":"","ref":"Anoma.Cli.html"},{"type":"function","title":"Anoma.Cli.argument_parser/0","doc":"","ref":"Anoma.Cli.html#argument_parser/0"},{"type":"function","title":"Anoma.Cli.cli_arguments_to_start_arguments/1","doc":"Provides taking CLI argument parsing to arguments used by the\napplication","ref":"Anoma.Cli.html#cli_arguments_to_start_arguments/1"},{"type":"function","title":"Anoma.Cli.client_commands/0","doc":"","ref":"Anoma.Cli.html#client_commands/0"},{"type":"function","title":"Anoma.Cli.run_client_command/3","doc":"","ref":"Anoma.Cli.html#run_client_command/3"},{"type":"function","title":"Anoma.Cli.run_commands/2","doc":"Runs the given client command","ref":"Anoma.Cli.html#run_commands/2"},{"type":"function","title":"Anoma.Cli.server_anoma_node/0","doc":"","ref":"Anoma.Cli.html#server_anoma_node/0"},{"type":"function","title":"Anoma.Cli.start_application/1","doc":"","ref":"Anoma.Cli.html#start_application/1"},{"type":"function","title":"Anoma.Cli.top_level_help/0","doc":"","ref":"Anoma.Cli.html#top_level_help/0"},{"type":"type","title":"Anoma.Cli.client_commands/0","doc":"","ref":"Anoma.Cli.html#t:client_commands/0"},{"type":"type","title":"Anoma.Cli.client_info/0","doc":"","ref":"Anoma.Cli.html#t:client_info/0"},{"type":"module","title":"Anoma.Cli.Client","doc":"I am a small engine that runs in a CLI's node and connects to and talks to\nthe local administration engine on another node running on the same system.\n\nI have to be a dedicated engine because of the protocol design: every message\nmust originate in a particular engine with its own id. (Proposed specs\nchanges may obviate this in the future.)","ref":"Anoma.Cli.Client.html"},{"type":"function","title":"Anoma.Cli.Client.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Cli.Client.html#child_spec/1"},{"type":"function","title":"Anoma.Cli.Client.error_code/1","doc":"I get the error code from the ran client function","ref":"Anoma.Cli.Client.html#error_code/1"},{"type":"function","title":"Anoma.Cli.Client.handle_continue/2","doc":"","ref":"Anoma.Cli.Client.html#handle_continue/2"},{"type":"function","title":"Anoma.Cli.Client.init/1","doc":"","ref":"Anoma.Cli.Client.html#init/1"},{"type":"function","title":"Anoma.Cli.Client.return_value/1","doc":"I get the error code from the ran client function","ref":"Anoma.Cli.Client.html#return_value/1"},{"type":"module","title":"Anoma.Configuration","doc":"I am a configuration module. I read the provided TOML configuration file\nand feed the appropriate info for Node launching\n\nThe codebase has a corresponding file that can inform the user of the\nformat I expect.","ref":"Anoma.Configuration.html"},{"type":"module","title":"Public API - Anoma.Configuration","doc":"- `configuration/0`\n- `configuration/1`\n- `read_configuration/1`\n- `node_settings/1`\n- `save/1`\n- `save/2`\n- `locate_dump_file/1`\n- `launch_min/1`\n- `launch_min/2`","ref":"Anoma.Configuration.html#module-public-api"},{"type":"function","title":"Anoma.Configuration.configuration/1","doc":"","ref":"Anoma.Configuration.html#configuration/1"},{"type":"function","title":"Anoma.Configuration.configuration_format/0","doc":"","ref":"Anoma.Configuration.html#configuration_format/0"},{"type":"function","title":"Anoma.Configuration.default_configuration_location/1","doc":"","ref":"Anoma.Configuration.html#default_configuration_location/1"},{"type":"function","title":"Anoma.Configuration.default_data_location/1","doc":"","ref":"Anoma.Configuration.html#default_data_location/1"},{"type":"function","title":"Anoma.Configuration.is_pinger/1","doc":"","ref":"Anoma.Configuration.html#is_pinger/1"},{"type":"function","title":"Anoma.Configuration.launch_min/2","doc":"Given a parsed map with minimal node startup info I launch the node with\nthe appropriate name","ref":"Anoma.Configuration.html#launch_min/2"},{"type":"function","title":"Options - Anoma.Configuration.launch_min/2","doc":"see `t:launch_option/0` for the full list of optional arguments","ref":"Anoma.Configuration.html#launch_min/2-options"},{"type":"function","title":"Anoma.Configuration.locate_dump_file/1","doc":"","ref":"Anoma.Configuration.html#locate_dump_file/1"},{"type":"function","title":"Anoma.Configuration.node_settings/1","doc":"Given a map, I decode all the needed info for a minimal node startup\nand put it in the appropriate keyword list","ref":"Anoma.Configuration.html#node_settings/1"},{"type":"function","title":"Anoma.Configuration.read_configuration/1","doc":"","ref":"Anoma.Configuration.html#read_configuration/1"},{"type":"function","title":"Anoma.Configuration.save/2","doc":"","ref":"Anoma.Configuration.html#save/2"},{"type":"type","title":"Anoma.Configuration.configuration/0","doc":"","ref":"Anoma.Configuration.html#t:configuration/0"},{"type":"type","title":"Anoma.Configuration.configuration_map/0","doc":"","ref":"Anoma.Configuration.html#t:configuration_map/0"},{"type":"type","title":"Anoma.Configuration.launch_option/0","doc":"I control options for `launch_min/2`\n\n###Options\n\n- `:use_rocksdb` - see `t:Anoma.Node.configuration/0` for more\ninformation\n- `:supervisor` - This flag determine if we use a supervisor and if\nso what options. See `t:Supervisor.option/0 ` for supervisor options\n- `:testing` - This flag notes if we are testing the node. This gets\n  fed directly into the type `t:Anoma.Node.configuration/0` for\n  `Anoma.Node.start_link/1`. Please consult the\n  `t:Anoma.Node.configuration/0` documentation for the full effect\n  this has on the node","ref":"Anoma.Configuration.html#t:launch_option/0"},{"type":"type","title":"Anoma.Configuration.node_settings/0","doc":"","ref":"Anoma.Configuration.html#t:node_settings/0"},{"type":"type","title":"Anoma.Configuration.section_format/0","doc":"","ref":"Anoma.Configuration.html#t:section_format/0"},{"type":"type","title":"Anoma.Configuration.section_map/0","doc":"","ref":"Anoma.Configuration.html#t:section_map/0"},{"type":"module","title":"Anoma.Constants","doc":"","ref":"Anoma.Constants.html"},{"type":"function","title":"Anoma.Constants.felt_one/0","doc":"","ref":"Anoma.Constants.html#felt_one/0"},{"type":"function","title":"Anoma.Constants.felt_zero/0","doc":"","ref":"Anoma.Constants.html#felt_zero/0"},{"type":"function","title":"Anoma.Constants.prf_expand_personalization_felt/0","doc":"","ref":"Anoma.Constants.html#prf_expand_personalization_felt/0"},{"type":"module","title":"Anoma.Dump","doc":"I provide an interface to dump current state and load appropriate\nexternal files to launch them as Anoma nodes.\n\nYou can also use me to dump info such as current states and tables\nin a readable map format as well as get info stored in external\nfiles in binary format.","ref":"Anoma.Dump.html"},{"type":"module","title":"Dumping API - Anoma.Dump","doc":"I give access to following public dumping functionality:\n\n- `dump/2`\n- `get_all/1`\n- `get_state/1`\n- `get_tables/1`","ref":"Anoma.Dump.html#module-dumping-api"},{"type":"module","title":"Loading API - Anoma.Dump","doc":"I give access to following public loading functionality\n\n- `launch/2`\n- `launch/3`\n- `load/1`","ref":"Anoma.Dump.html#module-loading-api"},{"type":"function","title":"Anoma.Dump.dump/2","doc":"I dump the current state with storage. I accept a string as a name,\nso that the resulting file will be created as name.txt in the\nappropriate data directory. As a second argument I accept a node\nname whose info presented as a map I dump as a binary.\n\nNote that if the environment is `test` we do not use the XDG format\nfor storing data and instead dump the files in the immediate app\nfolder.\n\nThe map typing can be seen in `get_all`","ref":"Anoma.Dump.html#dump/2"},{"type":"function","title":"Anoma.Dump.dump_full_path/2","doc":"","ref":"Anoma.Dump.html#dump_full_path/2"},{"type":"function","title":"Anoma.Dump.get_all/1","doc":"I get all the info on the node tables and engines in order:\n- router\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor\n- table names\n- qualified\n- order\n- block_storage\nAnd turn the info into a tuple","ref":"Anoma.Dump.html#get_all/1"},{"type":"function","title":"Anoma.Dump.get_state/1","doc":"I get the engine states in order:\n- router\n- mempool topic\n- executor topic\n- dumper\n- storage\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor","ref":"Anoma.Dump.html#get_state/1"},{"type":"function","title":"Anoma.Dump.get_tables/1","doc":"I get the node tables in order:\n- storage (names)\n- qualified\n- order\n- block_storage\n- logger\n- rocks options","ref":"Anoma.Dump.html#get_tables/1"},{"type":"function","title":"Anoma.Dump.launch/3","doc":"I launch a node given a file containing a binary version of an 12-tuple\nwith appropriate info in the following order:\n- router id\n- mempool topic id\n- executor topic id\n- dumper\n- storage\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor\n- storage names\n- qualified\n- order\n- block_storage\n- logger_storage\n- rocks\n\nAll engines have info on their states and id's so that checkpointing\nthe system will keep all addresses used in the previous session.\nNote that I ensure that the appropriate tables are new.\n\nMoreover, I ensure that the mempool and block storage are in sync.\nIn particular, I check that the order of the last block is less than\nthat of the mempool dumped. If not, I manually remove the last block.\n\nCheck whether your transactions have had an assigned worker. If not,\nrelaunch them directly. If blocks were out of sync with mempool,\nrelaunch the executions as well.","ref":"Anoma.Dump.html#launch/3"},{"type":"function","title":"Options - Anoma.Dump.launch/3","doc":"see `launch_options/0` for the full list of optional arguments","ref":"Anoma.Dump.html#launch/3-options"},{"type":"function","title":"Anoma.Dump.load/1","doc":"I read the given file which I assume contains binary info and convert\nit to an Elixir term.\n\nAs the dumped state may have extra atoms not present in the session,\nI currently allow for atom creation in the loaded term.","ref":"Anoma.Dump.html#load/1"},{"type":"function","title":"Anoma.Dump.remove_dump/2","doc":"Removes the given dump files at the specified address and with the\ngiven configuration.\n\nSee `Anoma.System.Directories` for more information about the path\nresolution and for the second atom.","ref":"Anoma.Dump.html#remove_dump/2"},{"type":"type","title":"Anoma.Dump.clock_eng/0","doc":"","ref":"Anoma.Dump.html#t:clock_eng/0"},{"type":"type","title":"Anoma.Dump.configuration_eng/0","doc":"","ref":"Anoma.Dump.html#t:configuration_eng/0"},{"type":"type","title":"Anoma.Dump.dump/0","doc":"","ref":"Anoma.Dump.html#t:dump/0"},{"type":"type","title":"Anoma.Dump.dump_eng/0","doc":"","ref":"Anoma.Dump.html#t:dump_eng/0"},{"type":"type","title":"Anoma.Dump.ex_eng/0","doc":"","ref":"Anoma.Dump.html#t:ex_eng/0"},{"type":"type","title":"Anoma.Dump.launch_option/0","doc":"I control launch options for `launch/2`","ref":"Anoma.Dump.html#t:launch_option/0"},{"type":"type","title":"Options - Anoma.Dump.launch_option/0","doc":"- `:supervisor` - This flag determine if we use a supervisor and if\nso what options. See `t:Supervisor.option/0 ` for supervisor options\n\n- `:testing` - This flag notes if we are testing the node. This gets\n  fed directly into the type `t:Anoma.Node.configuration/0` for\n  `Anoma.Node.start_link/1`. Please consult the\n  `t:Anoma.Node.configuration/0` documentation for the full effect\n  this has on the node","ref":"Anoma.Dump.html#t:launch_option/0-options"},{"type":"type","title":"Anoma.Dump.log_eng/0","doc":"","ref":"Anoma.Dump.html#t:log_eng/0"},{"type":"type","title":"Anoma.Dump.mem_eng/0","doc":"","ref":"Anoma.Dump.html#t:mem_eng/0"},{"type":"type","title":"Anoma.Dump.ord_eng/0","doc":"","ref":"Anoma.Dump.html#t:ord_eng/0"},{"type":"type","title":"Anoma.Dump.ping_eng/0","doc":"","ref":"Anoma.Dump.html#t:ping_eng/0"},{"type":"type","title":"Anoma.Dump.storage_eng/0","doc":"","ref":"Anoma.Dump.html#t:storage_eng/0"},{"type":"type","title":"Anoma.Dump.stores/0","doc":"","ref":"Anoma.Dump.html#t:stores/0"},{"type":"module","title":"Anoma.Node.Clock","doc":"I am the implmentation of the Local Wall Clock Engine.\n\nI provide info on the time elapsed in milliseconds after the node launched\nand the epoch from which it has been calculated using monotonic time.\n\nThe current implementation launches the epoch by asking for the system\nmonotonic time at the point of an Anoma node launch. This is recommended\nas all my public API uses system monotonic time to give measurements.","ref":"Anoma.Node.Clock.html"},{"type":"module","title":"Public API - Anoma.Node.Clock","doc":"I have the following public functionality:\n\n- `get_time/1`","ref":"Anoma.Node.Clock.html#module-public-api"},{"type":"function","title":"Anoma.Node.Clock.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Clock.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Clock.get_time/1","doc":"I get the local time by checking the clock epoch attached to\nthe clock address, taking the current system monotonic time,\nand then subtracting the former from the latter.","ref":"Anoma.Node.Clock.html#get_time/1"},{"type":"function","title":"Anoma.Node.Clock.init/1","doc":"I am the initialization function for a Clock Engine instance.","ref":"Anoma.Node.Clock.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Clock.init/1","doc":"- `init(%Clock{})` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist with a `:start` key and return the\n                 appropriate state.","ref":"Anoma.Node.Clock.html#init/1-pattern-matching-variations"},{"type":"type","title":"Anoma.Node.Clock.t/0","doc":"I am the type of the Clock Engine.\n\nI currently just store the start-up info, recording when the system was\nlaunched.","ref":"Anoma.Node.Clock.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Clock.t/0","doc":"- `:start` - Integer value corresponding to the system start timing\n             provided by the internal erlang functionality.","ref":"Anoma.Node.Clock.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Configuration","doc":"I am the implementation of the Configuration Engine.\n\nI remember the configuration that the application was launched with as\nwell as call the snapshotting and snapshot-deletion functionality.","ref":"Anoma.Node.Configuration.html"},{"type":"module","title":"Public API - Anoma.Node.Configuration","doc":"I have the following public functionality:\n\n- `snapshot/1`\n- `delete_dump/1`","ref":"Anoma.Node.Configuration.html#module-public-api"},{"type":"function","title":"Anoma.Node.Configuration.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Configuration.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Configuration.delete_dump/1","doc":"I am the function deleting the snapshot file.\n\nI check the dump path and check whether there is any file snapshot there.\nIf so, I delete it, otherwise I do nothing.","ref":"Anoma.Node.Configuration.html#delete_dump/1"},{"type":"function","title":"Anoma.Node.Configuration.handle_cast/3","doc":"","ref":"Anoma.Node.Configuration.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Configuration.init/1","doc":"I am the Configuration Engine initialization function.\n\nI receive a Configuration.t() structure and launch the engine instance\nwith the fed-in state.","ref":"Anoma.Node.Configuration.html#init/1"},{"type":"function","title":"Anoma.Node.Configuration.snapshot/1","doc":"I am the snapshot function.\n\nI take a snapshots of the current state. The topic sends back a message\nto the caller saying `:snapshot_done`.\n\nThe path for the snapshot is taken directly from the configuration map.","ref":"Anoma.Node.Configuration.html#snapshot/1"},{"type":"type","title":"Anoma.Node.Configuration.t/0","doc":"I am the type of the Configuration Engine.","ref":"Anoma.Node.Configuration.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Configuration.t/0","doc":"- `:configuration` - The configuration data stored in specified format.\n                     Please consult the\n                     `t:Anoma.Configuration.configuration_map/0`.\n                     Enforced: true.\n- `:logger` - The address of the Logger Engine. Enforced: false.","ref":"Anoma.Node.Configuration.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Dumper","doc":"I am the Dumper Engine.\n\nMy role is to spawn asynchronous processes which\nlisten to a specified block table announcement and await when blocks\nmodulo my count have been executed, at which point I checkpoint the\nassigned node using the duping system using a file with a specified name.","ref":"Anoma.Node.Dumper.html"},{"type":"module","title":"Public API - Anoma.Node.Dumper","doc":"I have the following public functionality:\n\n- `start/1`\n- `stop/1`\n- `set_count/2`","ref":"Anoma.Node.Dumper.html#module-public-api"},{"type":"function","title":"Anoma.Node.Dumper.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Dumper.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Dumper.handle_cast/3","doc":"","ref":"Anoma.Node.Dumper.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Dumper.init/1","doc":"I am the initialization function for the Dumper Engine.","ref":"Anoma.Node.Dumper.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Dumper.init/1","doc":"- `init(%Dumper{})` - I initialize the Engine with given state.\n- `init(opts)` - I expect a keylist with the `:count`, `:configuration`,\n                 and `:logger` keys available. I then start the engine\n                 instance with appropriate state.","ref":"Anoma.Node.Dumper.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Dumper.set_count/2","doc":"I set the count of a Dumper Engine instance.\n\nI first shutdown the current task, start a new task with a changed count\nparameter and return and register both the count and the task changes.\n\nIf count is a non-positive integer, I do nothing. If it is nil, I set both\nthe count and the task at hand to nil.","ref":"Anoma.Node.Dumper.html#set_count/2"},{"type":"function","title":"Anoma.Node.Dumper.start/1","doc":"I am the Dumper start function.\n\nI start a dumping loop based on the count supplied. If an old task was\npresent before the start, I shut it down. If the count is nil I return\na state with nil count and nil task.","ref":"Anoma.Node.Dumper.html#start/1"},{"type":"function","title":"Anoma.Node.Dumper.stop/1","doc":"I am the Dumper stop function.\n\nI shutdown the dumper task registered in the struct. Depending on the\nshutdown message, I provide separate logs and then set the task field to\n`nil`.","ref":"Anoma.Node.Dumper.html#stop/1"},{"type":"type","title":"Anoma.Node.Dumper.t/0","doc":"I am the type of the Dumper Engine.\n\nI store the number of blocks to be passed before snapshotting, the\nConfiguration Engine address, as well as the task responsible for the\nsnapshotting.","ref":"Anoma.Node.Dumper.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Dumper.t/0","doc":"- `:count` - Field specifying how many blocks ought to pass between\n             snapshots. Enforced: false.\n- `:configuration` - The Configuration Engine address using which the\n                     snapshot path is found.\n- `:task` - The field containing the task carrying out the\n            snapshotting. Enforced: false.\n- `:logger` - The address of the Logger Engine. Enforced: false.","ref":"Anoma.Node.Dumper.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Event","doc":"I am an Anoma node specific event. I go inside the body field of an EventBroker.Event.","ref":"Anoma.Node.Event.html"},{"type":"type","title":"Anoma.Node.Event.t/0","doc":"","ref":"Anoma.Node.Event.html#t:t/0"},{"type":"module","title":"Anoma.Node.Event.Filters.SourceEngine","doc":"I filter Anoma node events by source engine.","ref":"Anoma.Node.Event.Filters.SourceEngine.html"},{"type":"function","title":"Anoma.Node.Event.Filters.SourceEngine.filter/2","doc":"","ref":"Anoma.Node.Event.Filters.SourceEngine.html#filter/2"},{"type":"type","title":"Anoma.Node.Event.Filters.SourceEngine.t/0","doc":"","ref":"Anoma.Node.Event.Filters.SourceEngine.html#t:t/0"},{"type":"module","title":"Anoma.Node.Logger","doc":"I am the Logger Engine, an implementation of the Local Logging Engine.\n\nI have a storage field which accepts the storage used for the logging\ntied to a specific node, as well as the address of the clock used for\ntimestamping.\n\nI store and get the logging info using the keyspace method.","ref":"Anoma.Node.Logger.html"},{"type":"module","title":"Public API - Anoma.Node.Logger","doc":"I provide the following public functionality:\n\n#### Adding Logs\n\n- `add/3`\n\n#### Getting Logs\n\n- `get/1`\n- `get/2`","ref":"Anoma.Node.Logger.html#module-public-api"},{"type":"function","title":"Anoma.Node.Logger.add/3","doc":"I am the Logger add function, the implementation of LocalLoggingAppend of\nthe Local Logging Engine of the Anoma Specification.\n\nI receive three arguments: an address of the logger, an atom specifying\nthe urgency of the logging message and the logging message itself.\n\nIf the logger address is indeed an address, I put the info inside the\nspecified storage using `Storage.put/3`.\n\nThe information is stored using a keyspace method. The message is hence\nattached to a list of 4 elements:\n\n1. ID of the logger calling for storage\n2. ID of the engine whose info we log or a PID of the worker process\n3. Timestamp relative to the clock engine used\n4. The urgency atom\n\nI then use the atom to call the Elixir logger in order to inform the\nuser of any specific major logging event such as, e.g. failing\nworkers.","ref":"Anoma.Node.Logger.html#add/3"},{"type":"function","title":"Anoma.Node.Logger.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Logger.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Logger.get/1","doc":"I am the Logger get function of one argument.\n\nGiven a non-nil logger address, I get the entire keyspace related to the\nstorage attached to the aforementioned logger ID using\n`Storage.get_keyspace/2`\n\nI return a list of 2-tuples. Its left element will be a list whose\nhead is the ID of the specified logger, followed by the engine ID (or\nworker PID), the timestamp, and an atom specifying urgency of the logging\nmessage. Its right element will be the message.","ref":"Anoma.Node.Logger.html#get/1"},{"type":"function","title":"Anoma.Node.Logger.get/2","doc":"I am the Logger get function of two arguments.\n\nGiven a non-nil logger address and an engine address, I get the keyspace\nwhich contains all the info stored by the logger about the supplied\nengine using `Storage.get_keyspace/2`\n\nI return a list of 2-tuples. Its left element will be a list whose\nhead is the ID of the specified logger, followed by the engine ID (or\nworker PID), the timestamp, and an atom specifying urgency of the logging\nmessage. Its right element will be the message.","ref":"Anoma.Node.Logger.html#get/2"},{"type":"function","title":"Anoma.Node.Logger.handle_cast/3","doc":"","ref":"Anoma.Node.Logger.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Logger.init/1","doc":"I am the Logger Engine initialization function.","ref":"Anoma.Node.Logger.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Logger.init/1","doc":"- `init(Logger.t())` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist with `:storage`, `:clock`, and\n                 `:topic` keys and launch the Engine with the appropriate\n                 state.","ref":"Anoma.Node.Logger.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Logger.init_table/1","doc":"","ref":"Anoma.Node.Logger.html#init_table/1"},{"type":"type","title":"Anoma.Node.Logger.t/0","doc":"I am the type of the Logging Engine.\n\nI have the minimal fields required to store timestamped messages in the\nspecified storage.","ref":"Anoma.Node.Logger.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Logger.t/0","doc":"- `:clock` - The Clock Engine address used for timestamping.\n- `:table` - The table names used for persistent logging.\n- `:topic` - The topic address for broadcasting.","ref":"Anoma.Node.Logger.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Ordering","doc":"I am the Ordering Engine.\n\nMy main functionality is to calculate transaction ordering and keep track\nof said ordering relative to the transaction id's.","ref":"Anoma.Node.Ordering.html"},{"type":"module","title":"Public API - Anoma.Node.Ordering","doc":"I provide the following public functionality:\n\n#### Ordering\n\n- `true_order/2`\n- `new_order/2`\n\n#### Reset\n\n- `reset/1`\n- `hard_reset/2`\n\n#### Blocking\n\n- `caller_blocking_read_id/2`\n\n#### Other\n\n- `handle_new_order/2`","ref":"Anoma.Node.Ordering.html#module-public-api"},{"type":"function","title":"Anoma.Node.Ordering.caller_blocking_read_id/2","doc":"I call the blocking read functionality on a Worker request.\n\nI am called by the Worker, who sends me an Ordering Engine address and a\nlist with head a transaction ID and a subkey for the storage key.\n\nI get the orders of the transactions via checking their ID keys in the\nOrdering Engine. I then return the list by interchanging the transaction\nID with its order and call `Storage.blocking_read/2` with the\nappropriate arguments.","ref":"Anoma.Node.Ordering.html#caller_blocking_read_id/2"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Ordering.caller_blocking_read_id/2","doc":"- `caller_blocking_read_id(ordering, [id | subkey])` - I match on the\n                                                       given list to\n                                                       check transaction\n                                                       ID.","ref":"Anoma.Node.Ordering.html#caller_blocking_read_id/2-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Ordering.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Ordering.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Ordering.handle_cast/3","doc":"","ref":"Anoma.Node.Ordering.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Ordering.handle_new_order/2","doc":"I handle the new ordered transactions coming in to the Ordering Engine.\n\nI send read_ready messages regarding the transaction orders, then add the\nlength of the incoming transaction list to the `:next_order` value,\nfinally updating the `:hash_to_order` map with new key-values.\n\nI return a tuple where the first argument is the new proposed next order\nwhile the second argument is the new map of ID's to orders.","ref":"Anoma.Node.Ordering.html#handle_new_order/2"},{"type":"function","title":"Anoma.Node.Ordering.hard_reset/2","doc":"I hard reset the Ordering Engine.\n\nSimilarly to `reset/1` I get rid of all hot state fields in the Ordering\nEngine. Moreover, I ask the Storage engine to ensure that the tables are\nre-launched and put a new snapshot specified by the second argument.","ref":"Anoma.Node.Ordering.html#hard_reset/2"},{"type":"function","title":"Anoma.Node.Ordering.init/1","doc":"I am the initialization function for a Ordering Engine instance.","ref":"Anoma.Node.Ordering.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Ordering.init/1","doc":"- `init(%Ordering{})` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist with the `:logger` and `:storage`\n                 keys. I then ask the Storage engine given by the keyword\n                 to setup and return the appropriate initialization\n                 state.","ref":"Anoma.Node.Ordering.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Ordering.new_order/2","doc":"I am the function dealing with new ordered transactions.\n\nGiven a list of ordered transactions, I update the Ordering Engine state\nappropriately by changing the `:next_order` field and filling in the\n`:hash_to_order` field with new key-value pairs pairing the new ID's with\ntheir assigned orderings.","ref":"Anoma.Node.Ordering.html#new_order/2"},{"type":"function","title":"Anoma.Node.Ordering.reset/1","doc":"I am the Ordering Engine reset function.\n\nI get rid of all hot state fields of the Ordering Engine leaving only the\nStorage and Logger address intact.","ref":"Anoma.Node.Ordering.html#reset/1"},{"type":"function","title":"Anoma.Node.Ordering.true_order/2","doc":"I am the true order function.\n\nGiven a transaction ID, I get the order associated with the transaction.\nI look at the map stored in the state and then check the value of said\nID.","ref":"Anoma.Node.Ordering.html#true_order/2"},{"type":"type","title":"Anoma.Node.Ordering.key/0","doc":"I am a type representing a key in a key-value map.","ref":"Anoma.Node.Ordering.html#t:key/0"},{"type":"type","title":"Anoma.Node.Ordering.ordered_transactions/0","doc":"I am a list of ordered transactions.","ref":"Anoma.Node.Ordering.html#t:ordered_transactions/0"},{"type":"type","title":"Anoma.Node.Ordering.t/0","doc":"I am the type of the Ordering Engine.\n\nI have basic fields relating to upcoming ordering for the incoming\ntransactions as well as mapping of transaction ID's to their orders.","ref":"Anoma.Node.Ordering.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Ordering.t/0","doc":"- `:storage` - The address of the storage engine\n- `:next_order` - The integer referencing the order to be given to the\n                  next incoming transaction.\n                  Default: 1\n- `:hash_to_order` - A map of transaction ID's and their orders.\n                     Default: %{}\n- `:logger` - The Logger Engine address.","ref":"Anoma.Node.Ordering.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Pinger","doc":"I am the Pinger Engine.\n\nI provide periodic block execution based on submitted mempool address\nand time by calling the execution API in the mempool engine.","ref":"Anoma.Node.Pinger.html"},{"type":"module","title":"Public APIs - Anoma.Node.Pinger","doc":"I have the following public functionality:\n\n- `start/1`\n- `pinger/1`\n- `set_timer/2`","ref":"Anoma.Node.Pinger.html#module-public-apis"},{"type":"function","title":"Anoma.Node.Pinger.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Pinger.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Pinger.handle_cast/3","doc":"","ref":"Anoma.Node.Pinger.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Pinger.init/1","doc":"I am the initialiation function for the Pinger Engine.","ref":"Anoma.Node.Pinger.html#init/1"},{"type":"function","title":"Patern-Matching Variations - Anoma.Node.Pinger.init/1","doc":"- `init(%Pinger{})` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist with the `:mempool`, `:time` and\n                 `:logger` keywords and then start a Pinger Engine\n                 instance with appropriate state.","ref":"Anoma.Node.Pinger.html#init/1-patern-matching-variations"},{"type":"function","title":"Anoma.Node.Pinger.pinger/1","doc":"I am the pinger function.\n\nI receive an argument which is either an integer or :no_timer.\nIf it is an integer, send to self an :execute message after\nthe specified amount of time. Otherwise, simply reply :ok","ref":"Anoma.Node.Pinger.html#pinger/1"},{"type":"function","title":"Anoma.Node.Pinger.set_timer/2","doc":"I set the timer field for a Pinger Engine instance.\n\nGiven a server S and time T I change the timer set for the struct\nconnected to S setting it to T. Set T to :no_timer to stop the\npinger.","ref":"Anoma.Node.Pinger.html#set_timer/2"},{"type":"function","title":"Anoma.Node.Pinger.start/1","doc":"I start the Pinger Engine's execution-calling functionality.\n\nGiven a pinger address, I start up the pinger by calling the `pinger/1`\nfunction feeding it the time associated to the address.\n\nNote that if the timer specified has value :no_timer, the pinger will\nnot practically start.","ref":"Anoma.Node.Pinger.html#start/1"},{"type":"type","title":"Anoma.Node.Pinger.t/0","doc":"I am the type of the Pinger Engine instance.\n\nI store minimal info required to ask the mempool to execute, namely the\nmempool address and the time specified by the user.\n\n- `:mempool` - The Mempool Engine address which is called to execute.\n- `:time` - The time that should be elapsed between the calls to\n            execute or an atom saying that no timer should be set.\n            Default: `:no_timer`\n- `:logger` - The address of the Logger Engine.","ref":"Anoma.Node.Pinger.html#t:t/0"},{"type":"module","title":"Anoma.Node.Router","doc":"I am the Router, the central networking component of Anoma. My\nfunctionality includes several services:\n\n1. I provide central routing infrastructure for inter-node and\n   intra-node communication\n\n1. I provide service's for topic creation and\n   `Anoma.Node.Router.Engine` creation\n\n1. I provide a behavior interface similar to `GenServer` for both\n   [`Engine`](`Anoma.Node.Router.Engine`) messaging and `Topic`\n   messaging","ref":"Anoma.Node.Router.html"},{"type":"module","title":"Router Topology - Anoma.Node.Router","doc":"A good view of my topology and how various\n`Anoma.Node.Router.Engine` and topic's relate to me can be seen by\nthe following diagram.\n\n```mermaid\ngraph TB\n  S(Router Supervisor)\n  R(Router)\n  C(Engine #1) ~~~ B(Engine #2)\n  T1(Topic #1) ~~~ T2(Topic #2)\n  S ==>R & B & C\n  S -.->T1 & T2\n  R <-->|router| B & C & T1 & T2\n```\n\n`Anoma.Node.Router.Engine`'s that are spawned via `start_engine/3`\nare added to the supervisor, and messages sent via `call/3` or\n`cast/2` may be routed through myself.\n\nTopics are handled somewhat specially. Since they serve a much more\nlimited role, I handle and manage them personally and the dashed\nlines in the diagram are not real. However for building a conceptual\nmodel, we can view `Topics` spawned by `new_topic/1` as spawning an\n[`Engine`](`Anoma.Node.Router.Engine`), and messages sent via\n`call/3` or `cast/2` as being routed through myself.","ref":"Anoma.Node.Router.html#module-router-topology"},{"type":"module","title":"Server Terminology - Anoma.Node.Router","doc":"For the sake of this document, the word `Server` will refer to both\n[`Engines`](`Anoma.Node.Router.Engine`) and `Topics`.","ref":"Anoma.Node.Router.html#module-server-terminology"},{"type":"module","title":"Router PIDs - Anoma.Node.Router","doc":"The IDs of the various topics and\n[engines](`Anoma.Node.Router.Engine`), are not regular Erlang\nPID's. Instead we use our own address schema laid out in\n`Anoma.Node.Router.Addr`. Further information can also be found in\nour specs (link to specs when they are online).","ref":"Anoma.Node.Router.html#module-router-pids"},{"type":"module","title":"Public API - Anoma.Node.Router","doc":"I provide the following public functionality:\n\n#### Router API\n\nI offer an API for anyone wishing to call me. These functions are:\n\n- `start/0`\n- `start/1`\n- `new_topic/1`\n- `subscribe_topic/2`\n- `start_engine/3`\n- `start_engine/4`\n- `subscribe_topic/3`\n\n#### Server APIs\n\nWhen writing server code, My module acts as a `GenServer` behavior,\nin that one should be using these functions when writing code to\ntalk to the `Server`:\n\n- `call/2`\n- `cast/2`\n- `call/3`\n\nThe API I offer is very reminiscent of `GenServer`'s API, however\nplease read the [examples](#module-examples) section to get a sense\non how the server code differs.\n\n#### Self-Cast/Call API\n\nI have separate API for assisting myself upon message reception from\nmyself as a GenServer.\n\n- `handle_self_cast/3`\n- `handle_self_call/3`\n\n#### Other\n\n- `stop/0`\n- `self_addr/0`\n- `router/0`\n- `shutdown_node/1`\n- `dump_state/1`\n- `set_logger/2`\n- `send_raw/2`\n- `process_name/2`\n- `do_handle_external_cast/3`\n- `send_response/4`","ref":"Anoma.Node.Router.html#module-public-api"},{"type":"module","title":"Client/Server APIs - Anoma.Node.Router","doc":"Much like `GenServer`, user's typically don't call my `call/3` or\n`cast/2` directly. Instead the user wraps the calls in new functions\nrepresenting the public API of the server. These wrappers are called\nthe **client API**.","ref":"Anoma.Node.Router.html#module-client-server-apis"},{"type":"module","title":"Examples - Anoma.Node.Router","doc":"To get a good feel for writing idiomatic code using me, and how my\nAPI is differs from `GenServer`, we will look at an implementation\nof a stack and see how it [differs from GenServer's stack\nexample](https://hexdocs.pm/elixir/GenServer.html#module-client-server-apis)\n\n    defmodule Stack do\n      alias Anoma.Node.Router\n\n      use Router.Engine\n\n      @spec init(String.t()) :: {:ok, list(String.t())}\n      def init(elements) do\n        initial_state = String.split(elements, \",\", trim: true)\n        {:ok, initial_state}\n      end\n\n      @spec push(Router.addr(), String.t()) :: :ok\n      def push(pid, element) do\n        Router.cast(pid, {:push, element})\n      end\n\n      @spec pop(Addr.t()) :: String.t()\n      def pop(pid) do\n        Router.call(pid, :pop)\n      end\n\n      def handle_call(:pop, _from, state) do\n        [to_caller | new_state] = state\n        {:reply, to_caller, new_state}\n      end\n\n      def handle_cast({:push, element}, _from, state) do\n        new_state = [element | state]\n        {:noreply, new_state}\n      end\n    end\n\nAnd we can use this Engine like the following\n\n    iex> {:ok, router, _transport} = Router.start()\n    iex> {:ok, stack} = Router.start_engine(router, Stack, \"hello\")\n    iex> Stack.pop(stack)\n    \"hello\"\n    iex> Stack.push(stack, \"hi\")\n    :ok\n    iex> Stack.pop(stack)\n    \"hi\"\n\nOverall having both server and client functionality that is clearly\nlabeled, leads to good user UI's.","ref":"Anoma.Node.Router.html#module-examples"},{"type":"module","title":"Difference in Design from `GenServer` - Anoma.Node.Router","doc":"The Stack example shows how my API differs from `Genserver`:\n\n1. There is currently no `GenServer.start_link/3` for the Router\n\n2. Even `handle_cast`'s take a `from` parameter\n\n3. We use `Anoma.Node.Router.Engine` and not `GenServer`\n\n4. Further `call/2` by default has an :infinite timeout","ref":"Anoma.Node.Router.html#module-difference-in-design-from-genserver"},{"type":"module","title":"Summarizing the interactions between Server and Clients - Anoma.Node.Router","doc":"For basic `Server`'s we can summarize interactions between all\nparties as follows.\n\n  ```mermaid\n  sequenceDiagram\n    participant C as Client (Process/Engine)\n    participant R as Router (Engine)\n    participant S as Server (Engine)\n    participant M as Module (Code)\n\n    note right of C: Typically started by an init process\n    C->>+R: Router.start_engine(router, module, arg, options)\n    R->>+S: GenServer.start_link(router, module, arg, options)\n    S-->>+M: init(arg)\n    M-->>-S: {:ok, state} | :ignore | {:error, reason}\n    S->>-R: {:ok, addr} | :ignore | {:error, reason}\n    R->>-C: {:ok, addr} | :ignore | {:error, reason}\n\n    note right of C: call is synchronous\n    C->>+R: Router.call(addr, message)\n    note right of R: For known engines this is optimized away\n    R->>+S: GenSever.call(pid, {self, message})\n    S-->>+M: handle_call(message, from, state)\n    M-->>-S: {:reply, reply, state} | {:stop, reason, reply, state}\n    S->>-C: reply\n\n    note right of C: cast is asynchronous\n    C-)R: Router.cast(addr, message)\n    note right of R: For known engines this is optimized away\n    R-)S: GenServer.cast(pid, message)\n    S-->>+M: handle_cast(message, state)\n    M-->>-S: {:noreply, state} | {:stop, reason, state}\n\n    note right of C: send is asynchronous. the PAID must be known\n    C-)S: Kernel.send(pid, message)\n    S-->>+M: handle_info(message, state)\n    M-->>-S: {:noreply, state} | {:stop, reason, state}\n```\n\nWhat this diagram doesn't show is how Topic messaging works, and for\nthat, this diagram may be of assistance.\n\n  ```mermaid\n  sequenceDiagram\n    participant C as Client (Process/Engine)\n    participant S2 as Server2 (Engine)\n    participant R as Router (Engine)\n    participant T as Topic (Topic)\n    participant S as Server (Engine)\n\n\n    note right of R: For simplicity we do not display a client\n    S2-)+R: GenServer.subscribe(router, topic)\n    R-->>+T: GenSever.call(addr, {self, message})\n    T-->>-R: :ok | {:error, :no_such_topic}\n    R-)-S2: :ok | {:error, :no_such_topic}\n\n\n    note right of C: cast is asynchronous\n    C-)R: Router.cast(addr, message)\n    R-)+S: GenServer.cast(pid, message)\n    note right of S: Imagine this call sends an update to a topic\n    S-)-R: Router.cast(topic_addr, msg)\n    R-->>T: Genserver.cast(pid, msg)\n    T-->>R: Router.cast(addr_S2, msg)\n    R-)S2: Genserver.cast(pid, msg)\n```\n\nThe dotted lines in the diagram are theoretically how `Tasks` could\nbe implemented, however this is implementation dependent, and does\nindeed differ from the diagram.","ref":"Anoma.Node.Router.html#module-summarizing-the-interactions-between-server-and-clients"},{"type":"function","title":"Anoma.Node.Router.call/2","doc":"I am a call function.\n\nI use `call/3` with the specified address and message and set the default\ntimeout o 5000.","ref":"Anoma.Node.Router.html#call/2"},{"type":"function","title":"Anoma.Node.Router.call/3","doc":"I am the Router call function.\n\nI make a synchronous call to the `Server` and wait for a reply.\n\nCall has a few interesting cases we can consider\n\n1. Calling a local [`Engine`](`Anoma.Node.Router.Engine`)\n\n2. Calling a non local [`Engine`](`Anoma.Node.Router.Engine`)\n\nWe can not `call/3` a `Topic`, and thus those instances are not\nhandled.\n\nCurrently we do not handle the non local\n[`Engine`](`Anoma.Node.Router.Engine`) case.\n\nFor the local [`Engine`](`Anoma.Node.Router.Engine`), then their\n[`Engine.handle_call/3`](`c:Anoma.Node.Router.Engine.handle_call/3`)\nwill be called on the [`Engine`](`Anoma.Node.Router.Engine`) to\nhandle the request.","ref":"Anoma.Node.Router.html#call/3"},{"type":"function","title":"Timeouts - Anoma.Node.Router.call/3","doc":"By default the timeout is infinite for local calls. For non local\ncalls the timeout is not yet defined and will be iterated upon in\nfuture versions","ref":"Anoma.Node.Router.html#call/3-timeouts"},{"type":"function","title":"Anoma.Node.Router.cast/2","doc":"I am the Router cast function.\n\nI make a asynchronous cast to the `Server`.\n\nCall has a few interesting cases we can consider\n\n1. Casting to a local [`Engine`](`Anoma.Node.Router.Engine`)\n\n2. Casting to a non local [`Engine`](`Anoma.Node.Router.Engine`)\n\n3. Casting to a `Topic`\n\n\nFor the local [`Engine`](`Anoma.Node.Router.Engine`), then their\n[`Engine.handle_cast/3`](`c:Anoma.Node.Router.Engine.handle_cast/3`)\nwill be called on the [`Engine`](`Anoma.Node.Router.Engine`) to\nhandle the request.\n\nCasting a non local [`Engine`](`Anoma.Node.Router.Engine`) isn't\nhandled yet.\n\nFor `Topics` any `cast/2` sent, then triggers a series of `cast/2`\nto all subscribed `Process`'s","ref":"Anoma.Node.Router.html#cast/2"},{"type":"function","title":"Anoma.Node.Router.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Router.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Router.do_handle_external_cast/3","doc":"I am a function handling non-local casts to the Router.\n\nCurrently I only process a message to shut everything down by calling\n`System.stop/0`","ref":"Anoma.Node.Router.html#do_handle_external_cast/3"},{"type":"function","title":"Anoma.Node.Router.dump_state/1","doc":"I am the state cleanup function.\n\nI empty the entire state of the Router whose Address I receive.","ref":"Anoma.Node.Router.html#dump_state/1"},{"type":"function","title":"Anoma.Node.Router.handle_self_call/3","doc":"I am a handle_self_call function.\n\nOnce `call/2` or `do_call` gets done finding the appropriate server to\nsend the message to, some of them get forwarded back to the Router\nthrough itself. I am the helper function helping to process such\ninteractions.","ref":"Anoma.Node.Router.html#handle_self_call/3"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Router.handle_self_call/3","doc":"- `handle_self_call(:supervisor, src, s)` -\n    Asks for a supervisor of the router.\n- `handle_self_call({:create_topic, id, :local}, _, _)` -\n    Unless the topic has already been added to the topic table, puts it\n    to the table with an empty set of subscribers and return the new\n    structure with specified ID.\n- `handle_self_call({:subscribe_topic, topic, :local}, _, _)` -\n    Updates the topic tables and engine subscriber fields in the Router to\n    include the new specified subscriber.\n- `handle_self_call({:unsubscribe_topic, topic, :local}, _, _)` -\n    Updates the topic tables and engine subscriber fields in the Router to\n    remove the specified subscriber information.","ref":"Anoma.Node.Router.html#handle_self_call/3-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Router.handle_self_cast/3","doc":"I am a handle_self_cast function.\n\nOnce `cast/2` or `do_cast` gets done finding the appropriate server to\nsend the message to, some of them get forwarded back to the Router\nthrough itself. I am the helper function helping to process such\ninteractions.","ref":"Anoma.Node.Router.html#handle_self_cast/3"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Router.handle_self_cast/3","doc":"- `handle_self_cast{:set_logger, logger}, src, s` -\n    Assigns the specified Logger Engine address to the Router.\n- `handle_self_cast(:shutdown_everything, _, _)` -\n    Calls `System.stop` to shutdown the entire system.\n- `handle_self_cast({:send_response, _, _, _}, _, _)` -\n    Sends the response message to transport with specified cookie.\n- `handle_self_cast({:p2p_raw, _, _}, _, _)` -\n    Handles p2p messaging, either sending raw messages or post-processing\n    them using Router functionality. Note that unknown message formats get\n    dropped. The droppages get logged.","ref":"Anoma.Node.Router.html#handle_self_cast/3-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Router.init/1","doc":"","ref":"Anoma.Node.Router.html#init/1"},{"type":"function","title":"Anoma.Node.Router.new_topic/1","doc":"I am the topic-creation function.\n\nI create a new topic with a new random external key.","ref":"Anoma.Node.Router.html#new_topic/1"},{"type":"function","title":"Anoma.Node.Router.new_topic/2","doc":"I am the topic-creation function.\n\nI create a new topic with specified external ID from a full Anoma ID.","ref":"Anoma.Node.Router.html#new_topic/2"},{"type":"function","title":"Anoma.Node.Router.process_name/2","doc":"I am a function formulating a process name.\n\nGiven a module name and an external ID, I append to the module name the\nencoded sign field of the ID and return it as an atom.","ref":"Anoma.Node.Router.html#process_name/2"},{"type":"function","title":"Anoma.Node.Router.router/0","doc":"I am a function to search for the Engine Router inside an Engine.","ref":"Anoma.Node.Router.html#router/0"},{"type":"function","title":"Anoma.Node.Router.self_addr/0","doc":"I am a function providing the default address to the process which runs\nme.\n\nMy server is either the specified engine server or my PID.","ref":"Anoma.Node.Router.html#self_addr/0"},{"type":"function","title":"Anoma.Node.Router.send_raw/2","doc":"I send a message directly using Kernel.send/1 to the local process, assuming\nthere is one.","ref":"Anoma.Node.Router.html#send_raw/2"},{"type":"function","title":"Anoma.Node.Router.send_response/4","doc":"I am a function sending responses.\n\nI send a response to an externally received call. This is a low-level\nroutine, intended to be called only by the internals of Router and Engine.","ref":"Anoma.Node.Router.html#send_response/4"},{"type":"function","title":"Anoma.Node.Router.set_logger/2","doc":"I am the logger-setting function.\n\nAfter the Logger Engine has been started, we can add it to the Router to\nlog events using it. To avoid recursive calls, some logging utilizes only\nthe internal Elixir logger.","ref":"Anoma.Node.Router.html#set_logger/2"},{"type":"function","title":"Anoma.Node.Router.shutdown_node/1","doc":"I am a function for Node shutdown.\n\nAs an Anoma Node is associated with a specific Router, I can cast a\nmessage to shut down all local Engines, the Router, and the Node\nitself using only the Router.\n\nWe should tweak this in the future, with a mode to just shut down\nthe Anoma Node itself.","ref":"Anoma.Node.Router.html#shutdown_node/1"},{"type":"function","title":"Anoma.Node.Router.start/0","doc":"I am the minimal start function.\n\nI call `start/1` with a random `Anoma.Crypto.Id` and default state.","ref":"Anoma.Node.Router.html#start/0"},{"type":"function","title":"Anoma.Node.Router.start/1","doc":"I am the Router start function.\n\nI start a new router using the specified Anoma ID for the Router and the\ntransport. (Additionally, you can feed me a router state)\n\nUsing the fed in external ID, I name the supervisor using `process_name/2`\nand start it as a Dynamical Supervisor with appropriate name.\n\nSimilarly, I create the router name and address using the external ID and\nstart the Router and Transport structures as children to the specified\nsupervisor.\n\nOn success, return {:ok, router_addr, transport_addr}","ref":"Anoma.Node.Router.html#start/1"},{"type":"function","title":"Anoma.Node.Router.start_engine/4","doc":"I am the function launching a new Anoma Engine instance\n\nI start the Engine using `Anoma.Node.Router.Engine` with the base settings\nfrom the ROuter. As a server, I start it as a new child to the router\nsupervisor.","ref":"Anoma.Node.Router.html#start_engine/4"},{"type":"function","title":"Arguments - Anoma.Node.Router.start_engine/4","doc":"- `router` - the Router\n- `module` - the module we wish to start as an engine\n- `arg` - the argument to startup the engine with\n- `options` - the Options specified by `engine_options()`","ref":"Anoma.Node.Router.html#start_engine/4-arguments"},{"type":"function","title":"Options - Anoma.Node.Router.start_engine/4","doc":"- `id` - An already created ID for the node. This can be an external\nor internal ID.","ref":"Anoma.Node.Router.html#start_engine/4-options"},{"type":"function","title":"Anoma.Node.Router.start_link/1","doc":"","ref":"Anoma.Node.Router.html#start_link/1"},{"type":"function","title":"Anoma.Node.Router.start_supervisor/2","doc":"","ref":"Anoma.Node.Router.html#start_supervisor/2"},{"type":"function","title":"Anoma.Node.Router.stop/1","doc":"I do nothing.","ref":"Anoma.Node.Router.html#stop/1"},{"type":"function","title":"Anoma.Node.Router.stop_engine/3","doc":"I forcibly stop an engine by calling `terminate_child/2`.\n\nTODO, please try to be more friendly to the engine, try to send a\n`:shutdown` and waiting.","ref":"Anoma.Node.Router.html#stop_engine/3"},{"type":"function","title":"Example - Anoma.Node.Router.stop_engine/3","doc":"> node = ENode.fresh_full_node(...)\n> worker_zero = wait_for_tx(node.mempool, {:kv, zero}, 5000).addr\n> Router.stop_engine(node.router, worker_zero)","ref":"Anoma.Node.Router.html#stop_engine/3-example"},{"type":"type","title":"Anoma.Node.Router.addr/0","doc":"I am the type of an Engine address.","ref":"Anoma.Node.Router.html#t:addr/0"},{"type":"type","title":"Anoma.Node.Router.engine_options/0","doc":"I am the type of Engine identification.","ref":"Anoma.Node.Router.html#t:engine_options/0"},{"type":"type","title":"Options - Anoma.Node.Router.engine_options/0","doc":"- `{:id, Id.t()}` - Identify the engine by its full Anoma ID.\n- `{:id, Id.Extern.t()}` - Identify the engine by its external ID.\n- `{:supervisor, Supervisor.supervisor}` - Identify as supervisor.\n- `{:supervisor_mod, atom()}` - Identify as supervisor given a name.","ref":"Anoma.Node.Router.html#t:engine_options/0-options"},{"type":"type","title":"Anoma.Node.Router.t/0","doc":"I am the type of the Anoma Router. I contain all necessary information\nfor coordination of the Anoma network, including all registered local\nengines, topics, subscriptions, the message queues, message counter, as\nwell as local identification information.","ref":"Anoma.Node.Router.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Router.t/0","doc":"- `:local_engines` - The map of local engines external IDs to their full\n                     IDs alongside their global process identifications.\n- `:topic_table` - The map of local topic external IDs to the set of their\n                   subscribers.\n                   Default: %{}\n- `:waiting_engines` - Map whose keys are external IDs of engines who make\n                       a call and whose values are the external ID to whom\n                       the message gets sent to alongside the message\n                       counter.\n                       Default : %{}\n- `:max_call_id` - The latest message counter.\n                   Default: 0\n- `:local_engine_subs` - Similar to `:topic_table` but for local engine\n                         addresses and the values are individual external\n                         IDs.\n                         Default: %{}\n- `:id` - Router external ID.\n- `:internal_id` - Full Router Anoma ID.\n- `:addr` - Router Address.\n- `:supervisor` - Supervisor name.\n- `:transport` - Name of the used Transport.\n- `:msg_queue` - Map of IDs to the list of pending messages.\n                 Default: %{}\n- `:logger` - The Logger Engine address for Event keeping.","ref":"Anoma.Node.Router.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Router.Addr","doc":"I am a module providing address information for the Engine and Node\nnetworking used by the Router.\n\nThe server, if known, is a local actor which can receive it directly;\notherwise, the message will be sent via the central router.\n\nIf the server is known, but the id is not, then this is a local-only\nengine, which can only talk to other local engines.","ref":"Anoma.Node.Router.Addr.html"},{"type":"module","title":"Public API - Anoma.Node.Router.Addr","doc":"I provide the following public functionality:\n\n- `id/1`\n- `id!/1`\n- `server/1`\n- `server!/1`\n- `pid/1`\n- `pid!/1`\n- `noncanonical_server/1`","ref":"Anoma.Node.Router.Addr.html#module-public-api"},{"type":"function","title":"Anoma.Node.Router.Addr.id/1","doc":"I am an ID printing function.","ref":"Anoma.Node.Router.Addr.html#id/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Router.Addr.id/1","doc":"- `id(%Id.Extern{})` - If I match on an external identity, I print it.\n- `id(%Addr{id: id})` - If I match on an Address struct with an `id`\n                        field, I print said field\n- `id(x)` when is_pid(x) or is_atom(x) - If I match on a PID or atom, I\n                                         print nothing.","ref":"Anoma.Node.Router.Addr.html#id/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Router.Addr.id!/1","doc":"I am a function printing IDs of an address with a guarded side-effect.\n\nI use `id/1` on an address and print an error message if appropriate ID\ndoes not exist.","ref":"Anoma.Node.Router.Addr.html#id!/1"},{"type":"function","title":"Anoma.Node.Router.Addr.noncanonical_server/1","doc":"I return some Process destination without attempting to canonicalize the\nresult, that is, I may return a PID.","ref":"Anoma.Node.Router.Addr.html#noncanonical_server/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Router.Addr.noncanonical_server/1","doc":"- `noncanonical_server(%Id.Extern{})` - No server, so I print nil.\n- `noncanonical_server(%Addr{server: server})` - If an address has a\n                                                 server I print it.\n- `noncanonical_server(server)` when is_atom(server) - I print the server\n                                                      name as given.\n- `noncanonical_server(pid)` when is_pid(pid) - I print the pid.","ref":"Anoma.Node.Router.Addr.html#noncanonical_server/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Router.Addr.pid/1","doc":"I am a function finding an associated PID to an address.\n\nGiven an address I feed it to `noncanonical_server`. In case the returned\nvalue is a PID, I print it. If I get the server name, I use\n`Process.whereis/1` to search for its PID.\n\nIf `nil` is returned, I print `nil`.","ref":"Anoma.Node.Router.Addr.html#pid/1"},{"type":"function","title":"Anoma.Node.Router.Addr.pid!/1","doc":"I am a function printing PIDs of an address with a guarded side-effect.\n\nI use `pid/1` on an address and print an error message if appropriate PID\ndoes not exist.","ref":"Anoma.Node.Router.Addr.html#pid!/1"},{"type":"function","title":"Anoma.Node.Router.Addr.server/1","doc":"I am a function printing the server of the given Address attempting to\nfind its canonical registered name.\n\nGiven an address, I use `noncanonical_server/1` to see its associated pid\nor name. If I get a pid then I print the name of the process associated\nwith said pid by checking Erlang's `process_info/2` in case there is any,\notherwise returning the original PID.\n\nElse, I print the returned value (`nil`).","ref":"Anoma.Node.Router.Addr.html#server/1"},{"type":"function","title":"Anoma.Node.Router.Addr.server!/1","doc":"I am a function printing servers of an address with a guarded side-effect.\n\nI use `server/1` on an address and print an error message if appropriate\nID does not exist.","ref":"Anoma.Node.Router.Addr.html#server!/1"},{"type":"type","title":"Anoma.Node.Router.Addr.t/0","doc":"I am the type for general process identifications.\n\nI possess the minimal information needed to send some agent a message\nthrough the Anoma networking structure.","ref":"Anoma.Node.Router.Addr.html#t:t/0"},{"type":"type","title":"Options - Anoma.Node.Router.Addr.t/0","doc":"- `pid()` - The raw PID\n- `atom()` - The registered name\n- `Id.Extern.t()` - The Anoma identification\n- ` %Addr\n    {\n     id: Id.Extern.t(),\n     server: Process.dest()\n     }`  - The full address structure with its Anoma ID and server.","ref":"Anoma.Node.Router.Addr.html#t:t/0-options"},{"type":"behaviour","title":"Anoma.Node.Router.Engine","doc":"I am the general Engine module.\n\nI possess info on how all Engines are set up and process messages through\nthe Router. Moreover, I provide access to Engine-wide API.\n\nNote other that the coordination info, such as a Router address and\nmodule name of an engine instance, I provide an actual storage of an\nEngine state and all state transformations correspond to the changes one\ncan observe in my code.","ref":"Anoma.Node.Router.Engine.html"},{"type":"behaviour","title":"Public API - Anoma.Node.Router.Engine","doc":"I provide the following public functionality:\n\n- `get_state/1`\n- `get_router/1`\n- `child_spec/1`\n- `terminate/2`","ref":"Anoma.Node.Router.Engine.html#module-public-api"},{"type":"function","title":"Anoma.Node.Router.Engine.child_spec/1","doc":"I am an Engine-wide child specification function.\n\nGiven a tuple with router, module, ID, argument information, I call the\n`child_spec/1` function of the specified module and then merge with it\nbase information where the start info gets provided from the supplied\narguments.","ref":"Anoma.Node.Router.Engine.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Router.Engine.get_router/1","doc":"I am an Engine-wide function for getting the router address associated\nwith the given Engine.\n\nI provide it by simply dumping the `:router` field of the associated\nEngine server.","ref":"Anoma.Node.Router.Engine.html#get_router/1"},{"type":"function","title":"Anoma.Node.Router.Engine.get_state/1","doc":"I am an Engine-wide function for getting the current Engine state.\n\nGiven an address of an Engine, I simply dump the state associated with it\nstored in the Engine structure associated with the given server name.","ref":"Anoma.Node.Router.Engine.html#get_state/1"},{"type":"callback","title":"Anoma.Node.Router.Engine.handle_call/3","doc":"","ref":"Anoma.Node.Router.Engine.html#c:handle_call/3"},{"type":"callback","title":"Anoma.Node.Router.Engine.handle_cast/3","doc":"","ref":"Anoma.Node.Router.Engine.html#c:handle_cast/3"},{"type":"function","title":"Anoma.Node.Router.Engine.handle_continue/2","doc":"","ref":"Anoma.Node.Router.Engine.html#handle_continue/2"},{"type":"function","title":"Anoma.Node.Router.Engine.init/1","doc":"I am an Engine instance initialization function. I setup the initial\nstate of an Engine structure based on the state of an actual Engine\ninstance.\n\nI first cast a message to initialize a local engine to the connected\nrouter, then store the engine ID, server, and router information in the\nProcess dictionary.\n\nAfterwards, I call the actual (module) Engine instance initialization\nfunction, and put it as the initial state alongside the router and module\ninformation directly provided on startup.","ref":"Anoma.Node.Router.Engine.html#init/1"},{"type":"function","title":"Anoma.Node.Router.Engine.start_link/1","doc":"I am the starting function for an Engine instance.\n\nI create an appropriate server name using `Router.process_name` with the\nsupplied module name and Anoma ID, launching a GenServer with said name\nafterwards.","ref":"Anoma.Node.Router.Engine.html#start_link/1"},{"type":"function","title":"Anoma.Node.Router.Engine.terminate/2","doc":"I am an engine termination function.\n\nI provide the main functionality to shut down an engine.\n\nI first use the GenServer functionality to route a message to clean up\nthe local engine info stored inside the specified Router and then stop\nthe Engine process with a given reason.","ref":"Anoma.Node.Router.Engine.html#terminate/2"},{"type":"type","title":"Anoma.Node.Router.Engine.from/0","doc":"I am the type designating the Address of where the message got sent from.","ref":"Anoma.Node.Router.Engine.html#t:from/0"},{"type":"type","title":"Anoma.Node.Router.Engine.t/0","doc":"I am the type of an Engine as seen from the Router on the Anoma\nnetworking layer.","ref":"Anoma.Node.Router.Engine.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Router.Engine.t/0","doc":"- `:router_addr` - The address of the Router that the Engine is\n                   connected to.\n- `:module` - The module name of the Engine.\n- `:module_state` - The current state of an Engine instance.","ref":"Anoma.Node.Router.Engine.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport","doc":"I am the Transport Engine.\n\nI implement the transport layer for communication between nodes. Connections\nbetween nodes are established by means of a two-step handshake protocol.","ref":"Anoma.Node.Transport.html"},{"type":"module","title":"Public API - Anoma.Node.Transport","doc":"I provide the following public functionality:\n- `start_server/2`\n- `learn_node/3`\n- `learn_engine/3`\n- `new_connection/2`\n- `disconnect/2`\n- `send/3`\n- `receive_chunk/2`","ref":"Anoma.Node.Transport.html#module-public-api"},{"type":"function","title":"Anoma.Node.Transport.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.disconnected/2","doc":"","ref":"Anoma.Node.Transport.html#disconnected/2"},{"type":"function","title":"Anoma.Node.Transport.handle_cast/3","doc":"","ref":"Anoma.Node.Transport.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Transport.init/1","doc":"","ref":"Anoma.Node.Transport.html#init/1"},{"type":"function","title":"Anoma.Node.Transport.learn_engine/3","doc":"I notify the Transport Engine that the specified engine lives on the\nspecified node.","ref":"Anoma.Node.Transport.html#learn_engine/3"},{"type":"function","title":"Anoma.Node.Transport.learn_node/3","doc":"I notify the Transport Engine that the node specified by the given public id\ncan be reached through the specified transport address.\n\nIf there are pending outgoing messages addressed to the node, I try to\ninitiate a new connection to the node.","ref":"Anoma.Node.Transport.html#learn_node/3"},{"type":"function","title":"Anoma.Node.Transport.lookup_server/2","doc":"I locate a given transport server, taking the specified address","ref":"Anoma.Node.Transport.html#lookup_server/2"},{"type":"function","title":"Anoma.Node.Transport.new_connection/2","doc":"I notify the Transport Engine that you, a local engine, are now managing a new\nincoming connection of the specified type.","ref":"Anoma.Node.Transport.html#new_connection/2"},{"type":"function","title":"Anoma.Node.Transport.receive_chunk/2","doc":"I notify the Transport Engine that the given chunk of data has been received.\n\nI am normally called by a Transport Connection instance.","ref":"Anoma.Node.Transport.html#receive_chunk/2"},{"type":"function","title":"Anoma.Node.Transport.send/3","doc":"I send the specified message to the node with the specified id.","ref":"Anoma.Node.Transport.html#send/3"},{"type":"function","title":"Anoma.Node.Transport.start_server/2","doc":"I try to start a new transport server listening on the specified address.\n\nIf a new transport server fails to start, the Transport Engine state does not\nchange.","ref":"Anoma.Node.Transport.html#start_server/2"},{"type":"function","title":"Anoma.Node.Transport.transport_type/1","doc":"I return transport type of the given transport address.","ref":"Anoma.Node.Transport.html#transport_type/1"},{"type":"type","title":"Anoma.Node.Transport.listen_addr/0","doc":"I am a listener address type.","ref":"Anoma.Node.Transport.html#t:listen_addr/0"},{"type":"type","title":"Options - Anoma.Node.Transport.listen_addr/0","doc":"- `:tcp` - I provide host and port number for TCP socket.\n- `:unix` - I provide file path for Unix socket.","ref":"Anoma.Node.Transport.html#t:listen_addr/0-options"},{"type":"type","title":"Anoma.Node.Transport.t/0","doc":"I am the type of the Transport Engine.","ref":"Anoma.Node.Transport.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.t/0","doc":"- `:router` - The address of the Router Engine that the Transport Engine\n  instance serves to.\n- `:logger` - The Logger Engine address. Enforced: false.\n- `:node_internal_id` - Id of this node.\n- `:transport_internal_id` - Id of the Transport Engine.\n- `:connection_pool` - The supervisor which manages the connection pool that\n  the TCPConnection Engine instance belongs to.\n- `:node_connections` - For every current node connection, maps the\n  correspondent id to their address. Default: empty.\n- `:connection_states` - Maps current connections to their respective\n  connection states. Default: empty.\n- `:pending_outgoing_messages` - For every node, to which we have not\n  established a connection yet, store a queue of messages addressed to the node.\n  Default: empty.\n- `:pending_outgoing_engine_messages` - For every engine, whose node\n  location is not known yet, store a queue of messages addressed to the\n  engine. Default: empty.\n- `:servers` - Stores a set of transport servers that the Transport Engine\n  is currently running. Every transport server is mapped to an external\n  transport address, by which messages may reach the Engine through this\n  server. Default: empty.\n- `:known_nodes` - Maps every known node (indexed by its public id) to a\n  set of transport addresses through which the node can be reached.\n  Default: empty.\n- `:known_engines` - Stores a set of known engines by their public id: every\n  engine id is mapped to a public id of a node that the engine belongs to.\n  Default: empty.","ref":"Anoma.Node.Transport.html#t:t/0-fields"},{"type":"type","title":"Anoma.Node.Transport.transport_addr/0","doc":"I am a transport address type.","ref":"Anoma.Node.Transport.html#t:transport_addr/0"},{"type":"type","title":"Options - Anoma.Node.Transport.transport_addr/0","doc":"- `:tcp` - I provide host and port number for TCP socket.\n- `:unix` - I provide file path for Unix socket.","ref":"Anoma.Node.Transport.html#t:transport_addr/0-options"},{"type":"type","title":"Anoma.Node.Transport.transport_type/0","doc":"I am a transport type.","ref":"Anoma.Node.Transport.html#t:transport_type/0"},{"type":"type","title":"Option - Anoma.Node.Transport.transport_type/0","doc":"- `:tcp` - TCP socket\n- `:unix` - Unix socket","ref":"Anoma.Node.Transport.html#t:transport_type/0-option"},{"type":"module","title":"Anoma.Node.Transport.Connection","doc":"I am the Transport Connection module.\n\nI am an abstract interface that connection implementations obey.","ref":"Anoma.Node.Transport.Connection.html"},{"type":"module","title":"Public API - Anoma.Node.Transport.Connection","doc":"I provide the following public functionality:\n\n- `send/2`\n- `shutdown/1`","ref":"Anoma.Node.Transport.Connection.html#module-public-api"},{"type":"function","title":"Anoma.Node.Transport.Connection.send/2","doc":"I send messages to the given connection.","ref":"Anoma.Node.Transport.Connection.html#send/2"},{"type":"function","title":"Anoma.Node.Transport.Connection.shutdown/1","doc":"I asynchronously initiate the connection shutdown.","ref":"Anoma.Node.Transport.Connection.html#shutdown/1"},{"type":"module","title":"Anoma.Node.Transport.ConnectionState","doc":"","ref":"Anoma.Node.Transport.ConnectionState.html"},{"type":"type","title":"Anoma.Node.Transport.ConnectionState.t/0","doc":"I am the type of connection state.\n\nI keep information about connection from Transport point of view.","ref":"Anoma.Node.Transport.ConnectionState.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.ConnectionState.t/0","doc":"- `:type` - Type of connection: TCP socket or Unix socket.\n- `:connection` - Address of the correspondent that I establish connection to.\n- `:state` - Connection status.\n- `:id` - Public id of the correspondent node.\n- `:partial_message` - Incomplete message received so far.\n- `:outgoing_nonce` - Outgoing nonce used in the initial handshake message.\n- `:incoming_nonce` - Incoming nonce used in the correspondent's initial\n  handshake message.","ref":"Anoma.Node.Transport.ConnectionState.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Transport.Server","doc":"I am the Transport Server module.\n\nI am an abstract interface that server implementations obey.","ref":"Anoma.Node.Transport.Server.html"},{"type":"module","title":"Anoma.Node.Transport.Supervisor","doc":"I am the Transport Supervisor module.\n\nI serve as a supervision pool for various transport connections.\nMy instance is created by the Anoma Node.","ref":"Anoma.Node.Transport.Supervisor.html"},{"type":"function","title":"Anoma.Node.Transport.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.Supervisor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.Supervisor.init/1","doc":"","ref":"Anoma.Node.Transport.Supervisor.html#init/1"},{"type":"function","title":"Anoma.Node.Transport.Supervisor.start_link/1","doc":"","ref":"Anoma.Node.Transport.Supervisor.html#start_link/1"},{"type":"module","title":"Anoma.Node.Transport.TCPConnection","doc":"I am TCPConnection Engine.\n\nI manage an individual TCP connection and stream.\n\nI can run in two modes: either I can act as a client, initiating a connection\nto a server, or as a listener, waiting to accept and then accepting a\nconnection on a server.\nIn the latter case, since accepting the connection marks me as its owner and\nhandoff is complicated, I start up a new listener once I accept a connection.","ref":"Anoma.Node.Transport.TCPConnection.html"},{"type":"module","title":"How I work - Anoma.Node.Transport.TCPConnection","doc":"A good general overview of how I work at a high level with my\nenvironment can be seen in `Anoma.Node.Transport.TCPServer`.\n\nThe diagrams I'll include in my documentation are more focused on my D2D inner workings\n\n```mermaid\ngraph LR;\n\n%% Role Setup\nTCPConnection:::TCPConnection\nChild_Process(Child Connection):::Listener\nListener1(A TCP Listener Node):::Listener\nTransport(Our Transport):::Transport\n\n\n%% Note Relationship between TCPConnection and the outside\n:accept_connection -- start_listener --- Child_Process\nTransport -- handshake ---Listener1\n\n\nsubgraph TCPConnection\n  direction TB\n  :accept_connection:::Listener\n  :init_connection:::Client\n\n  init -- is a Listener -->:accept_connection\n  init -- is a Client -->:init_connection\n\n  :accept_connection -- \":gen_tcp.accept\" --- :accept_connection\n\n\n  :accept_connection & :init_connection -- failure --> sd(Shut down)\n  :accept_connection & :init_connection -- successful --> Standby\n\nend\n\n\n%% Note Relationship between TCPConnection and the outside\n:init_connection -- \":gen_tcp.connect\" --- Listener1\n:init_connection -- begin handshake ---Transport\n\n\n\n%% Styling\nclassDef Listener      fill:#add8e6\nclassDef TCPConnection fill:#fff9ca\nclassDef Client        fill:#e6add8\nclassDef Transport     fill:#d8e6ad\n\n\n%% Linking\n\nclick Transport \"https://anoma.github.io/anoma/Anoma.Node.Transport.html\"\nclick init \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html#init/1\"\nclick Child_Process \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\"\nclick :init_connection \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\"\nclick :accept_connection \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\"\nclick Listener1 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\"\n```\n\nThis diagram uses the following Color Codes:\n1. Blue Nodes represent TCP Connections running in the listening mode.\n2. Purple Node represents TCP Connection running in the client mode.\n3. Green Nodes is the Transport Server.\n\nWe can see that my behavior differs drastically if I'm in the client\nmode or a listening mode.\n\nIf I'm listening then I'll block calling `:gen_tcp.accept/1`, if\nthat works, then we create another\n`Anoma.Node.Transport.TCPConnection`. If not we shutdown\n\nLikewise for the client behavior, we try using\n`:gen_tcp.connect/3`. If this fails then we shutdown.\n\nIf we do successfully connect, then we begin the handshake process,\nwhich is best explained in a diagram in `Anoma.Node.Transport`.","ref":"Anoma.Node.Transport.TCPConnection.html#module-how-i-work"},{"type":"function","title":"Anoma.Node.Transport.TCPConnection.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.TCPConnection.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.TCPConnection.handle_cast/3","doc":"","ref":"Anoma.Node.Transport.TCPConnection.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Transport.TCPConnection.handle_continue/2","doc":"","ref":"Anoma.Node.Transport.TCPConnection.html#handle_continue/2"},{"type":"function","title":"Anoma.Node.Transport.TCPConnection.init/1","doc":"I am the initialization function for TCPConnection Engine.","ref":"Anoma.Node.Transport.TCPConnection.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Transport.TCPConnection.init/1","doc":"- `init({:client, router, transport, address, connection_pool, logger})` -\n  create a TCP connection as a client.\n\n- `init({:listener, router, transport, listener, connection_pool, logger})` -\n  create a TCP connection as a listener.","ref":"Anoma.Node.Transport.TCPConnection.html#init/1-pattern-matching-variations"},{"type":"type","title":"Anoma.Node.Transport.TCPConnection.t/0","doc":"I am the type of the TCPConnection Engine.","ref":"Anoma.Node.Transport.TCPConnection.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.TCPConnection.t/0","doc":"- `:router` - The address of the Router Engine that the Transport Engine\n  instance serves to.\n- `:transport` - The address of the Transport server managing the\n  connection.\n- `:connection_pool` - The supervisor which manages the connection pool that\n  the TCPConnection Engine instance belongs to.\n- `:mode` - The mode of the connection: client or listener.\n- `:listener` - The listening socket that accepts incoming connection\n  requests. Must be provided in the listener mode. Default: nil\n- `:conn` - Socket of the established connection for the listener mode.\n  Initially, nil. Filled in as soon as a connection is established.\n- `:logger` - The Logger Engine address. Enforced: false.","ref":"Anoma.Node.Transport.TCPConnection.html#t:t/0-fields"},{"type":"type","title":"Anoma.Node.Transport.TCPConnection.tcp_connect_result/0","doc":"I am the type of :gen_tcp.connect() result.","ref":"Anoma.Node.Transport.TCPConnection.html#t:tcp_connect_result/0"},{"type":"module","title":"Anoma.Node.Transport.TCPServer","doc":"I am TCPServer Engine.\n\nI open a listening TCP connection in server mode on the specified address.","ref":"Anoma.Node.Transport.TCPServer.html"},{"type":"module","title":"How I work - Anoma.Node.Transport.TCPServer","doc":"A good way to understand how I work is by looking at the diagram of my behavior below:\n\n```mermaid\ngraph TB;\nClient1(Client 1):::Client\nClient2(Client 2):::Client\nsubgraph Dynamic Supervisor\nTCPServer:::Server-- :start_listener---Conn1\nConn1(Listener 1):::Connection-- start_listener---Conn2\nConn2(Listener 2):::Connection-- start_listener---Conn3\nConn3(Listener 3):::Connection-- :gen_tcp.accept---Conn3\nend\nClient1-. \":gen_tcp.connect()\" .->Conn1\nClient2-. \":gen_tcp.connect()\" .->Conn2\n\nclassDef Server      fill:#d8e6ad\nclassDef Connection  fill:#add8e6\nclassDef Client      fill:#e6add8\n\nclick TCPServer \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPServer.html\" \"Anoma.Node.Transport.TCPServer\"\n\nclick Conn1 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\" \"Anoma.Node.Transport.TCPConnection\"\nclick Conn2 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\" \"Anoma.Node.Transport.TCPConnection\"\nclick Conn3 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\" \"Anoma.Node.Transport.TCPConnection\"\n\nclick Client1 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\" \"Anoma.Node.Transport.TCPConnection\"\nclick Client2 \"https://anoma.github.io/anoma/Anoma.Node.Transport.TCPConnection.html\" \"Anoma.Node.Transport.TCPConnection\"\n\nclick Dynamic Supervisor \"https://anoma.github.io/anoma/Anoma.Node.Transport.Supervisor.html\"\n```\n\nThis diagram uses the following Color Codes:\n1. Blue Nodes represent TCP Connections running in the listening mode.\n2. Purple Nodes represent TCP Connections running in the client mode.\n3. Green Node is the TCP Server.\n\nHere we can see that I manage the TCP Server by spawning\n`Anoma.Node.Transport.TCPConnection` instances that other TCP Clients can\ntalk to.\n\nSee `Anoma.Node.Transport.TCPConnection` for further information on\nthe specifics for how my connections work.","ref":"Anoma.Node.Transport.TCPServer.html#module-how-i-work"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Transport.TCPServer.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.handle_continue/2","doc":"","ref":"Anoma.Node.Transport.TCPServer.html#handle_continue/2"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.init/1","doc":"","ref":"Anoma.Node.Transport.TCPServer.html#init/1"},{"type":"function","title":"Anoma.Node.Transport.TCPServer.listener/1","doc":"I expose the listener of the server","ref":"Anoma.Node.Transport.TCPServer.html#listener/1"},{"type":"type","title":"Anoma.Node.Transport.TCPServer.t/0","doc":"I am the type of the TCPServer Engine.","ref":"Anoma.Node.Transport.TCPServer.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Transport.TCPServer.t/0","doc":"- `:router` - The address of the Router Engine that the Transport Engine\n  instance serves to.\n- `:transport` - The address of the Transport server managing the server.\n- `:connection_pool` - The supervisor which manages the connection pool that\n  the TCPServer Engine instance belongs to.\n- `:listener` - The socket listening on the specified host, port.\n- `:logger` - The Logger Engine address. Enforced: false.","ref":"Anoma.Node.Transport.TCPServer.html#t:t/0-fields"},{"type":"module","title":"Anoma.RM.Trans","doc":"","ref":"Anoma.RM.Trans.html"},{"type":"function","title":"Anoma.RM.Trans.compose_pre_check/2","doc":"","ref":"Anoma.RM.Trans.html#compose_pre_check/2"},{"type":"protocol","title":"Anoma.RM.Transaction","doc":"I am the Transaction protocol.\n\nUse me when you want to write logic over transactions.\n\nTransactions practically speaking be `Noun.Nounable`","ref":"Anoma.RM.Transaction.html"},{"type":"function","title":"Anoma.RM.Transaction.cm_tree/2","doc":"","ref":"Anoma.RM.Transaction.html#cm_tree/2"},{"type":"function","title":"Anoma.RM.Transaction.commitments/1","doc":"","ref":"Anoma.RM.Transaction.html#commitments/1"},{"type":"function","title":"Anoma.RM.Transaction.compose/2","doc":"I compose two transactions into a new transaction","ref":"Anoma.RM.Transaction.html#compose/2"},{"type":"function","title":"Anoma.RM.Transaction.nullifiers/1","doc":"","ref":"Anoma.RM.Transaction.html#nullifiers/1"},{"type":"function","title":"Anoma.RM.Transaction.resource_existence_check/2","doc":"","ref":"Anoma.RM.Transaction.html#resource_existence_check/2"},{"type":"function","title":"Anoma.RM.Transaction.storage_commitments/1","doc":"","ref":"Anoma.RM.Transaction.html#storage_commitments/1"},{"type":"function","title":"Anoma.RM.Transaction.storage_nullifiers/1","doc":"","ref":"Anoma.RM.Transaction.html#storage_nullifiers/1"},{"type":"function","title":"Anoma.RM.Transaction.verify/1","doc":"","ref":"Anoma.RM.Transaction.html#verify/1"},{"type":"type","title":"Anoma.RM.Transaction.t/0","doc":"All the types that implement this protocol.","ref":"Anoma.RM.Transaction.html#t:t/0"},{"type":"module","title":"Anoma.Serialise","doc":"","ref":"Anoma.Serialise.html"},{"type":"function","title":"Anoma.Serialise.from_msgpack/1","doc":"","ref":"Anoma.Serialise.html#from_msgpack/1"},{"type":"function","title":"Anoma.Serialise.pack/1","doc":"","ref":"Anoma.Serialise.html#pack/1"},{"type":"function","title":"Anoma.Serialise.to_msgpack/1","doc":"","ref":"Anoma.Serialise.html#to_msgpack/1"},{"type":"function","title":"Anoma.Serialise.unpack/1","doc":"","ref":"Anoma.Serialise.html#unpack/1"},{"type":"module","title":"Anoma.Serializer","doc":"I aspire to give a language independent serialization format for any\nerlang/elixir type. Further, I handle hashing and digesting the\nterms as well!\n\nFor the time being,  just use the basic erlang only technique,\nplease improve me!","ref":"Anoma.Serializer.html"},{"type":"function","title":"Anoma.Serializer.deserialize/1","doc":"I `deserialize` the given object back into an erlang term.","ref":"Anoma.Serializer.html#deserialize/1"},{"type":"function","title":"Anoma.Serializer.digest/1","doc":"","ref":"Anoma.Serializer.html#digest/1"},{"type":"function","title":"Anoma.Serializer.serialize/1","doc":"","ref":"Anoma.Serializer.html#serialize/1"},{"type":"function","title":"Anoma.Serializer.sign/2","doc":"I `deserialize` the given object back into an erlang term.","ref":"Anoma.Serializer.html#sign/2"},{"type":"function","title":"Anoma.Serializer.verify/3","doc":"","ref":"Anoma.Serializer.html#verify/3"},{"type":"type","title":"Anoma.Serializer.private_key/0","doc":"","ref":"Anoma.Serializer.html#t:private_key/0"},{"type":"type","title":"Anoma.Serializer.public_key/0","doc":"","ref":"Anoma.Serializer.html#t:public_key/0"},{"type":"module","title":"Anoma.ShieldedResource","doc":"I am a shielded resource.","ref":"Anoma.ShieldedResource.html"},{"type":"function","title":"Anoma.ShieldedResource.commitment/1","doc":"A commitment to the given resource.","ref":"Anoma.ShieldedResource.html#commitment/1"},{"type":"function","title":"Anoma.ShieldedResource.nullifier/1","doc":"The nullifier of the given resource.","ref":"Anoma.ShieldedResource.html#nullifier/1"},{"type":"function","title":"Anoma.ShieldedResource.random/1","doc":"Randomizes the rseed of a resource.","ref":"Anoma.ShieldedResource.html#random/1"},{"type":"function","title":"Anoma.ShieldedResource.set_nonce/2","doc":"Set the nonce of a resource, the nonce of output resource comes from the\nnullifer of input recource in the compliance proof.","ref":"Anoma.ShieldedResource.html#set_nonce/2"},{"type":"type","title":"Anoma.ShieldedResource.t/0","doc":"","ref":"Anoma.ShieldedResource.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ComplianceOutput","doc":"I represent a resource's output.","ref":"Anoma.ShieldedResource.ComplianceOutput.html"},{"type":"function","title":"Anoma.ShieldedResource.ComplianceOutput.from_public_input/1","doc":"","ref":"Anoma.ShieldedResource.ComplianceOutput.html#from_public_input/1"},{"type":"type","title":"Anoma.ShieldedResource.ComplianceOutput.t/0","doc":"","ref":"Anoma.ShieldedResource.ComplianceOutput.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.PartialTransaction","doc":"I am a shielded resource machine partial transaction.","ref":"Anoma.ShieldedResource.PartialTransaction.html"},{"type":"function","title":"Anoma.ShieldedResource.PartialTransaction.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.PartialTransaction.verify/1","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#verify/1"},{"type":"type","title":"Anoma.ShieldedResource.PartialTransaction.t/0","doc":"","ref":"Anoma.ShieldedResource.PartialTransaction.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ProofRecord","doc":"I am a proof record for a shielded resource.","ref":"Anoma.ShieldedResource.ProofRecord.html"},{"type":"function","title":"Anoma.ShieldedResource.ProofRecord.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.ProofRecord.generate_compliance_proof/1","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#generate_compliance_proof/1"},{"type":"type","title":"Anoma.ShieldedResource.ProofRecord.t/0","doc":"","ref":"Anoma.ShieldedResource.ProofRecord.html#t:t/0"},{"type":"module","title":"Anoma.ShieldedResource.ShieldedTransaction","doc":"I am a shielded resource machine transaction.","ref":"Anoma.ShieldedResource.ShieldedTransaction.html"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.finalize/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#finalize/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.from_noun/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#from_noun/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.get_binding_messages/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#get_binding_messages/1"},{"type":"function","title":"Anoma.ShieldedResource.ShieldedTransaction.get_compliance_outputs/1","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#get_compliance_outputs/1"},{"type":"type","title":"Anoma.ShieldedResource.ShieldedTransaction.t/0","doc":"","ref":"Anoma.ShieldedResource.ShieldedTransaction.html#t:t/0"},{"type":"module","title":"Anoma.Symbol","doc":"I am module that provides utilities over symbols","ref":"Anoma.Symbol.html"},{"type":"module","title":"Public API - Anoma.Symbol","doc":"- `append/2`","ref":"Anoma.Symbol.html#module-public-api"},{"type":"function","title":"Anoma.Symbol.append/2","doc":"I append two values that implement `to_string/1` and returns an appended symbol","ref":"Anoma.Symbol.html#append/2"},{"type":"type","title":"Anoma.Symbol.s/0","doc":"I am either a string or an atom","ref":"Anoma.Symbol.html#t:s/0"},{"type":"module","title":"Anoma.System.Directories","doc":"I provide out utilities for ensuring user Data, Config,\netc. directories are properly setup for the host operating system.\n\nPlease use me when trying to write to user directories.","ref":"Anoma.System.Directories.html"},{"type":"function","title":"Anoma.System.Directories.configuration/2","doc":"I provide a proper translation from a user directory to the\ncorresponding system configuration directory.","ref":"Anoma.System.Directories.html#configuration/2"},{"type":"function","title":"Parameters - Anoma.System.Directories.configuration/2","doc":"- `file_path` - the path given by the user\n- `env` (optional) - the system environment. It defaults to the\n  application environment. The `:test` environment uses the local\n  directory instead of the system directory","ref":"Anoma.System.Directories.html#configuration/2-parameters"},{"type":"function","title":"Returns - Anoma.System.Directories.configuration/2","doc":"The correct environment which to save configuration details","ref":"Anoma.System.Directories.html#configuration/2-returns"},{"type":"function","title":"Anoma.System.Directories.data/2","doc":"I provide a proper translation from a user directory to the\ncorresponding system data directory.","ref":"Anoma.System.Directories.html#data/2"},{"type":"function","title":"Parameters - Anoma.System.Directories.data/2","doc":"- `file_path` - the path given by the user\n- `env` (optional) - the system environment. It defaults to the\n  application environment. The `:test` environment uses the local\n  directory instead of the system directory","ref":"Anoma.System.Directories.html#data/2-parameters"},{"type":"function","title":"Returns - Anoma.System.Directories.data/2","doc":"The correct environment which to save data details","ref":"Anoma.System.Directories.html#data/2-returns"},{"type":"module","title":"Anoma.Transaction","doc":"I represent an Anoma Transaction at the execution level.\n\nNamely I contain the info on how the information gets processed at the\nengine level. See `Resource.Transaction` for the transaction\nspecification at the level of the Resource Machine.","ref":"Anoma.Transaction.html"},{"type":"function","title":"Anoma.Transaction.addr/1","doc":"","ref":"Anoma.Transaction.html#addr/1"},{"type":"function","title":"Anoma.Transaction.id/1","doc":"","ref":"Anoma.Transaction.html#id/1"},{"type":"function","title":"Anoma.Transaction.index/1","doc":"","ref":"Anoma.Transaction.html#index/1"},{"type":"function","title":"Anoma.Transaction.new/3","doc":"","ref":"Anoma.Transaction.html#new/3"},{"type":"function","title":"Anoma.Transaction.new_with_order/3","doc":"I create a new transaction structure with order field but no transaction\ncode.\n\nMy main purpose is to be used for testing. Generally, the index of the\ntransaction comes added to the structure bearing transaction backend code.","ref":"Anoma.Transaction.html#new_with_order/3"},{"type":"function","title":"Anoma.Transaction.transaction/1","doc":"","ref":"Anoma.Transaction.html#transaction/1"},{"type":"type","title":"Anoma.Transaction.execution/0","doc":"","ref":"Anoma.Transaction.html#t:execution/0"},{"type":"type","title":"Anoma.Transaction.t/0","doc":"I am the type of the Anoma Transaction at the Engine level.\n\nI contain info necessary for the Mempool, Ordering, and Workers to\nproperly go through a transaction lifecycle.\n\nA transaction structure may not contain transaction code or\nindex information.","ref":"Anoma.Transaction.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Transaction.t/0","doc":"- `:index` - An order given to the transaction by the Ordering Engine.\n             Enforced: false\n- `:id` - The ID of a transaction. Usually a random integer.\n- `:addr` - The address of the Worker responsible for the transaction.\n- `:transaction` - The backend transaction code the Worker uses.","ref":"Anoma.Transaction.html#t:t/0-fields"},{"type":"module","title":"EventBroker","doc":"I am the EventBroker Application Module.\n\nI startup the PubSub system as an own OTP application. Moreover I provide\nall the API necessary for the use of the system. I contain all public\nfunctionality provided by the Broker and the Registry.","ref":"EventBroker.html"},{"type":"module","title":"Public API - EventBroker","doc":"I have the following public functionality:\n\n- `event/1`\n- `subscribe_me/1`\n- `unsubscribe_me/1`\n- `subscribe/2`\n- `unsubscribe/2`","ref":"EventBroker.html#module-public-api"},{"type":"function","title":"EventBroker.event/2","doc":"I am the Event Broker event function.\n\nI process any incoming events by sending them to all of Broker subscribers\nusing the `send/2` functionality.","ref":"EventBroker.html#event/2"},{"type":"function","title":"EventBroker.start/2","doc":"","ref":"EventBroker.html#start/2"},{"type":"function","title":"EventBroker.subscribe/3","doc":"I am the subscription function.\n\nGiven a PID and a list of filter specs, I ensure that all the actors\ncorresponding to each spec given in the list is launched and subscribed\nto each other in the appropriate order - e.g. given `[spec1, spec2]` I\nensure that agents implemented `spec1` and `spec2` are launched and that\nthe former is subscribed to the top broker, while the latter is subscribed\nto the former.\n\nI also do this in a minimal fashion, that is, if some starting subchain of\nfilter spec dependency has already been registered, I launch the minimal\nchain remaining to build the full dependency.\n\nNote that each filter actor is hence not only determined by the filtering\nfunctionality it has but also on the chain of dependencies it is spawned\nwith. Hence `[spec1, spec2]` corresponds to an agent different from\n`[spec2]`.\n\nAfterwards, I subscribe the given PID to the final filter agent in the\ndependency chain and register all the new agents in the map by putting\nthe filter agent PIDs as values to their dependency filter specification.\n\nIf I notice that any of the filter structures do not have an appropriate\npublic filter functionality exposed, I return the list of such modules\nback to the user and do nothing with respect to agent-spawning or\nregistration.\n\nFilter Agent spawning is handled via DynamicSupervisor.","ref":"EventBroker.html#subscribe/3"},{"type":"function","title":"EventBroker.subscribe_me/2","doc":"I am a subscription function specifically for `self()`\n\nI call `subscribe/2` where the first argument is `self()`","ref":"EventBroker.html#subscribe_me/2"},{"type":"function","title":"EventBroker.unsubscribe/3","doc":"I am the unsubscription function.\n\nGiven a PID and a list of filter specs, I get the PID of the related\nfilter agent by looking in my state, then ask it to unsubscribe the\ngiven PID from it. In case the agent has other subscribers, I return the\nbase state.\n\nOtherwise, it will shut down, prompting to recursively send unsubscription\nrequests to its parent filters and processing their termination\nappropriately in a synchronous manner.\n\nAfter all the requests have been sent and terminations recorded, I remove\nall agents which have shut down from my registry map and return `:ok`","ref":"EventBroker.html#unsubscribe/3"},{"type":"function","title":"EventBroker.unsubscribe_me/2","doc":"I am the unsubscription function specifically for `self()`\n\nI call `unsubscribe/2` where the first argument is `self()`","ref":"EventBroker.html#unsubscribe_me/2"},{"type":"type","title":"EventBroker.filter_spec_list/0","doc":"I am a filter dependency specification, I am a list of filter specs listed\nin the order in which the filter agents implementing said specs should be\nsubscribed to one another.","ref":"EventBroker.html#t:filter_spec_list/0"},{"type":"module","title":"EventBroker.Broker","doc":"I am a Broker module.\n\nI specify the behavior of the server acting as a central broker of the\nPubSub servive. My functionality is minimal. I wait for messages and\nrelay them to my subscribers.","ref":"EventBroker.Broker.html"},{"type":"function","title":"EventBroker.Broker.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Broker.html#child_spec/1"},{"type":"function","title":"EventBroker.Broker.init/1","doc":"","ref":"EventBroker.Broker.html#init/1"},{"type":"function","title":"EventBroker.Broker.start_link/1","doc":"","ref":"EventBroker.Broker.html#start_link/1"},{"type":"type","title":"EventBroker.Broker.t/0","doc":"I am the type of the Event Broker.","ref":"EventBroker.Broker.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Broker.t/0","doc":"- `:subscribers` - The set of pids showcasing subscribers.\n                   Default: Map.Set.new()","ref":"EventBroker.Broker.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Event","doc":"I am an Event module for the Event Broker.\n\nI provide the standard event format to be distributed for the PubSub\nsystem. Unless the message is in my format it does not get processed.","ref":"EventBroker.Event.html"},{"type":"macro","title":"EventBroker.Event.new_with_body/1","doc":"","ref":"EventBroker.Event.html#new_with_body/1"},{"type":"type","title":"EventBroker.Event.t/0","doc":"I am the Event type for the Event Broker.\n\nMy fields determine the overall structure of the messages.","ref":"EventBroker.Event.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Event.t/0","doc":"- `:source_module` - The module from which the message got sent.\n- `:body` - A body of the event.","ref":"EventBroker.Event.html#t:t/0-fields"},{"type":"behaviour","title":"EventBroker.Filter","doc":"I am a filter module for the Event Broker. I provide the callbacks for\nall the filters used in the PubSub system.","ref":"EventBroker.Filter.html"},{"type":"callback","title":"EventBroker.Filter.filter/2","doc":"","ref":"EventBroker.Filter.html#c:filter/2"},{"type":"module","title":"EventBroker.FilterAgent","doc":"I am a Filter Agent module.\n\nI implement the base server behavior of the spawned filter agent. In\ngeneral, I monitor subscribers of an individual filtering agent and\nsend whichever events I receive to them.","ref":"EventBroker.FilterAgent.html"},{"type":"function","title":"EventBroker.FilterAgent.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.FilterAgent.html#child_spec/1"},{"type":"function","title":"EventBroker.FilterAgent.init/1","doc":"","ref":"EventBroker.FilterAgent.html#init/1"},{"type":"function","title":"EventBroker.FilterAgent.start_link/1","doc":"","ref":"EventBroker.FilterAgent.html#start_link/1"},{"type":"type","title":"EventBroker.FilterAgent.t/0","doc":"I am the type of the Filter Agent.\n\nI contain the minimal info for a filter to work, namely the filter\nspecification to aplly to incoming messages and subscribers to send\nfiltered messages to.","ref":"EventBroker.FilterAgent.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.FilterAgent.t/0","doc":"- `:spec` - The filter specification. This is a structure of a module\n            with a public filter API for the agent to call.\n- `:subscribers` - The list of subscribers to send filtered messages to.\n                   Default: MapSet.new()","ref":"EventBroker.FilterAgent.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Filters.LessTrivial","doc":"I represent a filter which filters a message based on the value I store\nin my struct.\n\nI either always return true or always return false.","ref":"EventBroker.Filters.LessTrivial.html"},{"type":"function","title":"EventBroker.Filters.LessTrivial.filter/2","doc":"","ref":"EventBroker.Filters.LessTrivial.html#filter/2"},{"type":"type","title":"EventBroker.Filters.LessTrivial.t/0","doc":"I store a value for filtering.","ref":"EventBroker.Filters.LessTrivial.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Filters.LessTrivial.t/0","doc":"- `:value` - A boolean value.","ref":"EventBroker.Filters.LessTrivial.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Filters.SourceModule","doc":"I filter an event based on its source module.","ref":"EventBroker.Filters.SourceModule.html"},{"type":"function","title":"EventBroker.Filters.SourceModule.filter/2","doc":"","ref":"EventBroker.Filters.SourceModule.html#filter/2"},{"type":"type","title":"EventBroker.Filters.SourceModule.t/0","doc":"I store the module representing the source of a message.","ref":"EventBroker.Filters.SourceModule.html#t:t/0"},{"type":"type","title":"Field - EventBroker.Filters.SourceModule.t/0","doc":"- `:module` - A module name.","ref":"EventBroker.Filters.SourceModule.html#t:t/0-field"},{"type":"module","title":"EventBroker.Filters.Trivial","doc":"I am the trivial filter. I always return true.","ref":"EventBroker.Filters.Trivial.html"},{"type":"function","title":"EventBroker.Filters.Trivial.filter/2","doc":"","ref":"EventBroker.Filters.Trivial.html#filter/2"},{"type":"type","title":"EventBroker.Filters.Trivial.t/0","doc":"","ref":"EventBroker.Filters.Trivial.html#t:t/0"},{"type":"module","title":"EventBroker.Registry","doc":"I am the Registry for the PubSub system.\n\nI am the central registry of all the topic subscirptions and filters. I\nam responsible for spawning filter agents, (un)subscribing to them, and\nkeeping track of relations between them.","ref":"EventBroker.Registry.html"},{"type":"function","title":"EventBroker.Registry.__struct__/0","doc":"I am the type of the registered filters, matching a filter agent to its\nPID.","ref":"EventBroker.Registry.html#__struct__/0"},{"type":"function","title":"EventBroker.Registry.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Registry.html#child_spec/1"},{"type":"function","title":"EventBroker.Registry.init/1","doc":"","ref":"EventBroker.Registry.html#init/1"},{"type":"function","title":"EventBroker.Registry.start_link/1","doc":"","ref":"EventBroker.Registry.html#start_link/1"},{"type":"type","title":"EventBroker.Registry.registered_filters/0","doc":"","ref":"EventBroker.Registry.html#t:registered_filters/0"},{"type":"type","title":"EventBroker.Registry.t/0","doc":"I am the type of the Registry.\n\nMy main functionality is to keep track of all spawned filter actors.","ref":"EventBroker.Registry.html#t:t/0"},{"type":"type","title":"Fields - EventBroker.Registry.t/0","doc":"- `:supervisor` - The name of the dynamic supervisor launched on start.\n- `:registered_filters` - The map whose keys are a filter-spec dependency\nlist and whose values are PID's of filter\nagents corresponding to said lists.\nDefault: %{}","ref":"EventBroker.Registry.html#t:t/0-fields"},{"type":"module","title":"EventBroker.Supervisor","doc":"I am the EventBroker Supervisor for PubSub.\n\nI start up 3 children, namely the Broker, the Registry, and the Dynamic\nSupervisor for the filters.","ref":"EventBroker.Supervisor.html"},{"type":"function","title":"EventBroker.Supervisor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"EventBroker.Supervisor.html#child_spec/1"},{"type":"function","title":"EventBroker.Supervisor.init/1","doc":"","ref":"EventBroker.Supervisor.html#init/1"},{"type":"function","title":"EventBroker.Supervisor.start_link/1","doc":"","ref":"EventBroker.Supervisor.html#start_link/1"},{"type":"module","title":"Examples.EBlock","doc":"","ref":"Examples.EBlock.html"},{"type":"function","title":"Examples.EBlock.ablock/0","doc":"","ref":"Examples.EBlock.html#ablock/0"},{"type":"function","title":"Examples.EBlock.apub_block/0","doc":"","ref":"Examples.EBlock.html#apub_block/0"},{"type":"function","title":"Examples.EBlock.bblock/0","doc":"","ref":"Examples.EBlock.html#bblock/0"},{"type":"function","title":"Examples.EBlock.empty_block/0","doc":"","ref":"Examples.EBlock.html#empty_block/0"},{"type":"module","title":"Examples.EClient","doc":"","ref":"Examples.EClient.html"},{"type":"function","title":"Examples.EClient.cleanup/2","doc":"","ref":"Examples.EClient.html#cleanup/2"},{"type":"function","title":"Examples.EClient.get_from_other/2","doc":"","ref":"Examples.EClient.html#get_from_other/2"},{"type":"function","title":"Examples.EClient.storage_423_from_cli/2","doc":"","ref":"Examples.EClient.html#storage_423_from_cli/2"},{"type":"function","title":"Examples.EClient.sub_memexec/1","doc":"","ref":"Examples.EClient.html#sub_memexec/1"},{"type":"function","title":"Examples.EClient.unsub_memexec/1","doc":"","ref":"Examples.EClient.html#unsub_memexec/1"},{"type":"type","title":"Examples.EClient.common/0","doc":"","ref":"Examples.EClient.html#t:common/0"},{"type":"module","title":"Examples.ECommitmentTree","doc":"","ref":"Examples.ECommitmentTree.html"},{"type":"function","title":"Examples.ECommitmentTree.babylon_mnesia_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#babylon_mnesia_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.cairo_poseidon_spec/0","doc":"","ref":"Examples.ECommitmentTree.html#cairo_poseidon_spec/0"},{"type":"function","title":"Examples.ECommitmentTree.current_tree_mnesia_ct/1","doc":"This fetches the current mnesia tree storage\n\nThis value is expected to differ, and will be a fixture for other\ntests to assert about.","ref":"Examples.ECommitmentTree.html#current_tree_mnesia_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.empty_mnesia_backed_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#empty_mnesia_backed_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.lots_of_inserts_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#lots_of_inserts_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.memory_backed_ct/1","doc":"","ref":"Examples.ECommitmentTree.html#memory_backed_ct/1"},{"type":"function","title":"Examples.ECommitmentTree.sha256_32_spec/0","doc":"","ref":"Examples.ECommitmentTree.html#sha256_32_spec/0"},{"type":"function","title":"Examples.ECommitmentTree.tree_storage/0","doc":"","ref":"Examples.ECommitmentTree.html#tree_storage/0"},{"type":"module","title":"Examples.EConfiguration","doc":"","ref":"Examples.EConfiguration.html"},{"type":"function","title":"Examples.EConfiguration.dumper_config/1","doc":"","ref":"Examples.EConfiguration.html#dumper_config/1"},{"type":"module","title":"Examples.ECrypto","doc":"","ref":"Examples.ECrypto.html"},{"type":"function","title":"Examples.ECrypto.alice/0","doc":"","ref":"Examples.ECrypto.html#alice/0"},{"type":"function","title":"Examples.ECrypto.alice_rsa/0","doc":"","ref":"Examples.ECrypto.html#alice_rsa/0"},{"type":"function","title":"Examples.ECrypto.bertha/0","doc":"","ref":"Examples.ECrypto.html#bertha/0"},{"type":"function","title":"Examples.ECrypto.blood_l_signed/0","doc":"","ref":"Examples.ECrypto.html#blood_l_signed/0"},{"type":"function","title":"Examples.ECrypto.blood_l_signed_detached/0","doc":"","ref":"Examples.ECrypto.html#blood_l_signed_detached/0"},{"type":"function","title":"Examples.ECrypto.blood_msg/0","doc":"","ref":"Examples.ECrypto.html#blood_msg/0"},{"type":"function","title":"Examples.ECrypto.bob_rsa/0","doc":"","ref":"Examples.ECrypto.html#bob_rsa/0"},{"type":"function","title":"Examples.ECrypto.eve/0","doc":"","ref":"Examples.ECrypto.html#eve/0"},{"type":"function","title":"Examples.ECrypto.londo/0","doc":"","ref":"Examples.ECrypto.html#londo/0"},{"type":"function","title":"Examples.ECrypto.xcc/0","doc":"","ref":"Examples.ECrypto.html#xcc/0"},{"type":"module","title":"Examples.EIdentity","doc":"","ref":"Examples.EIdentity.html"},{"type":"function","title":"Examples.EIdentity.alice_commits/0","doc":"","ref":"Examples.EIdentity.html#alice_commits/0"},{"type":"function","title":"Examples.EIdentity.alice_decrypts/0","doc":"","ref":"Examples.EIdentity.html#alice_decrypts/0"},{"type":"function","title":"Examples.EIdentity.bertha_commits/0","doc":"","ref":"Examples.EIdentity.html#bertha_commits/0"},{"type":"function","title":"Examples.EIdentity.failure_to_connect/1","doc":"","ref":"Examples.EIdentity.html#failure_to_connect/1"},{"type":"function","title":"Examples.EIdentity.londo_commits/0","doc":"","ref":"Examples.EIdentity.html#londo_commits/0"},{"type":"function","title":"Examples.EIdentity.memory_key/1","doc":"","ref":"Examples.EIdentity.html#memory_key/1"},{"type":"function","title":"Examples.EIdentity.memory_storage/1","doc":"","ref":"Examples.EIdentity.html#memory_storage/1"},{"type":"function","title":"Examples.EIdentity.memory_storage_connected_engines/1","doc":"","ref":"Examples.EIdentity.html#memory_storage_connected_engines/1"},{"type":"function","title":"Examples.EIdentity.no_memory_storage/1","doc":"","ref":"Examples.EIdentity.html#no_memory_storage/1"},{"type":"function","title":"Examples.EIdentity.same_id_multiple_times/1","doc":"","ref":"Examples.EIdentity.html#same_id_multiple_times/1"},{"type":"module","title":"Examples.ENock","doc":"","ref":"Examples.ENock.html"},{"type":"function","title":"Examples.ENock.anode/0","doc":"","ref":"Examples.ENock.html#anode/0"},{"type":"function","title":"Examples.ENock.anode/1","doc":"","ref":"Examples.ENock.html#anode/1"},{"type":"function","title":"Examples.ENock.bex/0","doc":"","ref":"Examples.ENock.html#bex/0"},{"type":"function","title":"Examples.ENock.bex_arm/0","doc":"The bex arm for taking bex:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localbex   =>  logics  |=  a=@  (bex a)\n\nand then grabbing the arm of localbex.","ref":"Examples.ENock.html#bex_arm/0"},{"type":"function","title":"Examples.ENock.counter_arm/0","doc":"The counter arm.\n\nAvailiable through `counter:logics` core.","ref":"Examples.ENock.html#counter_arm/0"},{"type":"function","title":"Examples.ENock.counter_logic/0","doc":"","ref":"Examples.ENock.html#counter_logic/0"},{"type":"function","title":"Examples.ENock.cue/0","doc":"","ref":"Examples.ENock.html#cue/0"},{"type":"function","title":"Examples.ENock.cue_arm/0","doc":"A cue arm for taking cue:anoma out of the logics core environment.\n\nCan be gotten by defining gate locally as\n\n=localcue   =>  logics  |=  a=@  (cue a)\n\nand then grabbing the arm of localcue.","ref":"Examples.ENock.html#cue_arm/0"},{"type":"function","title":"Examples.ENock.dec/0","doc":"","ref":"Examples.ENock.html#dec/0"},{"type":"function","title":"Examples.ENock.dec_arm/0","doc":"The decrement arm in the tests core.\n\nAvailiable through `use-dec:tests` core.","ref":"Examples.ENock.html#dec_arm/0"},{"type":"function","title":"Examples.ENock.devil_increment/0","doc":"","ref":"Examples.ENock.html#devil_increment/0"},{"type":"function","title":"Examples.ENock.env/1","doc":"","ref":"Examples.ENock.html#env/1"},{"type":"function","title":"Examples.ENock.factorial/0","doc":"","ref":"Examples.ENock.html#factorial/0"},{"type":"function","title":"Examples.ENock.factorial_arm/0","doc":"I am the battery of the fib:tests gate of the anoma stadard library.\n\nYou can dump me by calling\n\n.*  fib:tests  [0 2]","ref":"Examples.ENock.html#factorial_arm/0"},{"type":"function","title":"Examples.ENock.incorrectly_ending/0","doc":"","ref":"Examples.ENock.html#incorrectly_ending/0"},{"type":"function","title":"Examples.ENock.incorrectly_nested_noun/0","doc":"","ref":"Examples.ENock.html#incorrectly_nested_noun/0"},{"type":"function","title":"Examples.ENock.incorrectly_starting/0","doc":"","ref":"Examples.ENock.html#incorrectly_starting/0"},{"type":"function","title":"Examples.ENock.increment_counter_val/1","doc":"","ref":"Examples.ENock.html#increment_counter_val/1"},{"type":"function","title":"Examples.ENock.indexed_noun/0","doc":"","ref":"Examples.ENock.html#indexed_noun/0"},{"type":"function","title":"Examples.ENock.jam/0","doc":"","ref":"Examples.ENock.html#jam/0"},{"type":"function","title":"Examples.ENock.jam_and_cue/2","doc":"","ref":"Examples.ENock.html#jam_and_cue/2"},{"type":"function","title":"Examples.ENock.jam_arm/0","doc":"A cue arm for taking jam:anoma out of the logics core environment.\n\nCan be gotten by defining gate locally as\n\n=localjam   =>  logics  |=  a=@  (jam a)\n\nand then grabbing the arm of localjam.","ref":"Examples.ENock.html#jam_arm/0"},{"type":"function","title":"Examples.ENock.jamming_and_cueing/0","doc":"","ref":"Examples.ENock.html#jamming_and_cueing/0"},{"type":"function","title":"Examples.ENock.lsh0/0","doc":"I evaluate lsh at block size 0 and gate-input [2 6].\n\nlsh(0) evaluates the gate of the block door at block size 0,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh0/0"},{"type":"function","title":"Examples.ENock.lsh1/0","doc":"I evaluate lsh at block size 1 and gate-input [2 6].\n\nlsh(1) evaluates the gate of the block door at block size 1,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh1/0"},{"type":"function","title":"Examples.ENock.lsh2/0","doc":"I evaluate lsh at block size 1 and gate-input [2 6].\n\nlsh(2) evaluates the gate of the block door at block size 2,\n[6 1 2 6] replaces the sample with [2 6].","ref":"Examples.ENock.html#lsh2/0"},{"type":"function","title":"Examples.ENock.lsh/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=llsh   =>  logics  |=  a=@  lsh:block","ref":"Examples.ENock.html#lsh/1"},{"type":"function","title":"Examples.ENock.mat/0","doc":"","ref":"Examples.ENock.html#mat/0"},{"type":"function","title":"Examples.ENock.mat_arm/0","doc":"The mat arm for taking mat:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localmat   =>  logics  |=  a  (mat a)\n\nand then grabbing the arm of locamix.","ref":"Examples.ENock.html#mat_arm/0"},{"type":"function","title":"Examples.ENock.met0/0","doc":"I evaluate met at block size 0 and gate-input 28.\n\nmet(0) evaluates the gate of the block door at block size 0,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met0/0"},{"type":"function","title":"Examples.ENock.met1/0","doc":"I evaluate met at block size 1 and gate-input 28.\n\nmet(1) evaluates the gate of the block door at block size 1,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met1/0"},{"type":"function","title":"Examples.ENock.met2/0","doc":"I evaluate met at block size 2 and gate-input 28.\n\nmet(2) evaluates the gate of the block door at block size 2,\n[6 1 28] replaces the sample with 28.","ref":"Examples.ENock.html#met2/0"},{"type":"function","title":"Examples.ENock.met/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=lmet   =>  logics  |=  a=@  met:block","ref":"Examples.ENock.html#met/1"},{"type":"function","title":"Examples.ENock.miki_increment/0","doc":"","ref":"Examples.ENock.html#miki_increment/0"},{"type":"function","title":"Examples.ENock.miki_increment_candidate/0","doc":"","ref":"Examples.ENock.html#miki_increment_candidate/0"},{"type":"function","title":"Examples.ENock.miki_increment_kv_tx/0","doc":"","ref":"Examples.ENock.html#miki_increment_kv_tx/0"},{"type":"function","title":"Examples.ENock.mix/0","doc":"","ref":"Examples.ENock.html#mix/0"},{"type":"function","title":"Examples.ENock.mix_arm/0","doc":"The mix arm for taking mix:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localmix   =>  logics  |=  [a=@ b=@]  (mix [a b])\n\nand then grabbing the arm of locamix.","ref":"Examples.ENock.html#mix_arm/0"},{"type":"function","title":"Examples.ENock.nesting_noun/0","doc":"","ref":"Examples.ENock.html#nesting_noun/0"},{"type":"function","title":"Examples.ENock.one_two/0","doc":"","ref":"Examples.ENock.html#one_two/0"},{"type":"function","title":"Examples.ENock.raw_storage/0","doc":"","ref":"Examples.ENock.html#raw_storage/0"},{"type":"function","title":"Examples.ENock.replacing_terms/0","doc":"","ref":"Examples.ENock.html#replacing_terms/0"},{"type":"function","title":"Examples.ENock.rsh0/0","doc":"I evaluate rsh at block size 0 and gate-input [2 40].\n\nrsh(0) evaluates the gate of the block door at block size 0,\n[6 1 2 40] replaces the sample with [2 40].","ref":"Examples.ENock.html#rsh0/0"},{"type":"function","title":"Examples.ENock.rsh1/0","doc":"I evaluate rsh at block size 1 and gate-input [2 40].\n\nrsh(1) evaluates the gate of the block door at block size 1,\n[6 1 2 40] replaces the sample with [2 40].","ref":"Examples.ENock.html#rsh1/0"},{"type":"function","title":"Examples.ENock.rsh2/0","doc":"I evaluate rsh at block size 2 and gate-input [2 40].\n\nrsh(2) evaluates the gate of the block door at block size 2,\n[6 1 1 40] replaces the sample with [1 40].","ref":"Examples.ENock.html#rsh2/0"},{"type":"function","title":"Examples.ENock.rsh/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=rsh   =>  logics  |=  a=@  rsh:block","ref":"Examples.ENock.html#rsh/1"},{"type":"function","title":"Examples.ENock.sign/0","doc":"","ref":"Examples.ENock.html#sign/0"},{"type":"function","title":"Examples.ENock.sign_arm/0","doc":"The sign arm for taking sign:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localsign   =>  logics  |=  [a=@ b=@]  (sign [a b])\n\nand then grabbing the arm of localsign.","ref":"Examples.ENock.html#sign_arm/0"},{"type":"function","title":"Examples.ENock.sign_detatched/0","doc":"","ref":"Examples.ENock.html#sign_detatched/0"},{"type":"function","title":"Examples.ENock.sign_detatched_arm/0","doc":"The sign-detatched arm for taking sign-detached:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localsigndetached   =>  logics  |=  [a=@ b=@]  (sign-detached [a b])\n\nand then grabbing the arm of localsighdetached.","ref":"Examples.ENock.html#sign_detatched_arm/0"},{"type":"function","title":"Examples.ENock.successful_inc/0","doc":"","ref":"Examples.ENock.html#successful_inc/0"},{"type":"function","title":"Examples.ENock.uend0/0","doc":"I evaluate uend at block size 0 and gate-input [5 80].\n\nuend(0) evaluates the gate of the block door at block size 0,\n[6 1 5 80] replaces the sample with [5 80].","ref":"Examples.ENock.html#uend0/0"},{"type":"function","title":"Examples.ENock.uend1/0","doc":"I evaluate uend at block size 1 and gate-input [3 80] and [4 80].\n\nuend(1) evaluates the gate of the block door at block size 1,\n[6 1 3 80] replaces the sample with [3 80],\n[6 1 4 80] replaces the sample with [3 80]","ref":"Examples.ENock.html#uend1/0"},{"type":"function","title":"Examples.ENock.uend/1","doc":"I am an lash arm in the block door.\n\nMy index inside the door can be seen by asking to dump the logic of\n=luend   =>  logics  |=  a=@  luend:block","ref":"Examples.ENock.html#uend/1"},{"type":"function","title":"Examples.ENock.unsuccessful_inc/0","doc":"","ref":"Examples.ENock.html#unsuccessful_inc/0"},{"type":"function","title":"Examples.ENock.verify/0","doc":"","ref":"Examples.ENock.html#verify/0"},{"type":"function","title":"Examples.ENock.verify_arm/0","doc":"The verify arm for taking verify:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localverify   =>  logics  |=  [a=@ b=@]  (verify [a b])\n\nand then grabbing the arm of localverify.","ref":"Examples.ENock.html#verify_arm/0"},{"type":"function","title":"Examples.ENock.verify_detatched/0","doc":"","ref":"Examples.ENock.html#verify_detatched/0"},{"type":"function","title":"Examples.ENock.verify_detatched_arm/0","doc":"The verify-detatched arm for taking verify-detached:anoma from the logics core environment.\n\nCan be gotten by defining gate locally as:\n\n=localverifydetached   =>  logics  |=  [a=@ b=@ c=@]  (verify-detached [a b])\n\nand then grabbing the arm of localverifydetached.","ref":"Examples.ENock.html#verify_detatched_arm/0"},{"type":"function","title":"Examples.ENock.zero_counter/1","doc":"","ref":"Examples.ENock.html#zero_counter/1"},{"type":"function","title":"Examples.ENock.zero_delta_logic/0","doc":"","ref":"Examples.ENock.html#zero_delta_logic/0"},{"type":"module","title":"Examples.ENode","doc":"I give examples of the ENode.\n\nCurrently I make networks in `Phase_1` of the example. Meaning that\nnetwork configurations I provide, are not cloned. The given storage\nnames will be written over for any shared set of storage.\n\nWhen `phase_2` of the changes come in, the signature and examples of\nthis module in particular will likely change quite a bit to return\npersistent networks that other examples can use\nnon-destructively. And thus every example can simply add on to\nanother. However since we don't have this examples, are expected to\nclean out the state before running.","ref":"Examples.ENode.html"},{"type":"function","title":"Examples.ENode.attach_socks/2","doc":"","ref":"Examples.ENode.html#attach_socks/2"},{"type":"function","title":"Examples.ENode.base_snapshot_path/0","doc":"","ref":"Examples.ENode.html#base_snapshot_path/0"},{"type":"function","title":"Examples.ENode.fresh_full_node/3","doc":"We give an example of the full node!","ref":"Examples.ENode.html#fresh_full_node/3"},{"type":"function","title":"Examples.ENode.intent/1","doc":"","ref":"Examples.ENode.html#intent/1"},{"type":"function","title":"Examples.ENode.simple_ordering/1","doc":"Simple node with the minimal dependencies for Storage","ref":"Examples.ENode.html#simple_ordering/1"},{"type":"function","title":"Examples.ENode.simple_router/0","doc":"I am simply a node with just a router and transport","ref":"Examples.ENode.html#simple_router/0"},{"type":"function","title":"Examples.ENode.simple_storage/1","doc":"Minimal node, with storage","ref":"Examples.ENode.html#simple_storage/1"},{"type":"function","title":"Examples.ENode.simple_storage_topic/1","doc":"Minimal node, with storage and a topic","ref":"Examples.ENode.html#simple_storage_topic/1"},{"type":"function","title":"Examples.ENode.solver/1","doc":"","ref":"Examples.ENode.html#solver/1"},{"type":"function","title":"Examples.ENode.zero_clock/0","doc":"I am just the clock engine with router support. My time starts at 0","ref":"Examples.ENode.html#zero_clock/0"},{"type":"module","title":"Examples.ENode.EClock","doc":"","ref":"Examples.ENode.EClock.html"},{"type":"function","title":"Examples.ENode.EClock.start_clock/0","doc":"","ref":"Examples.ENode.EClock.html#start_clock/0"},{"type":"module","title":"Examples.ENode.EDumper","doc":"","ref":"Examples.ENode.EDumper.html"},{"type":"function","title":"Examples.ENode.EDumper.anode/1","doc":"","ref":"Examples.ENode.EDumper.html#anode/1"},{"type":"function","title":"Examples.ENode.EDumper.dumped_node/1","doc":"","ref":"Examples.ENode.EDumper.html#dumped_node/1"},{"type":"function","title":"Examples.ENode.EDumper.node_name/1","doc":"","ref":"Examples.ENode.EDumper.html#node_name/1"},{"type":"function","title":"Examples.ENode.EDumper.raw_storage/1","doc":"","ref":"Examples.ENode.EDumper.html#raw_storage/1"},{"type":"module","title":"Examples.ENode.EIntent","doc":"","ref":"Examples.ENode.EIntent.html"},{"type":"function","title":"Examples.ENode.EIntent.anode/1","doc":"","ref":"Examples.ENode.EIntent.html#anode/1"},{"type":"function","title":"Examples.ENode.EIntent.anode/2","doc":"","ref":"Examples.ENode.EIntent.html#anode/2"},{"type":"function","title":"Examples.ENode.EIntent.raw_storage/1","doc":"","ref":"Examples.ENode.EIntent.html#raw_storage/1"},{"type":"function","title":"Examples.ENode.EIntent.solved_trade/1","doc":"I am a simple solver. The return state is the solved node\n\nWe do not send any other transactions such as incrementing a solved\ncounter, though we could easily submit it.","ref":"Examples.ENode.EIntent.html#solved_trade/1"},{"type":"module","title":"Examples.ENode.EMempool","doc":"","ref":"Examples.ENode.EMempool.html"},{"type":"function","title":"Examples.ENode.EMempool.increment_pool/1","doc":"","ref":"Examples.ENode.EMempool.html#increment_pool/1"},{"type":"function","title":"Examples.ENode.EMempool.incremented_lucky_one_jam/1","doc":"","ref":"Examples.ENode.EMempool.html#incremented_lucky_one_jam/1"},{"type":"module","title":"Examples.ENode.EPinger","doc":"","ref":"Examples.ENode.EPinger.html"},{"type":"function","title":"Examples.ENode.EPinger.anode/1","doc":"","ref":"Examples.ENode.EPinger.html#anode/1"},{"type":"function","title":"Examples.ENode.EPinger.anode/2","doc":"","ref":"Examples.ENode.EPinger.html#anode/2"},{"type":"function","title":"Examples.ENode.EPinger.pinger_run/1","doc":"","ref":"Examples.ENode.EPinger.html#pinger_run/1"},{"type":"function","title":"Examples.ENode.EPinger.raw_storage/1","doc":"","ref":"Examples.ENode.EPinger.html#raw_storage/1"},{"type":"module","title":"Examples.ENode.EStorage","doc":"","ref":"Examples.ENode.EStorage.html"},{"type":"function","title":"Examples.ENode.EStorage.anode/1","doc":"","ref":"Examples.ENode.EStorage.html#anode/1"},{"type":"function","title":"Examples.ENode.EStorage.august_namespace/0","doc":"","ref":"Examples.ENode.EStorage.html#august_namespace/0"},{"type":"function","title":"Examples.ENode.EStorage.august_node/1","doc":"I am the august storage, see my Keys for details on my storage setup","ref":"Examples.ENode.EStorage.html#august_node/1"},{"type":"function","title":"Keys: - Examples.ENode.EStorage.august_node/1","doc":"- `miki_key/0` - `lucky_value/0`\n- `isuzumi_key/0` - `devil_value/0`\n- `Examples.ENode.base_snapshot_path/0` - snapshot of both","ref":"Examples.ENode.EStorage.html#august_node/1-keys"},{"type":"function","title":"Examples.ENode.EStorage.august_node_proper/1","doc":"I am like `august_node/1`. Except I sign the namespace reserved\n\nFurther besides the main space being owned by memory backed space,\nwe have `ECrypto.londo/0` owning the water. Thankfully we aren't on\nNarn.","ref":"Examples.ENode.EStorage.html#august_node_proper/1"},{"type":"function","title":"Examples.ENode.EStorage.august_replaced_keyspace/1","doc":"I am the replaced keyspace node for august.\n\nI use `august_node` and then delete the associated miki value. This way\nwhen we print keyspaces, we see all the previously availiable key-value\npairs sans the miki key.","ref":"Examples.ENode.EStorage.html#august_replaced_keyspace/1"},{"type":"function","title":"Examples.ENode.EStorage.august_space/0","doc":"","ref":"Examples.ENode.EStorage.html#august_space/0"},{"type":"function","title":"Examples.ENode.EStorage.august_subnamespace/1","doc":"","ref":"Examples.ENode.EStorage.html#august_subnamespace/1"},{"type":"function","title":"Examples.ENode.EStorage.bertha_speaks_for_all/1","doc":"","ref":"Examples.ENode.EStorage.html#bertha_speaks_for_all/1"},{"type":"function","title":"Examples.ENode.EStorage.blocking_for_put/1","doc":"","ref":"Examples.ENode.EStorage.html#blocking_for_put/1"},{"type":"function","title":"Examples.ENode.EStorage.deleting_nothing_works_fine/1","doc":"","ref":"Examples.ENode.EStorage.html#deleting_nothing_works_fine/1"},{"type":"function","title":"Examples.ENode.EStorage.deleting_the_put/1","doc":"","ref":"Examples.ENode.EStorage.html#deleting_the_put/1"},{"type":"function","title":"Examples.ENode.EStorage.devil_key/0","doc":"","ref":"Examples.ENode.EStorage.html#devil_key/0"},{"type":"function","title":"Examples.ENode.EStorage.devil_value/0","doc":"","ref":"Examples.ENode.EStorage.html#devil_value/0"},{"type":"function","title":"Examples.ENode.EStorage.empty_storage/1","doc":"","ref":"Examples.ENode.EStorage.html#empty_storage/1"},{"type":"function","title":"Examples.ENode.EStorage.isuzumi_key/0","doc":"","ref":"Examples.ENode.EStorage.html#isuzumi_key/0"},{"type":"function","title":"Examples.ENode.EStorage.londo_speaks_for_alice/1","doc":"","ref":"Examples.ENode.EStorage.html#londo_speaks_for_alice/1"},{"type":"function","title":"Examples.ENode.EStorage.lucky_key/0","doc":"","ref":"Examples.ENode.EStorage.html#lucky_key/0"},{"type":"function","title":"Examples.ENode.EStorage.lucky_value/0","doc":"","ref":"Examples.ENode.EStorage.html#lucky_value/0"},{"type":"function","title":"Examples.ENode.EStorage.miki_key/0","doc":"","ref":"Examples.ENode.EStorage.html#miki_key/0"},{"type":"function","title":"Examples.ENode.EStorage.put_storage/1","doc":"","ref":"Examples.ENode.EStorage.html#put_storage/1"},{"type":"function","title":"Examples.ENode.EStorage.random_id/0","doc":"","ref":"Examples.ENode.EStorage.html#random_id/0"},{"type":"function","title":"Examples.ENode.EStorage.raw_storage/1","doc":"","ref":"Examples.ENode.EStorage.html#raw_storage/1"},{"type":"function","title":"Examples.ENode.EStorage.reserved_august/1","doc":"","ref":"Examples.ENode.EStorage.html#reserved_august/1"},{"type":"function","title":"Examples.ENode.EStorage.snapshot_again/1","doc":"","ref":"Examples.ENode.EStorage.html#snapshot_again/1"},{"type":"function","title":"Examples.ENode.EStorage.snapshot_point/0","doc":"","ref":"Examples.ENode.EStorage.html#snapshot_point/0"},{"type":"function","title":"Examples.ENode.EStorage.snapshot_then_put/1","doc":"I have `Examples.Enock.one_two/2` in storage twice and a snapshot!\n\nThe snapshot only snapshots the first key though, keep that in mind.","ref":"Examples.ENode.EStorage.html#snapshot_then_put/1"},{"type":"function","title":"Keys: - Examples.ENode.EStorage.snapshot_then_put/1","doc":"- `Examples.ENock.one_two/0` - latest value is `lucky_value/0`\n - `Examples.ENode.base_snapshot_path/0` - snapshot with\n   `Examples.ENock.one_two/0` being 1","ref":"Examples.ENode.EStorage.html#snapshot_then_put/1-keys"},{"type":"function","title":"Examples.ENode.EStorage.sub/1","doc":"","ref":"Examples.ENode.EStorage.html#sub/1"},{"type":"function","title":"Examples.ENode.EStorage.unsub/1","doc":"","ref":"Examples.ENode.EStorage.html#unsub/1"},{"type":"module","title":"Examples.ENode.ETransport.ETCP","doc":"","ref":"Examples.ENode.ETransport.ETCP.html"},{"type":"function","title":"Examples.ENode.ETransport.ETCP.cleanup/2","doc":"","ref":"Examples.ENode.ETransport.ETCP.html#cleanup/2"},{"type":"function","title":"Examples.ENode.ETransport.ETCP.shutdown_from_outside/1","doc":"","ref":"Examples.ENode.ETransport.ETCP.html#shutdown_from_outside/1"},{"type":"module","title":"Examples.EParser","doc":"","ref":"Examples.EParser.html"},{"type":"function","title":"Examples.EParser.get_423/1","doc":"","ref":"Examples.EParser.html#get_423/1"},{"type":"function","title":"Examples.EParser.get_ro_submit_423/1","doc":"","ref":"Examples.EParser.html#get_ro_submit_423/1"},{"type":"function","title":"Examples.EParser.inc_submit_423/0","doc":"","ref":"Examples.EParser.html#inc_submit_423/0"},{"type":"function","title":"Examples.EParser.plus_one_ro_submit_423/1","doc":"","ref":"Examples.EParser.html#plus_one_ro_submit_423/1"},{"type":"function","title":"Examples.EParser.zero_submit_423/0","doc":"","ref":"Examples.EParser.html#zero_submit_423/0"},{"type":"type","title":"Examples.EParser.inc_submit_423/0","doc":"","ref":"Examples.EParser.html#t:inc_submit_423/0"},{"type":"type","title":"Examples.EParser.parse_result/0","doc":"","ref":"Examples.EParser.html#t:parse_result/0"},{"type":"type","title":"Examples.EParser.zero_submit_423/0","doc":"","ref":"Examples.EParser.html#t:zero_submit_423/0"},{"type":"module","title":"Examples.EProofRecord","doc":"","ref":"Examples.EProofRecord.html"},{"type":"function","title":"Examples.EProofRecord.a0_counter_proof/0","doc":"","ref":"Examples.EProofRecord.html#a0_counter_proof/0"},{"type":"function","title":"Examples.EProofRecord.a1_counter_proof/0","doc":"","ref":"Examples.EProofRecord.html#a1_counter_proof/0"},{"type":"function","title":"Examples.EProofRecord.a5_space_proof/0","doc":"","ref":"Examples.EProofRecord.html#a5_space_proof/0"},{"type":"function","title":"Examples.EProofRecord.a10_d0_proof/0","doc":"","ref":"Examples.EProofRecord.html#a10_d0_proof/0"},{"type":"function","title":"Examples.EProofRecord.a10_space_proof/0","doc":"","ref":"Examples.EProofRecord.html#a10_space_proof/0"},{"type":"function","title":"Examples.EProofRecord.ax_proof/0","doc":"","ref":"Examples.EProofRecord.html#ax_proof/0"},{"type":"function","title":"Examples.EProofRecord.ay_proof/0","doc":"","ref":"Examples.EProofRecord.html#ay_proof/0"},{"type":"function","title":"Examples.EProofRecord.b10_d0_proof/0","doc":"","ref":"Examples.EProofRecord.html#b10_d0_proof/0"},{"type":"function","title":"Examples.EProofRecord.b10_space_proof/0","doc":"","ref":"Examples.EProofRecord.html#b10_space_proof/0"},{"type":"function","title":"Examples.EProofRecord.bx_proof/0","doc":"","ref":"Examples.EProofRecord.html#bx_proof/0"},{"type":"function","title":"Examples.EProofRecord.by_proof/0","doc":"","ref":"Examples.EProofRecord.html#by_proof/0"},{"type":"module","title":"Examples.EResource","doc":"","ref":"Examples.EResource.html"},{"type":"function","title":"Examples.EResource.a0_counter_commit/0","doc":"","ref":"Examples.EResource.html#a0_counter_commit/0"},{"type":"function","title":"Examples.EResource.a0_counter_nullifier/0","doc":"","ref":"Examples.EResource.html#a0_counter_nullifier/0"},{"type":"function","title":"Examples.EResource.a0_counter_resource/0","doc":"","ref":"Examples.EResource.html#a0_counter_resource/0"},{"type":"function","title":"Examples.EResource.a1_counter_commit/0","doc":"","ref":"Examples.EResource.html#a1_counter_commit/0"},{"type":"function","title":"Examples.EResource.a1_counter_nullifier/0","doc":"","ref":"Examples.EResource.html#a1_counter_nullifier/0"},{"type":"function","title":"Examples.EResource.a1_counter_resource/0","doc":"","ref":"Examples.EResource.html#a1_counter_resource/0"},{"type":"function","title":"Examples.EResource.a2_commit/0","doc":"","ref":"Examples.EResource.html#a2_commit/0"},{"type":"function","title":"Examples.EResource.a2_nullifier/0","doc":"","ref":"Examples.EResource.html#a2_nullifier/0"},{"type":"function","title":"Examples.EResource.a2_resource/0","doc":"","ref":"Examples.EResource.html#a2_resource/0"},{"type":"function","title":"Examples.EResource.a5_space_commit/0","doc":"","ref":"Examples.EResource.html#a5_space_commit/0"},{"type":"function","title":"Examples.EResource.a5_space_nullifier/0","doc":"","ref":"Examples.EResource.html#a5_space_nullifier/0"},{"type":"function","title":"Examples.EResource.a5_space_resource/0","doc":"","ref":"Examples.EResource.html#a5_space_resource/0"},{"type":"function","title":"Examples.EResource.a10_d0_commit/0","doc":"","ref":"Examples.EResource.html#a10_d0_commit/0"},{"type":"function","title":"Examples.EResource.a10_d0_nullifier/0","doc":"","ref":"Examples.EResource.html#a10_d0_nullifier/0"},{"type":"function","title":"Examples.EResource.a10_d0_resource/0","doc":"","ref":"Examples.EResource.html#a10_d0_resource/0"},{"type":"function","title":"Examples.EResource.a10_space_commit/0","doc":"","ref":"Examples.EResource.html#a10_space_commit/0"},{"type":"function","title":"Examples.EResource.a10_space_nullifier/0","doc":"","ref":"Examples.EResource.html#a10_space_nullifier/0"},{"type":"function","title":"Examples.EResource.a10_space_resource/0","doc":"","ref":"Examples.EResource.html#a10_space_resource/0"},{"type":"function","title":"Examples.EResource.a_commit/0","doc":"","ref":"Examples.EResource.html#a_commit/0"},{"type":"function","title":"Examples.EResource.a_kind/0","doc":"","ref":"Examples.EResource.html#a_kind/0"},{"type":"function","title":"Examples.EResource.a_nullifier/0","doc":"","ref":"Examples.EResource.html#a_nullifier/0"},{"type":"function","title":"Examples.EResource.a_resource/0","doc":"","ref":"Examples.EResource.html#a_resource/0"},{"type":"function","title":"Examples.EResource.another_a_kind/0","doc":"","ref":"Examples.EResource.html#another_a_kind/0"},{"type":"function","title":"Examples.EResource.ax_commit/0","doc":"","ref":"Examples.EResource.html#ax_commit/0"},{"type":"function","title":"Examples.EResource.ax_nullifier/0","doc":"","ref":"Examples.EResource.html#ax_nullifier/0"},{"type":"function","title":"Examples.EResource.ax_resource/0","doc":"","ref":"Examples.EResource.html#ax_resource/0"},{"type":"function","title":"Examples.EResource.ay_commit/0","doc":"","ref":"Examples.EResource.html#ay_commit/0"},{"type":"function","title":"Examples.EResource.ay_nullifier/0","doc":"","ref":"Examples.EResource.html#ay_nullifier/0"},{"type":"function","title":"Examples.EResource.ay_resource/0","doc":"","ref":"Examples.EResource.html#ay_resource/0"},{"type":"function","title":"Examples.EResource.b10_d0_commit/0","doc":"","ref":"Examples.EResource.html#b10_d0_commit/0"},{"type":"function","title":"Examples.EResource.b10_d0_nullifier/0","doc":"","ref":"Examples.EResource.html#b10_d0_nullifier/0"},{"type":"function","title":"Examples.EResource.b10_d0_resource/0","doc":"","ref":"Examples.EResource.html#b10_d0_resource/0"},{"type":"function","title":"Examples.EResource.b10_space_commit/0","doc":"","ref":"Examples.EResource.html#b10_space_commit/0"},{"type":"function","title":"Examples.EResource.b10_space_nullifier/0","doc":"","ref":"Examples.EResource.html#b10_space_nullifier/0"},{"type":"function","title":"Examples.EResource.b10_space_resource/0","doc":"","ref":"Examples.EResource.html#b10_space_resource/0"},{"type":"function","title":"Examples.EResource.b_commit/0","doc":"","ref":"Examples.EResource.html#b_commit/0"},{"type":"function","title":"Examples.EResource.b_nullifier/0","doc":"","ref":"Examples.EResource.html#b_nullifier/0"},{"type":"function","title":"Examples.EResource.b_resource/0","doc":"","ref":"Examples.EResource.html#b_resource/0"},{"type":"function","title":"Examples.EResource.bx_commit/0","doc":"","ref":"Examples.EResource.html#bx_commit/0"},{"type":"function","title":"Examples.EResource.bx_nullifier/0","doc":"","ref":"Examples.EResource.html#bx_nullifier/0"},{"type":"function","title":"Examples.EResource.bx_resource/0","doc":"","ref":"Examples.EResource.html#bx_resource/0"},{"type":"function","title":"Examples.EResource.by_commit/0","doc":"","ref":"Examples.EResource.html#by_commit/0"},{"type":"function","title":"Examples.EResource.by_nullifier/0","doc":"","ref":"Examples.EResource.html#by_nullifier/0"},{"type":"function","title":"Examples.EResource.by_resource/0","doc":"","ref":"Examples.EResource.html#by_resource/0"},{"type":"function","title":"Examples.EResource.counter_kind/0","doc":"","ref":"Examples.EResource.html#counter_kind/0"},{"type":"function","title":"Examples.EResource.d0_kind/0","doc":"","ref":"Examples.EResource.html#d0_kind/0"},{"type":"function","title":"Examples.EResource.invalid_nullifier/0","doc":"","ref":"Examples.EResource.html#invalid_nullifier/0"},{"type":"function","title":"Examples.EResource.x_kind/0","doc":"","ref":"Examples.EResource.html#x_kind/0"},{"type":"function","title":"Examples.EResource.y_kind/0","doc":"","ref":"Examples.EResource.html#y_kind/0"},{"type":"module","title":"Examples.ESerialisation","doc":"","ref":"Examples.ESerialisation.html"},{"type":"function","title":"Examples.ESerialisation.aresource/0","doc":"","ref":"Examples.ESerialisation.html#aresource/0"},{"type":"function","title":"Examples.ESerialisation.empty_tx/0","doc":"","ref":"Examples.ESerialisation.html#empty_tx/0"},{"type":"function","title":"Examples.ESerialisation.pack_unpack_id/2","doc":"","ref":"Examples.ESerialisation.html#pack_unpack_id/2"},{"type":"function","title":"Examples.ESerialisation.simple_map/0","doc":"","ref":"Examples.ESerialisation.html#simple_map/0"},{"type":"module","title":"Examples.ETransaction","doc":"","ref":"Examples.ETransaction.html"},{"type":"function","title":"Examples.ETransaction.ax_for_y/0","doc":"","ref":"Examples.ETransaction.html#ax_for_y/0"},{"type":"function","title":"Examples.ETransaction.balanced_d0_logic/0","doc":"","ref":"Examples.ETransaction.html#balanced_d0_logic/0"},{"type":"function","title":"Examples.ETransaction.balanced_transaction/0","doc":"","ref":"Examples.ETransaction.html#balanced_transaction/0"},{"type":"function","title":"Examples.ETransaction.by_for_x/0","doc":"","ref":"Examples.ETransaction.html#by_for_x/0"},{"type":"function","title":"Examples.ETransaction.d0_delta/1","doc":"","ref":"Examples.ETransaction.html#d0_delta/1"},{"type":"function","title":"Examples.ETransaction.empty_transaction/0","doc":"","ref":"Examples.ETransaction.html#empty_transaction/0"},{"type":"function","title":"Examples.ETransaction.full_x_for_y/0","doc":"","ref":"Examples.ETransaction.html#full_x_for_y/0"},{"type":"function","title":"Examples.ETransaction.increment_counter_transaction/0","doc":"","ref":"Examples.ETransaction.html#increment_counter_transaction/0"},{"type":"function","title":"Examples.ETransaction.invalid_logic_check/0","doc":"","ref":"Examples.ETransaction.html#invalid_logic_check/0"},{"type":"function","title":"Examples.ETransaction.invalid_proofs_transaction/0","doc":"","ref":"Examples.ETransaction.html#invalid_proofs_transaction/0"},{"type":"function","title":"Examples.ETransaction.unbalanced_transaction/0","doc":"","ref":"Examples.ETransaction.html#unbalanced_transaction/0"},{"type":"function","title":"Examples.ETransaction.zero_delta/0","doc":"","ref":"Examples.ETransaction.html#zero_delta/0"},{"type":"module","title":"Glossary","doc":"","ref":"Glossary.html"},{"type":"function","title":"Glossary.transaction_candidate/0","doc":"A transaction candidate is `t:Noun.t/0` that evaluates to a valid or\ninvalid `transaction` for a specified\n`t:Anoma.Node.Executor.Worker.backend/0`","ref":"Glossary.html#transaction_candidate/0"},{"type":"module","title":"IdentityMap","doc":"A map with an identity value; all keys not explicitly assigned a value map to\nthe identity.","ref":"IdentityMap.html"},{"type":"function","title":"IdentityMap.get/2","doc":"","ref":"IdentityMap.html#get/2"},{"type":"function","title":"IdentityMap.new/3","doc":"","ref":"IdentityMap.html#new/3"},{"type":"function","title":"IdentityMap.put/3","doc":"","ref":"IdentityMap.html#put/3"},{"type":"function","title":"IdentityMap.update/3","doc":"","ref":"IdentityMap.html#update/3"},{"type":"type","title":"IdentityMap.t/2","doc":"","ref":"IdentityMap.html#t:t/2"},{"type":"module","title":"Livebook","doc":"I generate out extra information for Livebook\n\nMy main purpose is to generate out the TOC for each livebook\ndocument we have.\n\nto do this please run `toc_toplevel/0`\n\nTo set a certain order please set `sort_order/0` to have the updated\norder","ref":"Livebook.html"},{"type":"module","title":"API - Livebook","doc":"- `sort_order/0`\n- `toc_toplevel/0`\n- `get_all_livemd_documents/0`\n- `example_toc/0`","ref":"Livebook.html#module-api"},{"type":"function","title":"Livebook.add_heading_num/1","doc":"","ref":"Livebook.html#add_heading_num/1"},{"type":"function","title":"Livebook.change_header/4","doc":"I replace the header with the given TOC","ref":"Livebook.html#change_header/4"},{"type":"function","title":"Example - Livebook.change_header/4","doc":"> markdown_text = \"","ref":"Livebook.html#change_header/4-example"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"text here","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\"\n  > Livebook.change_header(markdown_text, \"##\", \"Index\", \"New Content\") |> IO.puts","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"New Content","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\n    :ok","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Livebook.count_depth/1","doc":"","ref":"Livebook.html#count_depth/1"},{"type":"function","title":"Livebook.dir_from_path/1","doc":"","ref":"Livebook.html#dir_from_path/1"},{"type":"function","title":"Livebook.example_toc/0","doc":"I provide an example of what a TOC looks like","ref":"Livebook.html#example_toc/0"},{"type":"function","title":"Livebook.generate_heading/4","doc":"","ref":"Livebook.html#generate_heading/4"},{"type":"function","title":"Livebook.generate_TOC/2","doc":"Generates out a TOC, given a series of nested documents\n\nWe take a path, and a place where we should be calculating the TOC from.","ref":"Livebook.html#generate_TOC/2"},{"type":"function","title":"Example - Livebook.generate_TOC/2","doc":"","ref":"Livebook.html#generate_TOC/2-example"},{"type":"function","title":"Livebook.get_all_livemd_documents/0","doc":"I get out all live view docs","ref":"Livebook.html#get_all_livemd_documents/0"},{"type":"function","title":"Livebook.get_livemd_documents/1","doc":"Gets all livemd documents in a sorted list given a path.","ref":"Livebook.html#get_livemd_documents/1"},{"type":"function","title":"Livebook.inject_TOC/2","doc":"","ref":"Livebook.html#inject_TOC/2"},{"type":"function","title":"Livebook.sort_order/0","doc":"","ref":"Livebook.html#sort_order/0"},{"type":"function","title":"Livebook.toc_toplevel/0","doc":"I generate out the TOC for all liveview docs","ref":"Livebook.html#toc_toplevel/0"},{"type":"type","title":"Livebook.sort/0","doc":"","ref":"Livebook.html#t:sort/0"},{"type":"module","title":"MapSetMap","doc":"An IdentityMap where the values are MapSets, plus some convenient helper functions.","ref":"MapSetMap.html"},{"type":"function","title":"MapSetMap.add/3","doc":"","ref":"MapSetMap.html#add/3"},{"type":"function","title":"MapSetMap.empty_map_p/1","doc":"","ref":"MapSetMap.html#empty_map_p/1"},{"type":"function","title":"MapSetMap.get/2","doc":"","ref":"MapSetMap.html#get/2"},{"type":"function","title":"MapSetMap.new/0","doc":"","ref":"MapSetMap.html#new/0"},{"type":"function","title":"MapSetMap.remove/3","doc":"","ref":"MapSetMap.html#remove/3"},{"type":"type","title":"MapSetMap.t/2","doc":"","ref":"MapSetMap.html#t:t/2"},{"type":"task","title":"mix client","doc":"I generate out the TOC for each liveview doc","ref":"Mix.Tasks.Client.html"},{"type":"function","title":"Mix.Tasks.Client.argument_parser/0","doc":"","ref":"Mix.Tasks.Client.html#argument_parser/0"},{"type":"function","title":"Mix.Tasks.Client.run/1","doc":"","ref":"Mix.Tasks.Client.html#run/1"},{"type":"task","title":"mix toc","doc":"I generate out the TOC for each liveview doc","ref":"Mix.Tasks.Toc.html"},{"type":"function","title":"Mix.Tasks.Toc.run/1","doc":"","ref":"Mix.Tasks.Toc.html#run/1"},{"type":"module","title":"Anoma.Resource","doc":" represent a resource.\n\nDo not create with `%Anoma.Resource{}` directly, instead use\n`%{Anoma.Resource.new | ...}` for random nonce and seed.","ref":"Anoma.Resource.html"},{"type":"function","title":"Anoma.Resource.commitment/1","doc":"A commitment to the given resource.","ref":"Anoma.Resource.html#commitment/1"},{"type":"function","title":"Anoma.Resource.commitment_hash/1","doc":"","ref":"Anoma.Resource.html#commitment_hash/1"},{"type":"function","title":"Anoma.Resource.commits_to/2","doc":"Whether a commitment commits to a given resource.","ref":"Anoma.Resource.html#commits_to/2"},{"type":"function","title":"Anoma.Resource.commits_to_any/2","doc":"","ref":"Anoma.Resource.html#commits_to_any/2"},{"type":"function","title":"Anoma.Resource.delta/1","doc":"The delta of the given resource (kind and quantity).","ref":"Anoma.Resource.html#delta/1"},{"type":"function","title":"Anoma.Resource.from_noun/1","doc":"","ref":"Anoma.Resource.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.kind/1","doc":"The kind of the given resource (labelled logic).","ref":"Anoma.Resource.html#kind/1"},{"type":"function","title":"Anoma.Resource.new/0","doc":"New blank resource. Randomized nonce and seed.","ref":"Anoma.Resource.html#new/0"},{"type":"function","title":"Anoma.Resource.new_with_npk/1","doc":"Helper to pass in the npk for initializing a valid but meaningless\nresource.","ref":"Anoma.Resource.html#new_with_npk/1"},{"type":"function","title":"Anoma.Resource.nullifier/2","doc":"The nullifier of the given resource.\n(It's up to the caller to use the right secret.)","ref":"Anoma.Resource.html#nullifier/2"},{"type":"function","title":"Anoma.Resource.nullifier_hash/1","doc":"","ref":"Anoma.Resource.html#nullifier_hash/1"},{"type":"function","title":"Anoma.Resource.nullifies/2","doc":"Whether a nullifier nullifies a given resource.","ref":"Anoma.Resource.html#nullifies/2"},{"type":"function","title":"Anoma.Resource.nullifies_any/2","doc":"","ref":"Anoma.Resource.html#nullifies_any/2"},{"type":"function","title":"Anoma.Resource.transparent_committed_resource/1","doc":"","ref":"Anoma.Resource.html#transparent_committed_resource/1"},{"type":"function","title":"Anoma.Resource.transparent_run_resource_logic/2","doc":"","ref":"Anoma.Resource.html#transparent_run_resource_logic/2"},{"type":"function","title":"Anoma.Resource.unique/1","doc":"Randomizes the nonce and seed of a resource.","ref":"Anoma.Resource.html#unique/1"},{"type":"type","title":"Anoma.Resource.t/0","doc":"","ref":"Anoma.Resource.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Delta","doc":"","ref":"Anoma.Resource.Delta.html"},{"type":"function","title":"Anoma.Resource.Delta.add/2","doc":"","ref":"Anoma.Resource.Delta.html#add/2"},{"type":"function","title":"Anoma.Resource.Delta.empty/0","doc":"","ref":"Anoma.Resource.Delta.html#empty/0"},{"type":"function","title":"Anoma.Resource.Delta.from_noun/1","doc":"","ref":"Anoma.Resource.Delta.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.Delta.negate/1","doc":"","ref":"Anoma.Resource.Delta.html#negate/1"},{"type":"function","title":"Anoma.Resource.Delta.new/1","doc":"","ref":"Anoma.Resource.Delta.html#new/1"},{"type":"function","title":"Anoma.Resource.Delta.sub/2","doc":"","ref":"Anoma.Resource.Delta.html#sub/2"},{"type":"type","title":"Anoma.Resource.Delta.t/0","doc":"","ref":"Anoma.Resource.Delta.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Proof","doc":"","ref":"Anoma.Resource.Proof.html"},{"type":"type","title":"Anoma.Resource.Proof.t/0","doc":"","ref":"Anoma.Resource.Proof.html#t:t/0"},{"type":"module","title":"Anoma.Resource.ProofRecord","doc":"","ref":"Anoma.Resource.ProofRecord.html"},{"type":"function","title":"Anoma.Resource.ProofRecord.from_noun/1","doc":"","ref":"Anoma.Resource.ProofRecord.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.ProofRecord.prove/1","doc":"","ref":"Anoma.Resource.ProofRecord.html#prove/1"},{"type":"type","title":"Anoma.Resource.ProofRecord.t/0","doc":"","ref":"Anoma.Resource.ProofRecord.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Transaction","doc":"I represent a resource machine transaction","ref":"Anoma.Resource.Transaction.html"},{"type":"function","title":"Anoma.Resource.Transaction.from_noun/1","doc":"","ref":"Anoma.Resource.Transaction.html#from_noun/1"},{"type":"type","title":"Anoma.Resource.Transaction.t/0","doc":"","ref":"Anoma.Resource.Transaction.html#t:t/0"},{"type":"module","title":"Nock","doc":"Nock, a universal function on nouns.","ref":"Nock.html"},{"type":"function","title":"Nock.cons/2","doc":"","ref":"Nock.html#cons/2"},{"type":"function","title":"Nock.decrement_arm/0","doc":"","ref":"Nock.html#decrement_arm/0"},{"type":"function","title":"Nock.decrement_core/0","doc":"","ref":"Nock.html#decrement_core/0"},{"type":"function","title":"Nock.gas_meter/0","doc":"","ref":"Nock.html#gas_meter/0"},{"type":"function","title":"Nock.gas_meter/1","doc":"","ref":"Nock.html#gas_meter/1"},{"type":"function","title":"Nock.get_jet/1","doc":"","ref":"Nock.html#get_jet/1"},{"type":"function","title":"Nock.logics_core/0","doc":"","ref":"Nock.html#logics_core/0"},{"type":"function","title":"Nock.metered_nock/2","doc":"","ref":"Nock.html#metered_nock/2"},{"type":"function","title":"Nock.metered_nock/3","doc":"","ref":"Nock.html#metered_nock/3"},{"type":"function","title":"Nock.naive_nock/2","doc":"","ref":"Nock.html#naive_nock/2"},{"type":"function","title":"Nock.naive_nock/3","doc":"","ref":"Nock.html#naive_nock/3"},{"type":"function","title":"Nock.nock/2","doc":"","ref":"Nock.html#nock/2"},{"type":"function","title":"Nock.nock/3","doc":"","ref":"Nock.html#nock/3"},{"type":"function","title":"Nock.nock_0/1","doc":"","ref":"Nock.html#nock_0/1"},{"type":"function","title":"Nock.nock_1/1","doc":"","ref":"Nock.html#nock_1/1"},{"type":"function","title":"Nock.nock_2/2","doc":"","ref":"Nock.html#nock_2/2"},{"type":"function","title":"Nock.nock_3/1","doc":"","ref":"Nock.html#nock_3/1"},{"type":"function","title":"Nock.nock_4/1","doc":"","ref":"Nock.html#nock_4/1"},{"type":"function","title":"Nock.nock_5/2","doc":"","ref":"Nock.html#nock_5/2"},{"type":"function","title":"Nock.nock_6/3","doc":"","ref":"Nock.html#nock_6/3"},{"type":"function","title":"Nock.nock_7/2","doc":"","ref":"Nock.html#nock_7/2"},{"type":"function","title":"Nock.nock_8/2","doc":"","ref":"Nock.html#nock_8/2"},{"type":"function","title":"Nock.nock_9/2","doc":"","ref":"Nock.html#nock_9/2"},{"type":"function","title":"Nock.nock_10/3","doc":"","ref":"Nock.html#nock_10/3"},{"type":"function","title":"Nock.nock_11/2","doc":"","ref":"Nock.html#nock_11/2"},{"type":"function","title":"Nock.nock_11/3","doc":"","ref":"Nock.html#nock_11/3"},{"type":"function","title":"Nock.put_jet/2","doc":"","ref":"Nock.html#put_jet/2"},{"type":"function","title":"Nock.read_with_id/2","doc":"","ref":"Nock.html#read_with_id/2"},{"type":"function","title":"Nock.rm_core/0","doc":"","ref":"Nock.html#rm_core/0"},{"type":"function","title":"Nock.stdlib_core/0","doc":"","ref":"Nock.html#stdlib_core/0"},{"type":"function","title":"Nock.stdlib_layers/0","doc":"Gives the total numbers of layers in the standard library","ref":"Nock.html#stdlib_layers/0"},{"type":"type","title":"Nock.t/0","doc":"I contain environmental information on how Nock shall be evaluated.\n\nFor example  contain information on jettedness to\ndetermine if we should be using jets or not","ref":"Nock.html#t:t/0"},{"type":"module","title":"Nock.Bits","doc":"","ref":"Nock.Bits.html"},{"type":"function","title":"Nock.Bits.bit_list_to_integer/1","doc":"","ref":"Nock.Bits.html#bit_list_to_integer/1"},{"type":"function","title":"Nock.Bits.integer_to_bits/1","doc":"","ref":"Nock.Bits.html#integer_to_bits/1"},{"type":"function","title":"Nock.Bits.num_bits/2","doc":"","ref":"Nock.Bits.html#num_bits/2"},{"type":"module","title":"Nock.Cli","doc":"","ref":"Nock.Cli.html"},{"type":"function","title":"Nock.Cli.argument_option/0","doc":"","ref":"Nock.Cli.html#argument_option/0"},{"type":"function","title":"Nock.Cli.main/1","doc":"","ref":"Nock.Cli.html#main/1"},{"type":"module","title":"Nock.Cue","doc":"","ref":"Nock.Cue.html"},{"type":"function","title":"Nock.Cue.bit_width_tag/2","doc":"","ref":"Nock.Cue.html#bit_width_tag/2"},{"type":"function","title":"Nock.Cue.bit_width_tag/3","doc":"","ref":"Nock.Cue.html#bit_width_tag/3"},{"type":"function","title":"Nock.Cue.cue/1","doc":"","ref":"Nock.Cue.html#cue/1"},{"type":"function","title":"Nock.Cue.cue!/1","doc":"","ref":"Nock.Cue.html#cue!/1"},{"type":"function","title":"Nock.Cue.cue_tag/2","doc":"","ref":"Nock.Cue.html#cue_tag/2"},{"type":"function","title":"Nock.Cue.parse/1","doc":"","ref":"Nock.Cue.html#parse/1"},{"type":"function","title":"Nock.Cue.parse/2","doc":"","ref":"Nock.Cue.html#parse/2"},{"type":"function","title":"Nock.Cue.parse_single/2","doc":"","ref":"Nock.Cue.html#parse_single/2"},{"type":"function","title":"Nock.Cue.rub_no_index/2","doc":"","ref":"Nock.Cue.html#rub_no_index/2"},{"type":"type","title":"Nock.Cue.cue_tag/0","doc":"","ref":"Nock.Cue.html#t:cue_tag/0"},{"type":"type","title":"Nock.Cue.t/0","doc":"","ref":"Nock.Cue.html#t:t/0"},{"type":"module","title":"Nock.Jam","doc":"","ref":"Nock.Jam.html"},{"type":"function","title":"Nock.Jam.cache_noun/2","doc":"","ref":"Nock.Jam.html#cache_noun/2"},{"type":"function","title":"Nock.Jam.encode/2","doc":"","ref":"Nock.Jam.html#encode/2"},{"type":"function","title":"Nock.Jam.fetch_cache_noun/2","doc":"","ref":"Nock.Jam.html#fetch_cache_noun/2"},{"type":"function","title":"Nock.Jam.handle_back/3","doc":"","ref":"Nock.Jam.html#handle_back/3"},{"type":"function","title":"Nock.Jam.jam/1","doc":"","ref":"Nock.Jam.html#jam/1"},{"type":"function","title":"Nock.Jam.write/2","doc":"","ref":"Nock.Jam.html#write/2"},{"type":"function","title":"Nock.Jam.write_atom/2","doc":"","ref":"Nock.Jam.html#write_atom/2"},{"type":"function","title":"Nock.Jam.write_back_ref/2","doc":"","ref":"Nock.Jam.html#write_back_ref/2"},{"type":"function","title":"Nock.Jam.write_length/2","doc":"","ref":"Nock.Jam.html#write_length/2"},{"type":"type","title":"Nock.Jam.cache/0","doc":"","ref":"Nock.Jam.html#t:cache/0"},{"type":"type","title":"Nock.Jam.t/0","doc":"","ref":"Nock.Jam.html#t:t/0"},{"type":"module","title":"Nock.Jets","doc":"Jets for the Nock interpreter, taking a gate core. Not fully general.","ref":"Nock.Jets.html"},{"type":"function","title":"Nock.Jets.add/1","doc":"","ref":"Nock.Jets.html#add/1"},{"type":"function","title":"Nock.Jets.bex/1","doc":"","ref":"Nock.Jets.html#bex/1"},{"type":"function","title":"Nock.Jets.calculate_core_param/3","doc":"","ref":"Nock.Jets.html#calculate_core_param/3"},{"type":"function","title":"Nock.Jets.calculate_mug_of_core/2","doc":"We calculate the mug of a given core at a given gate.","ref":"Nock.Jets.html#calculate_mug_of_core/2"},{"type":"function","title":"Parameters - Nock.Jets.calculate_mug_of_core/2","doc":"- `index_in_core` - the index of the gate itself\n\n- `parent_layer` - the layer of the standard library. This should be\n  the same as the layer numbers found in `anoma.hoon`","ref":"Nock.Jets.html#calculate_mug_of_core/2-parameters"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_core/2","doc":"In the Hoon repl one should write\n\n    dojo> |commit %anoma\n    >=\n    dojo> =anoma -build-file /=anoma=/lib/anoma/hoon\n    dojo> =>  anoma  !=(sub)\n    [9 47 0 31]\n\nNow in IEX\n\n    > Nock.Jets.calculate_mug_of_core(47, 1)\n    14801825384048474882","ref":"Nock.Jets.html#calculate_mug_of_core/2-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_layer/1","doc":"We calculate the mug of a given layer at any given gate.","ref":"Nock.Jets.html#calculate_mug_of_layer/1"},{"type":"function","title":"Parameters - Nock.Jets.calculate_mug_of_layer/1","doc":"- `parent_layer` - the layer of the standard library. This should be\n  the same as the layer numbers found in `anoma.hoon`","ref":"Nock.Jets.html#calculate_mug_of_layer/1-parameters"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_layer/1","doc":"In the Hoon repl one should write\n\n    dojo> |commit %anoma\n    >=\n    dojo> =anoma -build-file /=anoma=/lib/anoma/hoon\n    dojo> =>  anoma  !=(sub)\n    [9 47 0 31]\n\nNow in IEX\n\n    > Nock.Jets.calculate_mug_of_layer(1)\n    17654928022549292273\n\nThis value should match Nock.@layer_1_contex_mug","ref":"Nock.Jets.html#calculate_mug_of_layer/1-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_param_core/3","doc":"Like `calculate_mug_of_core/2` except we work over a parameterized core.","ref":"Nock.Jets.html#calculate_mug_of_param_core/3"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_param_core/3","doc":"> Nock.Jets.calculate_mug_of_param_core(767, 10, 4)\n    12605872635346981159\n\nFor our standard library, so far only layer 4 is parameterized","ref":"Nock.Jets.html#calculate_mug_of_param_core/3-example"},{"type":"function","title":"Nock.Jets.calculate_mug_of_param_layer/2","doc":"Like `calculate_mug_of_layer/1` except we work over a parameterized core.","ref":"Nock.Jets.html#calculate_mug_of_param_layer/2"},{"type":"function","title":"Example - Nock.Jets.calculate_mug_of_param_layer/2","doc":"> Nock.Jets.calculate_mug_of_param_layer(10, 4)\n    11284470320276584209\n\nFor our standard library, so far only layer 4 is parameterized","ref":"Nock.Jets.html#calculate_mug_of_param_layer/2-example"},{"type":"function","title":"Nock.Jets.cue/1","doc":"","ref":"Nock.Jets.html#cue/1"},{"type":"function","title":"Nock.Jets.dec/1","doc":"","ref":"Nock.Jets.html#dec/1"},{"type":"function","title":"Nock.Jets.div/1","doc":"","ref":"Nock.Jets.html#div/1"},{"type":"function","title":"Nock.Jets.gte/1","doc":"","ref":"Nock.Jets.html#gte/1"},{"type":"function","title":"Nock.Jets.gth/1","doc":"","ref":"Nock.Jets.html#gth/1"},{"type":"function","title":"Nock.Jets.jam/1","doc":"","ref":"Nock.Jets.html#jam/1"},{"type":"function","title":"Nock.Jets.lsh/1","doc":"","ref":"Nock.Jets.html#lsh/1"},{"type":"function","title":"Nock.Jets.lte/1","doc":"","ref":"Nock.Jets.html#lte/1"},{"type":"function","title":"Nock.Jets.lth/1","doc":"","ref":"Nock.Jets.html#lth/1"},{"type":"function","title":"Nock.Jets.met/1","doc":"","ref":"Nock.Jets.html#met/1"},{"type":"function","title":"Nock.Jets.mix/1","doc":"","ref":"Nock.Jets.html#mix/1"},{"type":"function","title":"Nock.Jets.mod/1","doc":"","ref":"Nock.Jets.html#mod/1"},{"type":"function","title":"Nock.Jets.mul/1","doc":"","ref":"Nock.Jets.html#mul/1"},{"type":"function","title":"Nock.Jets.nend/1","doc":"","ref":"Nock.Jets.html#nend/1"},{"type":"function","title":"Nock.Jets.rsh/1","doc":"","ref":"Nock.Jets.html#rsh/1"},{"type":"function","title":"Nock.Jets.sample/1","doc":"","ref":"Nock.Jets.html#sample/1"},{"type":"function","title":"Nock.Jets.sign/1","doc":"","ref":"Nock.Jets.html#sign/1"},{"type":"function","title":"Nock.Jets.sign_detatched/1","doc":"","ref":"Nock.Jets.html#sign_detatched/1"},{"type":"function","title":"Nock.Jets.sub/1","doc":"","ref":"Nock.Jets.html#sub/1"},{"type":"function","title":"Nock.Jets.verify/1","doc":"","ref":"Nock.Jets.html#verify/1"},{"type":"function","title":"Nock.Jets.verify_detatched/1","doc":"","ref":"Nock.Jets.html#verify_detatched/1"},{"type":"module","title":"Noun","doc":"The noun data structure.\n\nRepresented as Elixir cons cells, which might get annoying.","ref":"Noun.html"},{"type":"function","title":"Noun.atom_binary_to_integer/1","doc":"","ref":"Noun.html#atom_binary_to_integer/1"},{"type":"function","title":"Noun.atom_integer_to_binary/1","doc":"","ref":"Noun.html#atom_integer_to_binary/1"},{"type":"function","title":"Noun.atom_integer_to_binary/2","doc":"","ref":"Noun.html#atom_integer_to_binary/2"},{"type":"function","title":"Noun.axis/2","doc":"","ref":"Noun.html#axis/2"},{"type":"function","title":"Noun.condensed_print/1","doc":"","ref":"Noun.html#condensed_print/1"},{"type":"function","title":"Noun.equal/2","doc":"","ref":"Noun.html#equal/2"},{"type":"function","title":"Noun.index_to_offset/1","doc":"Calculates the index from the given access offset","ref":"Noun.html#index_to_offset/1"},{"type":"macro","title":"Noun.is_noun_atom/1","doc":"","ref":"Noun.html#is_noun_atom/1"},{"type":"macro","title":"Noun.is_noun_cell/1","doc":"","ref":"Noun.html#is_noun_cell/1"},{"type":"function","title":"Noun.is_zero/1","doc":"","ref":"Noun.html#is_zero/1"},{"type":"function","title":"Noun.list_nock_to_erlang/1","doc":"","ref":"Noun.html#list_nock_to_erlang/1"},{"type":"function","title":"Noun.mug/1","doc":"","ref":"Noun.html#mug/1"},{"type":"function","title":"Noun.normalize_noun/1","doc":"","ref":"Noun.html#normalize_noun/1"},{"type":"function","title":"Noun.pad_trailing/2","doc":"","ref":"Noun.html#pad_trailing/2"},{"type":"function","title":"Noun.replace/3","doc":"","ref":"Noun.html#replace/3"},{"type":"function","title":"Noun.to_normalized_noun/1","doc":"","ref":"Noun.html#to_normalized_noun/1"},{"type":"type","title":"Noun.noun_atom/0","doc":"","ref":"Noun.html#t:noun_atom/0"},{"type":"type","title":"Noun.noun_cell/0","doc":"","ref":"Noun.html#t:noun_cell/0"},{"type":"type","title":"Noun.t/0","doc":"","ref":"Noun.html#t:t/0"},{"type":"module","title":"Noun.Format","doc":"Parsing and printing of nouns.","ref":"Noun.Format.html"},{"type":"function","title":"Noun.Format.parse/1","doc":"","ref":"Noun.Format.html#parse/1"},{"type":"function","title":"Noun.Format.parse_always/1","doc":"","ref":"Noun.Format.html#parse_always/1"},{"type":"function","title":"Noun.Format.parse_cell/1","doc":"","ref":"Noun.Format.html#parse_cell/1"},{"type":"function","title":"Noun.Format.parse_inner/1","doc":"","ref":"Noun.Format.html#parse_inner/1"},{"type":"function","title":"Noun.Format.parse_tail/1","doc":"","ref":"Noun.Format.html#parse_tail/1"},{"type":"function","title":"Noun.Format.print/1","doc":"","ref":"Noun.Format.html#print/1"},{"type":"function","title":"Noun.Format.print_tail/1","doc":"","ref":"Noun.Format.html#print_tail/1"},{"type":"protocol","title":"Noun.Nounable","doc":"","ref":"Noun.Nounable.html"},{"type":"function","title":"Noun.Nounable.to_noun/1","doc":"I turn the transaction into a noun","ref":"Noun.Nounable.html#to_noun/1"},{"type":"type","title":"Noun.Nounable.t/0","doc":"All the types that implement this protocol.","ref":"Noun.Nounable.html#t:t/0"},{"type":"behaviour","title":"Noun.Nounable.Kind","doc":"","ref":"Noun.Nounable.Kind.html"},{"type":"callback","title":"Noun.Nounable.Kind.from_noun/1","doc":"I convert the given `t:Noun.t/0` into the given structure","ref":"Noun.Nounable.Kind.html#c:from_noun/1"},{"type":"module","title":"Anoma.Node","doc":"I act as a registry for Anoma Nodes\n\nThere are two ways to launch a Node. Either with minimal\narguments or having the full specification for all the\nengines, including their external ID's.\n\nAll inputs should come in format of a list of atom-value\n2-tuples, `{:settings, map()}` specifying the info on\nall relevant engines and storages possibly including their\ntables presented in a dumped format, `{:name, atom()}`\nspecifying the name of the node, and `{:new_storage, bool()}`\nspecifying whether the table names, if supplied, need to be\nset-up without any deletions.\n\nFor more info on format check `start_min/1`","ref":"Anoma.Node.html"},{"type":"module","title":"Minimal Arguments - Anoma.Node","doc":"- `name` - name for this process\n  - `snapshot_path` : [`atom()` | 0]\n    - A snapshot location for the service (used in the worker)\n  - `storage` : `Anoma.Node.Storage.t()` - The Storage tables to use\n  - `block_storage` - a location to store the blocks produced","ref":"Anoma.Node.html#module-minimal-arguments"},{"type":"module","title":"Created Tables - Anoma.Node","doc":"- `storage.qualified`\n  - `storage.order`\n  - `block_storage`","ref":"Anoma.Node.html#module-created-tables"},{"type":"function","title":"Anoma.Node.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.html#child_spec/1"},{"type":"function","title":"Anoma.Node.init/1","doc":"","ref":"Anoma.Node.html#init/1"},{"type":"function","title":"Anoma.Node.raw_storage/1","doc":"I give the storage from a node.\n\nThis is useful when we want to bring storage to a new node.","ref":"Anoma.Node.html#raw_storage/1"},{"type":"function","title":"Anoma.Node.start_link/1","doc":"I assume I am fed a list with atom-value 2-tuples\n:name, :settings, :use_rocks. The value of :settings is a 2-tuple\nwith the first component matching either :new_storage or :from_dump.\nIf the former case, I need a :snapshot_path key in the settings.\nFor the latter case, check Anoma.Dump for format descriptions of\nthe settings.\n\nI ensure that the storages are deleted and created.\nAfterwards, if the storage is truly new, I put the snapshot\nin the ordering. Otherwise, I simply repopulate the tables\nfrom a supplied list by the settings.\nIf :use_rocks has value true, I use rocksdb as storage backend.","ref":"Anoma.Node.html#start_link/1"},{"type":"function","title":"Anoma.Node.start_link_or_find_instance/1","doc":"I work just like `start_link/1` except I give back the pid directly\nif the node is already started.\n\nThis is preferable in tests, as we wish to have them be robust upon\nrerunning.","ref":"Anoma.Node.html#start_link_or_find_instance/1"},{"type":"function","title":"Anoma.Node.start_min/1","doc":"Given minimal arguments, I create appropriate setup for the\n`:settings` argument for Node initialization.","ref":"Anoma.Node.html#start_min/1"},{"type":"function","title":"Anoma.Node.state/1","doc":"","ref":"Anoma.Node.html#state/1"},{"type":"type","title":"Anoma.Node.configuration/0","doc":"I am the configuration type for the `Anoma.Node`.\n\n contain information necessary for tweaking the behavior of the\n`Anoma.Node` application. See my `Fields` section for more\ninformation on how my behavior changes the node.","ref":"Anoma.Node.html#t:configuration/0"},{"type":"type","title":"Fields - Anoma.Node.configuration/0","doc":"- `:use_rocks` - determines if we wish to use rocksdb, or use mnesia\n in memory database\n\n - `:settings` - are the engine specific and anoma node configuration\n   settings. See `node_settings/0` for more details\n - `:testing` is a flag that specifies if the node being launched is\n   for testing purposes. Currently this just affects if we take up\n   the standard socket over the current `Anoma` instance or not.","ref":"Anoma.Node.html#t:configuration/0-fields"},{"type":"type","title":"Anoma.Node.engine_configuration/0","doc":"","ref":"Anoma.Node.html#t:engine_configuration/0"},{"type":"type","title":"Anoma.Node.min_engine_configuration/0","doc":"","ref":"Anoma.Node.html#t:min_engine_configuration/0"},{"type":"type","title":"Anoma.Node.node_settings/0","doc":"I am the node settings\n\nI can be resumed from two states, either from new/fresh storage in\nwhich I just have a `engine_configuration/0` or from a previously\ndumped configuration. In which case I contain `t:Anoma.Dump.dump/0`.\n\nIf the mode is in `:new_storage`, then  just contain `Engine`\nspecific configuration settings. However if I'm a `:from_dump` then\n have a superset of that information containing `mnesia` table\nconfiguration information as well.","ref":"Anoma.Node.html#t:node_settings/0"},{"type":"type","title":"Anoma.Node.t/0","doc":"","ref":"Anoma.Node.html#t:t/0"},{"type":"module","title":"Anoma.Node.Mempool","doc":"I am the Mempool Engine.\n\nI provide the interface for transaction management including\ncommunication with the Executor engine to create transaction candidates\nwith given code, executing said transactions, and creating appropriate\nblocks.","ref":"Anoma.Node.Mempool.html"},{"type":"module","title":"Public API - Anoma.Node.Mempool","doc":"I provide the following public functionality:\n\n- `execute/1`\n- `soft_reset/1`\n- `hard_reset/1`\n- `tx/2`","ref":"Anoma.Node.Mempool.html#module-public-api"},{"type":"function","title":"Anoma.Node.Mempool.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Mempool.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Mempool.choose_and_execute_ordering/2","doc":"I order the transactions based on the current ordering specified by the\nOrdering engine, place a new orderig, and for every ordered transaction,\nsend to their appropriate Worker a `:write_ready` message.\n\nReturn :ok.","ref":"Anoma.Node.Mempool.html#choose_and_execute_ordering/2"},{"type":"function","title":"Anoma.Node.Mempool.execute/1","doc":"I am the execution function.\n\nI execute the block containing top 100 transaction candidates availiable,\nordering them using the specified Ordering Engine.","ref":"Anoma.Node.Mempool.html#execute/1"},{"type":"function","title":"Anoma.Node.Mempool.handle_cast/3","doc":"","ref":"Anoma.Node.Mempool.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Mempool.handle_execute/1","doc":"I handle Mempool execution.\n\nI take the top 100 transaction candidates, ask for an ordering on them,\nproducing and storing an encoded block.\n\nI return a tuple with first entry specifying how many transactions got\ninto the execution and a new appropriately changed state.","ref":"Anoma.Node.Mempool.html#handle_execute/1"},{"type":"function","title":"Anoma.Node.Mempool.handle_tx/3","doc":"I handle the transaction candidate creation.\n\nGiven transaction code and the Mempool state, I ask the Executor to fire\na new transaction with a randomly generated transaction ID.\n\nI reply with a newly created transaction and specified Worker.","ref":"Anoma.Node.Mempool.html#handle_tx/3"},{"type":"function","title":"Anoma.Node.Mempool.hard_reset/1","doc":"I am the hard reset function.\n\nSimilar to `soft_reset/1`, I kill transactions, but also call for an\nExecutor snapshot, delete the block table and hard reset the Ordering\nEngine. The block table is then re-launched with the same rocks flag as\nbefore.","ref":"Anoma.Node.Mempool.html#hard_reset/1"},{"type":"function","title":"Anoma.Node.Mempool.init/1","doc":"I am the initialization function for a Mempool Engine instance.","ref":"Anoma.Node.Mempool.html#init/1"},{"type":"function","title":"Pattern-Macthing Variations - Anoma.Node.Mempool.init/1","doc":"- `init(%Mempool{})` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist with all keys in the structure fields\n                 listed necessary for the Mempool Engine to start. I then\n                 create a table with the given `:block_storage` argument\n                 and initialize an instance with given parameters.","ref":"Anoma.Node.Mempool.html#init/1-pattern-macthing-variations"},{"type":"function","title":"Anoma.Node.Mempool.kill_transactions/1","doc":"I kill transactions listed in the fed-in state.\n\nGiven a state with a list of transaction candidates, I call for the\nExecutor engine to kill each one in the list.","ref":"Anoma.Node.Mempool.html#kill_transactions/1"},{"type":"function","title":"Anoma.Node.Mempool.order/2","doc":"I order a list of transactions based on a given order.\n\nGiven a list of transaction candidates and an order number, I shuffle the\ntransactions, and index them starting with the given order number.","ref":"Anoma.Node.Mempool.html#order/2"},{"type":"function","title":"Anoma.Node.Mempool.order_format/2","doc":"I order a transaction structure by giving it an index.\n\nGiven a transaction candidate and an order, I put the index specified by\nthe input as its `:index` field value.","ref":"Anoma.Node.Mempool.html#order_format/2"},{"type":"function","title":"Anoma.Node.Mempool.persistent_transaction/1","doc":"I give core information on a transaction candidate.\n\nGiven a transaction candidate, I return a tuple. The first element is the\nid of the transaction. The second element is the transaction code.","ref":"Anoma.Node.Mempool.html#persistent_transaction/1"},{"type":"function","title":"Anoma.Node.Mempool.produce_block/2","doc":"I produce a block with the key and round from the given state and eturn it.","ref":"Anoma.Node.Mempool.html#produce_block/2"},{"type":"function","title":"Anoma.Node.Mempool.reset_blocks/1","doc":"I provide block-resetting functionality.\n\nI delete the mnesia table for block storage provided in the given state.\n\nI then create the table with the same name and rocks flag.","ref":"Anoma.Node.Mempool.html#reset_blocks/1"},{"type":"function","title":"Anoma.Node.Mempool.reset_state/1","doc":"I return a state with no transactions and 0 round count.","ref":"Anoma.Node.Mempool.html#reset_state/1"},{"type":"function","title":"Anoma.Node.Mempool.save_block/2","doc":"I save a provided block.\n\nGiven a Mempool Engine state and a block, I encode the block and write it\nat the specified mnesia table.","ref":"Anoma.Node.Mempool.html#save_block/2"},{"type":"function","title":"Anoma.Node.Mempool.soft_reset/1","doc":"I am the soft reset function.\n\nI empty the transaction and round fields of the appropriate Mempool\nEngine, asking the linked Executor to kill relevant transaction Workers.","ref":"Anoma.Node.Mempool.html#soft_reset/1"},{"type":"function","title":"Anoma.Node.Mempool.tx/3","doc":"I am the transaction candidate creating API.\n\nGiven a Mempool Engine address and a transaction candidate code, I ask\nthe Executor Engine to fire a new transaction with a random ID created in\nthe process. The value computed by the transactions (for read-only\ntransactions) will be sent to reply_to address. I return the new state,\nadding the transaction.","ref":"Anoma.Node.Mempool.html#tx/3"},{"type":"type","title":"Anoma.Node.Mempool.t/0","doc":"I am the type of the Mempool Engine.\n\nMy fields store information necessary to successfully call for\ntransaction candidate creation, execution, and ordering requests.","ref":"Anoma.Node.Mempool.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Mempool.t/0","doc":"- `:ordering` - The Ordering Engine Address.\n- `:executor` - The Executor Engine Address.\n- `:block_storage` - The name of the storage for created blocks.\n                     Default: `Anoma.Block`\n- `:transactions` - List of transaction candidates. Currently these do\n                    not have index info. That is handled by the\n                    Ordering engine.\n                    Default: []\n- `:round` - The block round information.\n             Default: 0\n- `:topic` - The topic address for broadcasting.\n- `:key` - The key used for block creation.\n           Default: `:crypto.generate_key(:rsa, {1024, 65537}`\n- `:logger` - The address of the Logger Engine.\n              Enforced: false","ref":"Anoma.Node.Mempool.html#t:t/0-fields"},{"type":"type","title":"Anoma.Node.Mempool.transactions/0","doc":"I am a list of transaction candidates.","ref":"Anoma.Node.Mempool.html#t:transactions/0"},{"type":"module","title":"Anoma.Node.Executor","doc":"I am the Executor Engine.\n\nMy main responsibility is to be the intermediary between the Mempool and\ntransaction spawning by launching the Worker Engines provided the pending\ntransaction code.","ref":"Anoma.Node.Executor.html"},{"type":"module","title":"API - Anoma.Node.Executor","doc":"My public facing API is\n\n- `snapshot/1`\n- `kill_transactions/2`\n- `fire_new_transaction/4`","ref":"Anoma.Node.Executor.html#module-api"},{"type":"function","title":"Anoma.Node.Executor.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Executor.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Executor.fire_new_transaction/5","doc":"I am a function spawning a new transaction.\n\nI do so by spawning a new engine with the info provided. If the\nenvironment is left unspecified I launch the Worker with the given\nambient environment stored in the state.\nThe computed value will be sent to the specified reply-to address.","ref":"Anoma.Node.Executor.html#fire_new_transaction/5"},{"type":"function","title":"Anoma.Node.Executor.handle_cast/3","doc":"","ref":"Anoma.Node.Executor.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Executor.init/1","doc":"","ref":"Anoma.Node.Executor.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Executor.init/1","doc":"- `init(%Executor{})` - I initialize the Engine with the given state.\n- `init({router, env, topic, logger})` - I expect a tuple with needed\n                                         arguments to launch the executor.","ref":"Anoma.Node.Executor.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Executor.kill_transactions/2","doc":"I am a function killing transactions.\n\nI currently do not filter through which transactions to kill. I just go\nthrough the list of all Workers stored in my state and kill their\nprocesses one by one. The returned state will have a nil list for the\ncurrent worker list.","ref":"Anoma.Node.Executor.html#kill_transactions/2"},{"type":"function","title":"Anoma.Node.Executor.snapshot/1","doc":"I return the snapshot path.","ref":"Anoma.Node.Executor.html#snapshot/1"},{"type":"type","title":"Anoma.Node.Executor.t/0","doc":"I am the type of the Executor Engine.","ref":"Anoma.Node.Executor.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Executor.t/0","doc":"- `:router` - The Router Engine address used by the Executor.\n- `:topic` - The topic for broadcasting.\n- `:ambiant_env` - The default environment to be fed to spawned workers.\n- `:workers` - A list of worker addresses spawned.\n               Default: []\n- `:logger` - The Logger Engine address.\n              Enforced: false","ref":"Anoma.Node.Executor.html#t:t/0-fields"},{"type":"module","title":"Anoma.Node.Executor.Worker","doc":"I am the Worker Engine.\n\nMy instance gets launched by the Executor and is connected to a unique\ntransaction.\n\nI am responsible for the main work done to run a successful transaction\nlifecycle. This includes processing of transactions, calling for their\nordering via the Ordering Engine, creation and revision of commitment\ntrees, nullifier key-checking, as well as the storage of relevant data\nfor transaction completion before block-execution.","ref":"Anoma.Node.Executor.Worker.html"},{"type":"module","title":"Public API - Anoma.Node.Executor.Worker","doc":"I provide the following public functionality:\n\n- `rm_nullifier_check/2`","ref":"Anoma.Node.Executor.Worker.html#module-public-api"},{"type":"function","title":"Anoma.Node.Executor.Worker.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Executor.Worker.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Executor.Worker.init/1","doc":"I am the Worker initialization function.\n\nI send myself a `:run` message which launches my core functionality and\nreturn the appropriate state.","ref":"Anoma.Node.Executor.Worker.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Executor.Worker.init/1","doc":"- `init({id, tx, env, completion_topic, reply_to})` - I receive a tuple with all\n                                                      the specified info to launch\n                                                      a Worker instance.","ref":"Anoma.Node.Executor.Worker.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Executor.Worker.rm_nullifier_check/2","doc":"I perform the nullifier check for a resource machine transaction.\n\nGiven a storage and a list of stored nullifiers I check their placing in storage.","ref":"Anoma.Node.Executor.Worker.html#rm_nullifier_check/2"},{"type":"type","title":"Anoma.Node.Executor.Worker.backend/0","doc":"","ref":"Anoma.Node.Executor.Worker.html#t:backend/0"},{"type":"type","title":"Anoma.Node.Executor.Worker.t/0","doc":"I am the type of a Worker Engine instance.\n\nI contain all the info for appropriate transaction processing.","ref":"Anoma.Node.Executor.Worker.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Executor.Worker.t/0","doc":"- `:id` - The ID of the transaction fed in.\n- `:tx` - The transaction code.\n- `:env` - The environment for the transaction to be evaluated in. E.g.\n           contains the Ordering engine address. See `Nock.t()`\n- `:completion_topic` - The address of the topic connected to the\n                        relevant Executor Engine for broadcasting.\n- `:reply_to` - The address that the computed value (for read-only\n                transaction) is sent to.","ref":"Anoma.Node.Executor.Worker.html#t:t/0-fields"},{"type":"type","title":"Anoma.Node.Executor.Worker.transaction/0","doc":"","ref":"Anoma.Node.Executor.Worker.html#t:transaction/0"},{"type":"module","title":"Anoma.Identity.Backend","doc":"I determine which backend to use in order to generate or connect an identity.","ref":"Anoma.Identity.Backend.html"},{"type":"type","title":"Anoma.Identity.Backend.t/0","doc":"","ref":"Anoma.Identity.Backend.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Backend.Local","doc":"I represent generating the keys on some sort of local storage that\nis connected to Anoma","ref":"Anoma.Identity.Backend.Local.html"},{"type":"type","title":"Anoma.Identity.Backend.Local.t/0","doc":"","ref":"Anoma.Identity.Backend.Local.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Backend.Memory","doc":"I keep the identity in memory. I may or may not persisting across\nreboots. This depends if the table is set to disc_only copies, or\nmemory_copies","ref":"Anoma.Identity.Backend.Memory.html"},{"type":"type","title":"Anoma.Identity.Backend.Memory.t/0","doc":"We determine the information needed to properly store a memory copy.","ref":"Anoma.Identity.Backend.Memory.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Identity.Backend.Memory.t/0","doc":"- `symmetric` - this is a symmetric encryption/decryption key\n    known by the user and the system. This key will be used to\n    encrypt the public and private key, and along with the\n    `External.t/1` can index into table\n\n - `storage` - this is the storage where in memory this will be stored","ref":"Anoma.Identity.Backend.Memory.html#t:t/0-fields"},{"type":"module","title":"Anoma.Identity.Backend.Remote","doc":"I denote that the identity creation should be routed to some\n`t:Anoma.Crypto.Id.Extern.t/0`","ref":"Anoma.Identity.Backend.Remote.html"},{"type":"type","title":"Anoma.Identity.Backend.Remote.t/0","doc":"","ref":"Anoma.Identity.Backend.Remote.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Capabilities","doc":"I specify which capabilities to request when generating a new\nidentity or connecting an existing one.","ref":"Anoma.Identity.Capabilities.html"},{"type":"function","title":"Anoma.Identity.Capabilities.commit/0","doc":"","ref":"Anoma.Identity.Capabilities.html#commit/0"},{"type":"function","title":"Anoma.Identity.Capabilities.commit_and_decrypt/0","doc":"","ref":"Anoma.Identity.Capabilities.html#commit_and_decrypt/0"},{"type":"function","title":"Anoma.Identity.Capabilities.decrypt/0","doc":"","ref":"Anoma.Identity.Capabilities.html#decrypt/0"},{"type":"type","title":"Anoma.Identity.Capabilities.t/0","doc":"","ref":"Anoma.Identity.Capabilities.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Encapsulated","doc":"I contain the information necessary for engines like:\n  - `Anoma.Node.Identity.Decryption`\n  - `Anoma.Node.Identity.Commitment`\n\nto operate.\n\nTo speak plainly, I contain the secret information necessary to\ndecrypt and encrypt messages","ref":"Anoma.Identity.Encapsulated.html"},{"type":"type","title":"Anoma.Identity.Encapsulated.t/0","doc":"","ref":"Anoma.Identity.Encapsulated.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Encryption","doc":"I am responsible for encrypting messages to external identities. It\nautomatically uses \"reads for\" relationship information from the\nReads For Engine along with caller preference information in order\nto choose which identity to encrypt to.","ref":"Anoma.Identity.Encryption.html"},{"type":"function","title":"Anoma.Identity.Encryption.seal/3","doc":"","ref":"Anoma.Identity.Encryption.html#seal/3"},{"type":"module","title":"Anoma.Identity.Evidence","doc":"","ref":"Anoma.Identity.Evidence.html"},{"type":"type","title":"Anoma.Identity.Evidence.name/0","doc":"","ref":"Anoma.Identity.Evidence.html#t:name/0"},{"type":"type","title":"Anoma.Identity.Evidence.t/1","doc":"","ref":"Anoma.Identity.Evidence.html#t:t/1"},{"type":"module","title":"Anoma.Identity.Manager","doc":"I am responsible for generating, connecting, and deleting identities.\n\nI abstracts a uniform interface over identities created with\ndifferent \"backends\", including, for example:\n\n  - internal identities stored in local memory\n  - internal identities stored in a hardware device, e.g. Ledger\n  - internal identities stored in a browser extension\n  - internal identities stored in another machine accessible over the network\n\nWhen an identity is generated or connected, I do not return the\ninternal identity directly, but rather return handles to the\ncorresponding commitment and decryption engine instances, which can\nbe used to generate commitments by and decrypt data encrypted to,\nrespectively, the internal identity (which is still kept in whatever\nbackend is in use).","ref":"Anoma.Identity.Manager.html"},{"type":"function","title":"Anoma.Identity.Manager.connect/3","doc":"","ref":"Anoma.Identity.Manager.html#connect/3"},{"type":"function","title":"Anoma.Identity.Manager.delete/2","doc":"I delete the given key.\n\nNote that depending on the backend the following could happen:\n\n1. If there is an active Decryption and Commitment engine and the\n   backend is a memory backend, then the keys can still be used for\n   singing and decryption. However once these engines die there is\n   not a way to get them back after deletion.\n2. If there is an active Decryption and Commitment engine and the\n   backend is external, then they can't be used anymore as the\n   actual keys are gone from the external device.\n3. One can no longer connect to the key given it does not exist in\n   the system anymore","ref":"Anoma.Identity.Manager.html#delete/2"},{"type":"function","title":"Anoma.Identity.Manager.generate/3","doc":"","ref":"Anoma.Identity.Manager.html#generate/3"},{"type":"function","title":"Anoma.Identity.Manager.name_space/0","doc":"","ref":"Anoma.Identity.Manager.html#name_space/0"},{"type":"type","title":"Anoma.Identity.Manager.instance/0","doc":"","ref":"Anoma.Identity.Manager.html#t:instance/0"},{"type":"type","title":"Anoma.Identity.Manager.resp/1","doc":"","ref":"Anoma.Identity.Manager.html#t:resp/1"},{"type":"module","title":"Anoma.Identity.Name","doc":"","ref":"Anoma.Identity.Name.html"},{"type":"function","title":"Anoma.Identity.Name.add/3","doc":"Adds the given key to the given namespace. The signer who owns the\nnamespace must have signed.","ref":"Anoma.Identity.Name.html#add/3"},{"type":"function","title":"Anoma.Identity.Name.all_identities/2","doc":"","ref":"Anoma.Identity.Name.html#all_identities/2"},{"type":"function","title":"Anoma.Identity.Name.name_space/0","doc":"","ref":"Anoma.Identity.Name.html#name_space/0"},{"type":"function","title":"Anoma.Identity.Name.reserve_namespace/4","doc":"","ref":"Anoma.Identity.Name.html#reserve_namespace/4"},{"type":"type","title":"Anoma.Identity.Name.t/0","doc":"","ref":"Anoma.Identity.Name.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Parameters","doc":"I specify what parameters to use when generating a new identity.","ref":"Anoma.Identity.Parameters.html"},{"type":"type","title":"Anoma.Identity.Parameters.t/0","doc":"","ref":"Anoma.Identity.Parameters.html#t:t/0"},{"type":"module","title":"Anoma.Identity.SignsFor","doc":"","ref":"Anoma.Identity.SignsFor.html"},{"type":"function","title":"Anoma.Identity.SignsFor.known/2","doc":"","ref":"Anoma.Identity.SignsFor.html#known/2"},{"type":"function","title":"Anoma.Identity.SignsFor.name_space/0","doc":"","ref":"Anoma.Identity.SignsFor.html#name_space/0"},{"type":"function","title":"Anoma.Identity.SignsFor.sign_for/2","doc":"","ref":"Anoma.Identity.SignsFor.html#sign_for/2"},{"type":"function","title":"Anoma.Identity.SignsFor.signs_for?/3","doc":"","ref":"Anoma.Identity.SignsFor.html#signs_for?/3"},{"type":"module","title":"Anoma.Identity.Verification","doc":"I am responsible for verifying commitments made by external\nidentities. I automatically uses \"signs for\" relationship\ninformation from the Anoma.Identity.SignsFor along with caller preference\ninformation in order to choose how to verify a commitment.","ref":"Anoma.Identity.Verification.html"},{"type":"function","title":"Anoma.Identity.Verification.verify_combined/3","doc":"","ref":"Anoma.Identity.Verification.html#verify_combined/3"},{"type":"function","title":"Anoma.Identity.Verification.verify_request/4","doc":"","ref":"Anoma.Identity.Verification.html#verify_request/4"},{"type":"module","title":"Anoma.Node.Identity.Commitment","doc":"","ref":"Anoma.Node.Identity.Commitment.html"},{"type":"function","title":"Anoma.Node.Identity.Commitment.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Identity.Commitment.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Identity.Commitment.commit/2","doc":"","ref":"Anoma.Node.Identity.Commitment.html#commit/2"},{"type":"function","title":"Anoma.Node.Identity.Commitment.commit_combined/2","doc":"","ref":"Anoma.Node.Identity.Commitment.html#commit_combined/2"},{"type":"function","title":"Anoma.Node.Identity.Commitment.init/1","doc":"","ref":"Anoma.Node.Identity.Commitment.html#init/1"},{"type":"function","title":"Anoma.Node.Identity.Commitment.start_link/1","doc":"","ref":"Anoma.Node.Identity.Commitment.html#start_link/1"},{"type":"module","title":"Anoma.Node.Identity.Decryption","doc":"","ref":"Anoma.Node.Identity.Decryption.html"},{"type":"function","title":"Anoma.Node.Identity.Decryption.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Identity.Decryption.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Identity.Decryption.decrypt/2","doc":"","ref":"Anoma.Node.Identity.Decryption.html#decrypt/2"},{"type":"function","title":"Anoma.Node.Identity.Decryption.init/1","doc":"","ref":"Anoma.Node.Identity.Decryption.html#init/1"},{"type":"function","title":"Anoma.Node.Identity.Decryption.start_link/1","doc":"","ref":"Anoma.Node.Identity.Decryption.html#start_link/1"},{"type":"module","title":"Anoma.Node.IntentPool","doc":"","ref":"Anoma.Node.IntentPool.html"},{"type":"function","title":"Anoma.Node.IntentPool.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.IntentPool.html#child_spec/1"},{"type":"function","title":"Anoma.Node.IntentPool.handle_cast/3","doc":"","ref":"Anoma.Node.IntentPool.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.IntentPool.init/1","doc":"","ref":"Anoma.Node.IntentPool.html#init/1"},{"type":"function","title":"Anoma.Node.IntentPool.intents/1","doc":"","ref":"Anoma.Node.IntentPool.html#intents/1"},{"type":"function","title":"Anoma.Node.IntentPool.new_intent/2","doc":"","ref":"Anoma.Node.IntentPool.html#new_intent/2"},{"type":"function","title":"Anoma.Node.IntentPool.remove_intent/2","doc":"","ref":"Anoma.Node.IntentPool.html#remove_intent/2"},{"type":"type","title":"Anoma.Node.IntentPool.intents/0","doc":"","ref":"Anoma.Node.IntentPool.html#t:intents/0"},{"type":"type","title":"Anoma.Node.IntentPool.t/0","doc":"","ref":"Anoma.Node.IntentPool.html#t:t/0"},{"type":"module","title":"Anoma.Node.Storage","doc":"I am the Anoma Storage Engine.\n\nThe Anoma database usage is separated into two parts:\n\n1) The Ordering table provides info on the order of appropriate keys.\n   That is, it has info about how many times the key has been assigned to\n   some value.\n\n2) The Qualified table provides a representation of all stored key-values\n   in a particular format. Each entry has inside it\n\n   1) The table name attached\n   2) The order of the key given by the Ordering\n   3) The namespace idenifying the Storage Engine\n   4) The key itself as provided by the user.\n\nAs a Storage Engine, I provide the appropriate functionality\nto coordinate the Ordering and Qualified tables of a launched Anoma Node.\n\nThat is, I help with writing things respecting the ordering of events\nwhile providing appropriate reading capabilities of the tables used, so\nthat the base read events read only the latest value of a given key.","ref":"Anoma.Node.Storage.html"},{"type":"module","title":"Public API - Anoma.Node.Storage","doc":"I provide the following public functionality:\n\n#### Setup\n\n- `setup/1`\n- `remove/1`\n- `do_setup/1`\n- `ensure_new/2`\n- `do_ensure_new/2`\n\n#### Writing\n\n- `put_snapshot/2`\n- `delete_key/2`\n- `put/3`\n\n#### Reading\n\n- `snapshot_order/1`\n- `get/2`\n- `get_keyspace/2`\n- `get_at_snapshot/2`\n- `in_snapshot/2`\n- `read_order/2`\n- `read_order_tx/2`\n- `read_at_order/3`\n- `read_at_order_tx/3`\n\n\n#### Blocking\n\n- `blocking_read/2`\n\n#### Other\n\n- `cm_tree_spec/0`","ref":"Anoma.Node.Storage.html#module-public-api"},{"type":"function","title":"Anoma.Node.Storage.blocking_read/2","doc":"I provide the final part of the blocking functionality for the Worker\nnecessary for transaction-execution.","ref":"Anoma.Node.Storage.html#blocking_read/2"},{"type":"function","title":"General Usage - Anoma.Node.Storage.blocking_read/2","doc":"I expect a Storage Engine address alongside with a key. Given a key which\nisn't a list, I error. Given a key which is a list starting with 0, I\nerror following Nock and Ordering semantics. Given any other list, I\nsubscribe to a Qualified table that is attached to the given Storage and\nread it in the Qualified table.\n\nIf the key has a non-empty value in the table, I return `{:ok, value}`\nand unsubscribe from the table.\n\nIf the key does not have a value in the table, I wait until I receive a\n`:write` message from the table, where the key written is exactly the key\nsupplied. Given the message, I return the written value as `{:ok, value}`\nand unsubscribe from the table.","ref":"Anoma.Node.Storage.html#blocking_read/2-general-usage"},{"type":"function","title":"Anoma-Intended Semantics - Anoma.Node.Storage.blocking_read/2","doc":"My intended use in the Anoma Lifecycle is as follows:\n\nI am called by the Worker after assigning its transaction ID to the order\nassigned for block-generation. The key here is given as a cell of form\n[n | snapshot_path] where `n` is a natural number representing the `n`-th\ntransaction candidate - i.e. the order of the transaction the Worker is\noccupied with - and snapshot_path is a Nock list, i.e. an improper list\nof form `[... | <<>>]`.\n\nMy main functionality is to make sure that the value of said transaction\nhas been recorded successfully in the Qualified table in the following\nway:\n\nAfter subscribing to the appropriate Qualified table, I first check the\nfed-in Nock noun. If it starts with 0, I produce `:error`, per standard\nsemantics. Given another Nock cell, we then read it as a key inside our\nQualified table. If the value has already been written, we return it as\nan `{:ok, value}` tuple.\n\nOtherwise, if we read-off an empty list, i.e. if the appropriate\ntransaction value has not been written, we wait for the message that the\nexact key has been written with some value in the table. Then we return\nthe value written in an `{:ok, value}` tuple.","ref":"Anoma.Node.Storage.html#blocking_read/2-anoma-intended-semantics"},{"type":"function","title":"Anoma.Node.Storage.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Storage.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Storage.delete_key/2","doc":"I provide the main tombstoning functionality for the Storage Engine.\n\nMy main goal is to provide the API to make a key indistinguishable from\nbeing absent in the underlying table. That is, I use `put/3` to make the\nlatest key value `:absent`. This way, I make it impossible to distinguish\nbetween the given key never been put into the Qualified table and being\ndeleted using the main `get/2` functionality.","ref":"Anoma.Node.Storage.html#delete_key/2"},{"type":"function","title":"Anoma.Node.Storage.do_ensure_new/2","doc":"I ensure that the fed in storage names correspond to completely empty new\ntables.\n\nI first delete all tables as specified in the Storage Engine structure,\nafterwards creating the tables with given names using `do_setup/2`.","ref":"Anoma.Node.Storage.html#do_ensure_new/2"},{"type":"function","title":"Anoma.Node.Storage.do_setup/2","doc":"I setup storage with the given tables from the Storage Engine structure.\n\nI will try to create all values of storage, even if the first one fails\ndue to already being created, we will try the others, setting them using\nrocksdb depending on the second argument given in the argument.","ref":"Anoma.Node.Storage.html#do_setup/2"},{"type":"function","title":"Anoma.Node.Storage.ensure_new/2","doc":"I am the function ensuring appropriate db functionality.\n\nGiven a Storage address and a boolean flag, I first use `remove/1`\nfunctionality to delete specified tables of the Engine and then\nask for a setup using `setup/1` functionality with an appropriate flag\nfor rocksdb copies.","ref":"Anoma.Node.Storage.html#ensure_new/2"},{"type":"function","title":"Anoma.Node.Storage.get/2","doc":"I am the main reading function for the Storage functionality.\n\nGiven a storage address and key name in the Order format, I look up the\nlatest value of such a key in the Qualified storage and return it in the\nstandard mnesia format. Otherwise, I return `:absent` if no value is\npresent (or if the key is tombstoned* in the latest instance).\n\nSee `delete_key/2`","ref":"Anoma.Node.Storage.html#get/2"},{"type":"function","title":"Anoma.Node.Storage.get_at_snapshot/2","doc":"I provide the main functionality of rescuing latest snapshot value of a\ngiven key.\n\nGiven a {storage, snapshot} pair and a key, I search for the order of the\nkey as captured by the snapshot using `in_snapshot/2`. Afterwards, I\ncheck the value of said key in said position in the provided table,\nreturning said value in the standard mnesia format.","ref":"Anoma.Node.Storage.html#get_at_snapshot/2"},{"type":"function","title":"Anoma.Node.Storage.get_keyspace/2","doc":"I am the keyspace reading function for the Storage Engine.\n\nGiven a storage address and a list of keys in the appropriate format, I\nfirst look up whether the keys appear in any qualified key in the\nQualified table. If so, look up all appropriate latest values of all such\nkeys and return them as a list of table query responses in a standard\nmnesia format. If no values are present, I return an empty list.","ref":"Anoma.Node.Storage.html#get_keyspace/2"},{"type":"function","title":"Anoma.Node.Storage.handle_cast/3","doc":"","ref":"Anoma.Node.Storage.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Storage.in_snapshot/2","doc":"I am the function searching for a key position inside of a given Ordering\nsnapshot.\n\nGiven a {key, snapshot} tuple I go though the snapshot searching for the\nkey in the format we store it inside the tables (i.e. namespaced). After\nwhich, I return the stored value, i.e. the latest Order at the point of\nsnapshot-taking.","ref":"Anoma.Node.Storage.html#in_snapshot/2"},{"type":"function","title":"Anoma.Node.Storage.init/1","doc":"I am the initialization function for a Storage Engine Instance.","ref":"Anoma.Node.Storage.html#init/1"},{"type":"function","title":"Pattern-Matching Variations - Anoma.Node.Storage.init/1","doc":"- `init(%Storage{})` - I initialize the Engine with the given state.\n- `init(args)` - I expect a keylist/map with all the keywords matching\n                 the Storage Engine type fields. I then setup the tables\n                 and return the appropriate Engine state for startup.","ref":"Anoma.Node.Storage.html#init/1-pattern-matching-variations"},{"type":"function","title":"Anoma.Node.Storage.namespace_key/2","doc":"","ref":"Anoma.Node.Storage.html#namespace_key/2"},{"type":"function","title":"Anoma.Node.Storage.namespace_qualified_key/2","doc":"","ref":"Anoma.Node.Storage.html#namespace_qualified_key/2"},{"type":"function","title":"Anoma.Node.Storage.put/3","doc":"I provide the main writing functionality of the Storage Engine.\n\nI am responsible for assigning the given values to key while respecting\nthe underlying table structure.\n\nThat is, given a key and a value, I first namespace the key getting the\nnamespace info from the appropriate storage state. Secondly, I re-write\nthe order-value assigned to said namespaced key, incrementing its value.\nFinally, I write the value given to me to the Qualified table, assigning\nit to the namespaced key with appropriate new order attached,\ncorresponding to the one in the Ordering table.","ref":"Anoma.Node.Storage.html#put/3"},{"type":"function","title":"Anoma.Node.Storage.put_snapshot/2","doc":"I am the function responsible for writing an Ordering snapshot to our db.\n\nGiven a Storage Address and a key, I first snapshot the appropriate\nOrdering table - similarly to `snapshot_order/1` - and then put it using\nthe functionality underlying `put/3` as a value for the supplied key.\n\nConsult `put/3` on the exact mechanism behind our writing.","ref":"Anoma.Node.Storage.html#put_snapshot/2"},{"type":"function","title":"Anoma.Node.Storage.read_at_order/3","doc":"I am the read_at_order function.\n\nI provide detailed reading functionality for the qualified table. Given a\nstorage structure, a key, and an order, I read the Qualified mnesia table\nat a value which on a high-level corresponds to reading the key value at\nthat particular order, which is, of course, represented by the order\nbeing part of the searched key at the mnesia level.\n\nI return a list of 3-tuples with elements:\n\n1) Name of Qualified Table\n2) Key (note here \"key\" has different semantics than top-level API as\n        noted above, it has a lot of extra info such as the order)\n3) Value of the key","ref":"Anoma.Node.Storage.html#read_at_order/3"},{"type":"function","title":"Anoma.Node.Storage.read_at_order_tx/3","doc":"I am the function getting the value of a key at a particular order.\n\nMy main role is to get transactions at the order given by the Ordering\nEngine. Generally, the user is to inquire about the value of a key using\n`get/2` functionality.\n\nGiven a Storage address, a key, and the order, I return the list\ncontaining the name of the storage, the key as given in the inputs, and\nits value at the specified order in the traditional mnesia format using\n`:mnesia.transaction` capabilities.\n\nSee `read_at_order/3` for how we actually read the value from the\nQualified table.","ref":"Anoma.Node.Storage.html#read_at_order_tx/3"},{"type":"function","title":"Anoma.Node.Storage.read_keyspace_order/2","doc":"I am the read_keyspace_order function.\n\nMy functionality is very similar to `read_order/2` yet instead of using\nthe mnesia `read` I use `select` and pick out any keys of list type in\nthe Ordering table which might contain inside the given keylist.\n\nI return the `{:atomic, lst}` tuple where the latter value is a list of\nlists where the head are the denamespaced keys containing our original\nquery keylist and the tail being the order.","ref":"Anoma.Node.Storage.html#read_keyspace_order/2"},{"type":"function","title":"Anoma.Node.Storage.read_order/2","doc":"I am the read_order function.\n\nGiven a storage structure and a key, I read the order of said key\nby literally asking mnesia to read the Ordering table at the key which\nis gotten by appending the storage namespace to the initially given key.\n\nI return a list of three-tuples with following elements:\n\n1) Ordering table name\n2) Key\n3) Order number","ref":"Anoma.Node.Storage.html#read_order/2"},{"type":"function","title":"Anoma.Node.Storage.read_order_tx/2","doc":"I am the main function for getting orders of keys.\n\nGiven a Storage address and a key, I return the key with its specified\norder in the Ordering table Storage using `:mnesia.transaction` to get\nthe value in standard mnesia format.\n\nSee `read_order/2` for the exact mechanism behind order-reading.","ref":"Anoma.Node.Storage.html#read_order_tx/2"},{"type":"function","title":"Anoma.Node.Storage.remove/1","doc":"I am the storage removal function.\n\nGiven a Storage Engine address, I ask mnesia to delete all tables found\ninside said Engine structure.","ref":"Anoma.Node.Storage.html#remove/1"},{"type":"function","title":"Anoma.Node.Storage.setup/1","doc":"I am the setup function for Storage.\n\nGiven a Storage address, I look for the tables inside its structure,\nand then try to create all mnesia tables with the given names. On\nsuccess, I also create a new commitment tree.","ref":"Anoma.Node.Storage.html#setup/1"},{"type":"function","title":"Anoma.Node.Storage.snapshot_order/1","doc":"I provide a snapshotting functionality for the Ordering table.\n\nGiven a Storage address, I look up the Ordering table attached to the\nEngine and provide a snapshot of it as a list of keys with their orders\nreturned in a mnesia result format and the attached storage structure.","ref":"Anoma.Node.Storage.html#snapshot_order/1"},{"type":"type","title":"Anoma.Node.Storage.order_key/0","doc":"I designate the type of keys for Ordering table queries.","ref":"Anoma.Node.Storage.html#t:order_key/0"},{"type":"type","title":"Anoma.Node.Storage.order_value/0","doc":"I designate the type of values of keys for Ordering table queries.","ref":"Anoma.Node.Storage.html#t:order_value/0"},{"type":"type","title":"Anoma.Node.Storage.qualified_key/0","doc":"I designate the type of keys for Qualified table queries.","ref":"Anoma.Node.Storage.html#t:qualified_key/0"},{"type":"type","title":"Anoma.Node.Storage.qualified_value/0","doc":"I designate the type of values of Keys for Qualified table queries.","ref":"Anoma.Node.Storage.html#t:qualified_value/0"},{"type":"type","title":"Anoma.Node.Storage.result/1","doc":"I am the type of a mensia table query result.","ref":"Anoma.Node.Storage.html#t:result/1"},{"type":"type","title":"Anoma.Node.Storage.snapshot/0","doc":"I designate the snapshot type for table queries.","ref":"Anoma.Node.Storage.html#t:snapshot/0"},{"type":"type","title":"Anoma.Node.Storage.t/0","doc":"I am the type of the Storage Engine.\n\nI store info on the db tables used by the Node and info for appropriate\nread/write actions.","ref":"Anoma.Node.Storage.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Node.Storage.t/0","doc":"- `:qualified` - The name of the Qualified table.\n                   Default: Anoma.Node.Storage.Qualified\n  - `:order` - The name of the Ordering table.\n               Default: Anoma.Node.Storage.Order\n  - `:rm_commitments` - The name of the Resource Machine Commitments table.\n                        Default: Anoma.Node.Storage.RMCommitments\n  - `:cairo_rm_commitments` - The name of the Cairo RM Commitments table.\n  - `:namespace` - The namespace used for writing functionality.\n                   Default: []\n  - `:topic` - The subscription topic.\n               Enforced: false","ref":"Anoma.Node.Storage.html#t:t/0-fields"},{"type":"module","title":"Anoma.Crypto.Encrypt","doc":"","ref":"Anoma.Crypto.Encrypt.html"},{"type":"function","title":"Anoma.Crypto.Encrypt.new_keypair/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Encrypt.seal/2","doc":"I seal the given message for the publicly known recipient.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Encrypt.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Encrypt.unseal/3","doc":"","ref":"Anoma.Crypto.Encrypt.html#unseal/3"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_secret/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Id","doc":"I represent the Identity","ref":"Anoma.Crypto.Id.html"},{"type":"function","title":"Anoma.Crypto.Id.external_id/1","doc":"Grabs the external id of a given key\n\nUseful when we want to use id and the external as interchangeable","ref":"Anoma.Crypto.Id.html#external_id/1"},{"type":"function","title":"Anoma.Crypto.Id.new_keypair/0","doc":"","ref":"Anoma.Crypto.Id.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Id.salt_keys/2","doc":"I salt the given keys for further storage. Or for storage\nlookup\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for salting for storage\n- `Extern.t\u0000` is useful for looking up keys for storage\n- `Intern.t\u0000` is useful in case one wants to see the salted key","ref":"Anoma.Crypto.Id.html#salt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.seal/2","doc":"","ref":"Anoma.Crypto.Id.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Id.truncated_key_string/1","doc":"","ref":"Anoma.Crypto.Id.html#truncated_key_string/1"},{"type":"function","title":"Anoma.Crypto.Id.unsalt_keys/2","doc":"I unsalt the given keys for use after looking up from storage\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for unsalting from Storage\n- `Extern.t\u0000` is useful for external keys which are salted\n- `Intern.t\u0000` is useful in case when one wants to unsalt their private keys","ref":"Anoma.Crypto.Id.html#unsalt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.verify/2","doc":"","ref":"Anoma.Crypto.Id.html#verify/2"},{"type":"type","title":"Anoma.Crypto.Id.identities/0","doc":"","ref":"Anoma.Crypto.Id.html#t:identities/0"},{"type":"type","title":"Anoma.Crypto.Id.t/0","doc":"","ref":"Anoma.Crypto.Id.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Extern","doc":"","ref":"Anoma.Crypto.Id.Extern.html"},{"type":"type","title":"Anoma.Crypto.Id.Extern.t/0","doc":"","ref":"Anoma.Crypto.Id.Extern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Intern","doc":"","ref":"Anoma.Crypto.Id.Intern.html"},{"type":"type","title":"Anoma.Crypto.Id.Intern.t/0","doc":"","ref":"Anoma.Crypto.Id.Intern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Randomness","doc":"I am an implementation of the Local Randomness Engine","ref":"Anoma.Crypto.Randomness.html"},{"type":"function","title":"Anoma.Crypto.Randomness.get_random/1","doc":"Given a non-negative integer N, I provide a random bit of size N","ref":"Anoma.Crypto.Randomness.html#get_random/1"},{"type":"module","title":"Anoma.Crypto.Sign","doc":"","ref":"Anoma.Crypto.Sign.html"},{"type":"function","title":"Anoma.Crypto.Sign.new_keypair/0","doc":"","ref":"Anoma.Crypto.Sign.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Sign.sign/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign/2"},{"type":"function","title":"Anoma.Crypto.Sign.sign_detached/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign_detached/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify/2","doc":"","ref":"Anoma.Crypto.Sign.html#verify/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify_detached/3","doc":"","ref":"Anoma.Crypto.Sign.html#verify_detached/3"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_public/0"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_secret/0"},{"type":"type","title":"Anoma.Crypto.Sign.public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Sign.secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Symmetric","doc":"","ref":"Anoma.Crypto.Symmetric.html"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt_raw/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt/2","doc":"I encrypt data given any known schema and a message.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Symmetric.html#encrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt_raw/2","doc":"I encrypt data given any known schema and a message.\n\nI am raw in that I do not serialize the data, Only use me if you\nknow what you are doing.","ref":"Anoma.Crypto.Symmetric.html#encrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_key/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_nonce/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.t/0","doc":"I represent the symmetric types available to the system","ref":"Anoma.Crypto.Symmetric.html#t:t/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_key/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_nonce/0"},{"type":"module","title":"Anoma.Node.Solver","doc":"I am a strawman intent solver for testing purposes.","ref":"Anoma.Node.Solver.html"},{"type":"function","title":"Anoma.Node.Solver.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Solver.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Solver.get_solved/1","doc":"","ref":"Anoma.Node.Solver.html#get_solved/1"},{"type":"function","title":"Anoma.Node.Solver.handle_cast/3","doc":"","ref":"Anoma.Node.Solver.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Solver.init/1","doc":"","ref":"Anoma.Node.Solver.html#init/1"},{"type":"function","title":"Anoma.Node.Solver.mempool_send/2","doc":"","ref":"Anoma.Node.Solver.html#mempool_send/2"},{"type":"function","title":"Anoma.Node.Solver.solve/1","doc":"","ref":"Anoma.Node.Solver.html#solve/1"},{"type":"type","title":"Anoma.Node.Solver.t/0","doc":"","ref":"Anoma.Node.Solver.html#t:t/0"},{"type":"module","title":"CommitmentTree","doc":"A simple commitment tree.\n\nCurrently stores all commitments forever, and stores the full tree in memory,\npending future more sophisticated retention policies.  Does not yet store any\nanchors itself for the same reason--this is a complex policy level decision.\n\nHas a fixed depth.\n\nFiats that empty subtrees have a hash of 0 for simplicity.","ref":"CommitmentTree.html"},{"type":"function","title":"CommitmentTree.add/2","doc":"Adds commitments to the commitment tree, and returns the new tree and the anchor.\nTODO handle the tree's filling up","ref":"CommitmentTree.html#add/2"},{"type":"function","title":"CommitmentTree.init_storage/1","doc":"","ref":"CommitmentTree.html#init_storage/1"},{"type":"function","title":"CommitmentTree.new/2","doc":"Creates a new `CommitmentTree` struct.","ref":"CommitmentTree.html#new/2"},{"type":"function","title":"CommitmentTree.prove/2","doc":"","ref":"CommitmentTree.html#prove/2"},{"type":"type","title":"CommitmentTree.t/0","doc":"","ref":"CommitmentTree.html#t:t/0"},{"type":"module","title":"CommitmentTree.Node","doc":"","ref":"CommitmentTree.Node.html"},{"type":"function","title":"CommitmentTree.Node.new/2","doc":"Creates a new internal node.\nChildren is a tuple of size spec.splay, each element of which is either a binary or another node.","ref":"CommitmentTree.Node.html#new/2"},{"type":"function","title":"CommitmentTree.Node.new_empty/1","doc":"Creates a new internal node, all children of which are empty.","ref":"CommitmentTree.Node.html#new_empty/1"},{"type":"function","title":"CommitmentTree.Node.prove/3","doc":"Produces a proof for leaf #cursor of node, taking the form of a nested tuple,\nas described in proof.ex","ref":"CommitmentTree.Node.html#prove/3"},{"type":"type","title":"CommitmentTree.Node.t/0","doc":"","ref":"CommitmentTree.Node.html#t:t/0"},{"type":"module","title":"CommitmentTree.Proof","doc":"I represent a compact proof that a particular element is contained within the\ncommitment tree.","ref":"CommitmentTree.Proof.html"},{"type":"function","title":"CommitmentTree.Proof.new/2","doc":"","ref":"CommitmentTree.Proof.html#new/2"},{"type":"function","title":"CommitmentTree.Proof.verify/4","doc":"","ref":"CommitmentTree.Proof.html#verify/4"},{"type":"function","title":"CommitmentTree.Proof.verifyx/5","doc":"","ref":"CommitmentTree.Proof.html#verifyx/5"},{"type":"type","title":"CommitmentTree.Proof.t/0","doc":"","ref":"CommitmentTree.Proof.html#t:t/0"},{"type":"module","title":"CommitmentTree.Spec","doc":"A specification for a commitment tree.","ref":"CommitmentTree.Spec.html"},{"type":"function","title":"CommitmentTree.Spec.cairo_poseidon_cm_tree_spec/0","doc":"","ref":"CommitmentTree.Spec.html#cairo_poseidon_cm_tree_spec/0"},{"type":"function","title":"CommitmentTree.Spec.cm_tree_spec/0","doc":"","ref":"CommitmentTree.Spec.html#cm_tree_spec/0"},{"type":"function","title":"CommitmentTree.Spec.new/4","doc":"","ref":"CommitmentTree.Spec.html#new/4"},{"type":"type","title":"CommitmentTree.Spec.t/0","doc":"","ref":"CommitmentTree.Spec.html#t:t/0"},{"type":"module","title":"Anoma.Mnesia","doc":"I help with various queries around *Mnesia*.","ref":"Anoma.Mnesia.html"},{"type":"module","title":"Usage - Anoma.Mnesia","doc":"i> Anoma.Mnesia.init()","ref":"Anoma.Mnesia.html#module-usage"},{"type":"module","title":"Initialization - Anoma.Mnesia","doc":"I can help with initializing *Mnesia*. calling `init/0` should setup\nthe project to be compatible with\n\nNote that the Erlang Node I reside in can only have one Mnesia\ndatabase open at a time.","ref":"Anoma.Mnesia.html#module-initialization"},{"type":"module","title":"Querying - Anoma.Mnesia","doc":"I have the following functions that can help query data\n\n  - `dirt_dump/1`","ref":"Anoma.Mnesia.html#module-querying"},{"type":"function","title":"Anoma.Mnesia.attach/0","doc":"","ref":"Anoma.Mnesia.html#attach/0"},{"type":"function","title":"Anoma.Mnesia.dirty_dump/1","doc":"I help dump all data in a given table","ref":"Anoma.Mnesia.html#dirty_dump/1"},{"type":"function","title":"Example - Anoma.Mnesia.dirty_dump/1","doc":"iex(15)> :mnesia.create_table(:test, [attributes: [:id, :name, :job]])\n     {:atomic, :ok}\n     iex(16)> :mnesia.dirty_write({:test, 1, \"G'kar\", \"Ambassador\"})\n     :ok\n     iex(17)> Anoma.Mnesia.dirty_dump(:test)\n     [[{:test, 1, \"G'kar\", \"Ambassador\"}]]","ref":"Anoma.Mnesia.html#dirty_dump/1-example"},{"type":"function","title":"Anoma.Mnesia.dump/1","doc":"I help dump all data in a given table in a non-dirty way.\n\nSee `dirty_dump/1`","ref":"Anoma.Mnesia.html#dump/1"},{"type":"function","title":"Anoma.Mnesia.fresh_storage/0","doc":"I ensure storage is freshly setup","ref":"Anoma.Mnesia.html#fresh_storage/0"},{"type":"function","title":"Anoma.Mnesia.init/0","doc":"","ref":"Anoma.Mnesia.html#init/0"},{"type":"module","title":"Anoma.Utility","doc":"I provide utility functions for users.","ref":"Anoma.Utility.html"},{"type":"module","title":"Public API - Anoma.Utility","doc":"I possess the following public API:\n\n- message_label/1","ref":"Anoma.Utility.html#module-public-api"},{"type":"macro","title":"Anoma.Utility.defbug/2","doc":"I am the function definition macro for debugging.\n\nI mainly should be used on functions which satisfy:\n\n1) Needing to be private i.e. not expose API to other Engines.\n2) Important for core functionality and hence requiring documentation.\n\nGiven the two are satisfied, use me to define a function which becomes\npublic once in debug mode and otherwise remains private.\n\nI am to be used alongside the `docp/1` macro to allow for good\ndocumentation practices.","ref":"Anoma.Utility.html#defbug/2"},{"type":"macro","title":"Anoma.Utility.docp/1","doc":"I am a macro which allows to provide documentation to possibly private\nfunctions.\n\nIf the environment of the application is `:debug` I actually put the docs\ninto the compiled module. If not, I produce `nil`, which does not\ninteract with overall module environment.","ref":"Anoma.Utility.html#docp/1"},{"type":"function","title":"Anoma.Utility.message_label/1","doc":"Helps labeling for `Kino.Process.seq_trace/2`, for the Router abstraction","ref":"Anoma.Utility.html#message_label/1"},{"type":"module","title":"TestHelper.Executor","doc":"I am a testing module allowing to listen to new spawned Executor workers.","ref":"TestHelper.Executor.html"},{"type":"function","title":"TestHelper.Executor.wait_for_spawn/5","doc":"I am the helper function for awaiting spawned Workers by the executor.\n\nI ask to fire a new transaction and then wait for the appropriate\nmessage. Upon message reception I give back the spawned Engine.","ref":"TestHelper.Executor.html#wait_for_spawn/5"},{"type":"module","title":"TestHelper.Mempool","doc":"","ref":"TestHelper.Mempool.html"},{"type":"function","title":"TestHelper.Mempool.wait_for_tx/4","doc":"I am a helper function waiting for launching transaction code.\n\nI ask the mempool to use it's `tx/2` functionality with the given\ntransaction code. I then await for a `:submitted` message in the mailbox\nfor a timeout-specified ammount of time.\n\nAfterwards I return the pending transaction structure.","ref":"TestHelper.Mempool.html#wait_for_tx/4"},{"type":"module","title":"TestHelper.Nock","doc":"I am a testing module that has some common definitions for nock\nfunctions.","ref":"TestHelper.Nock.html"},{"type":"function","title":"TestHelper.Nock.counter_val_plus_one/1","doc":"","ref":"TestHelper.Nock.html#counter_val_plus_one/1"},{"type":"function","title":"TestHelper.Nock.increment_counter_val/1","doc":"","ref":"TestHelper.Nock.html#increment_counter_val/1"},{"type":"function","title":"TestHelper.Nock.zero_counter/1","doc":"","ref":"TestHelper.Nock.html#zero_counter/1"},{"type":"module","title":"TestHelper.Node","doc":"","ref":"TestHelper.Node.html"},{"type":"function","title":"TestHelper.Node.become_engine/0","doc":"We fake becoming an engine\n\nIf a router is not passed in, we make a new one","ref":"TestHelper.Node.html#become_engine/0"},{"type":"function","title":"TestHelper.Node.become_engine/1","doc":"","ref":"TestHelper.Node.html#become_engine/1"},{"type":"function","title":"TestHelper.Node.router_talking_to_client/2","doc":"","ref":"TestHelper.Node.html#router_talking_to_client/2"},{"type":"function","title":"TestHelper.Node.talk_to_server_router/4","doc":"","ref":"TestHelper.Node.html#talk_to_server_router/4"},{"type":"module","title":"TestHelper.TestMacro","doc":"I am a module populated by macros associated to Anoma Testing.\n\nMy use macro replaces ExUnit.case use macro with the caveat of ignoring\nthe Assertions imports.\n\nUse me in order to define various macros to be used in tests.","ref":"TestHelper.TestMacro.html"},{"type":"macro","title":"TestHelper.TestMacro.assert/2","doc":"I call the `assert` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#assert/2"},{"type":"macro","title":"TestHelper.TestMacro.assert_receive/3","doc":"I call the `assert_receive` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#assert_receive/3"},{"type":"function","title":"TestHelper.TestMacro.assertion_abstract/3","doc":"I catch a variable binding expression in debug mode and call `call_assert`\non it.\n\nIf the expression caught is variable-bining, after evaluating I also\ncall said binding at AST level to bind it outside try-rescue.\n\nIf the expression is not in debug mode, I simply call the assertion on\nthe expression.","ref":"TestHelper.TestMacro.html#assertion_abstract/3"},{"type":"function","title":"TestHelper.TestMacro.assertion_alias/2","doc":"I add the ExUnit.Assertions prefix to the function call on the AST level\nand apply it to the expression as a quoted structure.","ref":"TestHelper.TestMacro.html#assertion_alias/2"},{"type":"function","title":"TestHelper.TestMacro.call_assert/2","doc":"I call the try functionality to capture the error.","ref":"TestHelper.TestMacro.html#call_assert/2"},{"type":"function","title":"Pattern-Matching Variations - TestHelper.TestMacro.call_assert/2","doc":"- `call_assert(atom, [{:=, _, [left, _]}])` - Afterwards I bind the\n                                              left side variables.\n- `call_assert(atom, expr)` - Just call the capture.","ref":"TestHelper.TestMacro.html#call_assert/2-pattern-matching-variations"},{"type":"function","title":"TestHelper.TestMacro.message_parse/3","doc":"Depending on the given message, I call either `assert` or `refute` with\ndifferent arities.","ref":"TestHelper.TestMacro.html#message_parse/3"},{"type":"function","title":"TestHelper.TestMacro.quote_try/2","doc":"I quote the error-capturing of expressions.","ref":"TestHelper.TestMacro.html#quote_try/2"},{"type":"macro","title":"TestHelper.TestMacro.refute/2","doc":"I call the `refute` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#refute/2"},{"type":"macro","title":"TestHelper.TestMacro.refute_receive/3","doc":"I call the `assert_refute` macro from ExUnit.Assertions\n\nIf the environment is :debug I pry on errors.","ref":"TestHelper.TestMacro.html#refute_receive/3"},{"type":"function","title":"TestHelper.TestMacro.try_assert/2","doc":"I present a quoted expression to try depending on the input.","ref":"TestHelper.TestMacro.html#try_assert/2"},{"type":"function","title":"Pattern-Matching Variations - TestHelper.TestMacro.try_assert/2","doc":"- `try_assert(atom, [{:=, _, _}])` - I use the assertion, print the\n                                     binded variables to escape\n                                     warnings and then print the\n                                     original result\n- `try_assert(atom, expr)` - I use the assertion","ref":"TestHelper.TestMacro.html#try_assert/2-pattern-matching-variations"},{"type":"module","title":"TestHelper.Worker","doc":"","ref":"TestHelper.Worker.html"},{"type":"function","title":"TestHelper.Worker.wait_for_read_value/1","doc":"","ref":"TestHelper.Worker.html#wait_for_read_value/1"},{"type":"function","title":"TestHelper.Worker.wait_for_worker/2","doc":"","ref":"TestHelper.Worker.html#wait_for_worker/2"},{"type":"extras","title":"Anoma","doc":"# Anoma\n\nThis is an implementation of the Anoma protocol, whose specs can be\nfound [here](https://specs.anoma.net/alpha).","ref":"readme.html"},{"type":"extras","title":"Following Development - Anoma","doc":"Work is merged into `base` on a bi-weekly (once every two weeks)\nschedule.\n\nDevelopment can be followed in multiple ways:\n\n1. [Issues are put into the project overview](https://github.com/orgs/anoma/projects/19)\n   - This is a good way to see what work is assigned and the various\n     views into how goals are being met\n2. [Promise Graph from the project overview](https://specs.anoma.net/projects/anoma-19.html)\n   - This is the same information as `1.` but using our own promise\n     graph tooling. This is kept up to date hourly.\n3. [What's Cooking on Anoma](https://github.com/orgs/anoma/projects/20 \"A good view on how topics are progressing throughout a cycle\")\n4. [Issues](https://github.com/anoma/anoma/issues) and [pull requests](https://github.com/anoma/anoma/pulls)\n   - This is good for viewing new issues and work coming in, but the\n     other views are typically a better way to view this","ref":"readme.html#following-development"},{"type":"extras","title":"Dependencies - Anoma","doc":"To have a working Anoma Node the following dependencies are required:\n\n1. `cmake`\n2. `Erlang`\n3. `Elixir`\n4. `zig`\n5. `rust`","ref":"readme.html#dependencies"},{"type":"extras","title":"OSX - Anoma","doc":"```sh\nbrew install elixir\nbrew install zig\n```","ref":"readme.html#osx"},{"type":"extras","title":"Linux - Anoma","doc":"All the dependencies can be grabbed from your distro's package manager.","ref":"readme.html#linux"},{"type":"extras","title":"Installation - Anoma","doc":"To install the dependencies as well as Anoma run:\n\n```bash\nmix deps.get\nmix compile\n```\n\nTo start an Anoma instance run one of these:\n\n```bash\niex -S mix # starts an interactive shell\nmix run --no-halt # starts a non-interactive shell\n```\n\nSee the Contributing section for how to get the best use of the\ninteractive shell.","ref":"readme.html#installation"},{"type":"extras","title":"Contributing - Anoma","doc":"Please read the [contributor's guide](./documentation/contributing.livemd) for in\ndepth details about the codebase.","ref":"readme.html#contributing"},{"type":"extras","title":"Git - Anoma","doc":"This codebase follows a git style similar to\n[git](https://git-scm.com/) or\n[linux](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git).\n\nNew code should be based on `base`, and no attempt to keep it up to\nsync with `main` should be had. When one's topic is ready, just submit\na PR on github and a maintainer will handle any merge conflicts.\n\nThere are bi-weekly releases, so do not be afraid if a maintainer says\nthe PR is merged but it's still open, this just means that it's merged\ninto `next` or `main` and will be included in the next scheduled\nrelease.\n\nFor more information on a smooth git experience check out the [git\nsection in contributor's guide](./documentation/contributing/git.livemd)\n\nHappy hacking, and don't be afraid to submit patches.","ref":"readme.html#git"},{"type":"extras","title":"Analysis","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Analysis","ref":"analysis.html"},{"type":"extras","title":"Index - Analysis","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"analysis.html#index"},{"type":"extras","title":"Analysis - Analysis","doc":"Documents in this section cover analysis over the code in the repository.","ref":"analysis.html#analysis"},{"type":"extras","title":"Fema Analysis On the Pinger","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Fema Analysis On the Pinger","ref":"fema-analysis-pinger.html"},{"type":"extras","title":"Index - Fema Analysis On the Pinger","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"fema-analysis-pinger.html#index"},{"type":"extras","title":"Analysis - Fema Analysis On the Pinger","doc":"This document contains a [FEMA](https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis) analysis on `Anoma.Node.Pinger`.\n\nThe pinger module is responsible for producing blocks at a set time.\n\nIn order to get a good feeling of the errors, this document will:\n\n1. Cover the traces of it's public API\n2. Do a more indpeth analysis of the effects, inducing the key calls\n3. Disect how the module could fail\n4. Locate how the API could be misused and create a failure case\n5. Look at the codebase for potential areas where this could occur\n6. Note the nock-on effects on a failing actor on other actors in the `Anoma` system.\n7. Write out each bug in full effect.\n8. Provide a summary of the findings with the precieved severity level","ref":"fema-analysis-pinger.html#analysis"},{"type":"extras","title":"Pinger API Tracing - Fema Analysis On the Pinger","doc":"Let us startup the Anoma Environment to run the code in.\n\n```elixir\nalias Anoma.Node.{Mempool, Router, Pinger}\nalias Anoma.Storage\nalias Anoma.Node.Storage.Ordering\nimport TestHelper.Nock\n\nname = :anoma\nnode = Anoma.Node.state(name)\n:all_good\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:all_good\n```\n\nThe Pinger has 2 `public` methods that we can abuse `Anoma.Node.Pinger.start/1` and `Anoma.Node.Pinger.set_timer/2`.\n\nLet use begin by first tracing what all these methods do in depth\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.pinger.server)],\n  fn ->\n    # we should use the router, but pinger is special\n    Pinger.set_timer(node.pinger, 20)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 0 AS self();\nparticipant 1 AS Anoma.Node.Pinger HFn/uuQ5P5oDd3yBKS2rDz+Nx++XqLKOL+zJdO70aJg=;\n0->>1: CALL: set\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\"Timer set to 20\"\n```","ref":"fema-analysis-pinger.html#pinger-api-tracing"},{"type":"extras","title":"In Depth Analysis - Fema Analysis On the Pinger","doc":"Now that we have seen the rough API of the Pinger, let us now look deeper at how the interactions work, and see what we can derive.\n\nThe first bit to note is that `set_timer` does not actually trigger the pinger to start sending\n\nAnalyzing the code, we can see that if **state.time** is set properly, then the pinger will handle a self call of `:execute`.\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.pinger.server)],\n  fn ->\n    # we should use the router, but pinger is special\n    send(Process.whereis(node.pinger.server), :execute)\n    :timer.sleep(1)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 2 AS Anoma.Node.Mempool 4/XLsEdgkzoiXSBYoBHJexd5ax8K1Sp7feQki1HV45k=;\nparticipant 0 AS self();\nparticipant 1 AS Anoma.Node.Pinger HFn/uuQ5P5oDd3yBKS2rDz+Nx++XqLKOL+zJdO70aJg=;\n0->>1: INFO: execute\n1->>2: CALL: execute\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"fema-analysis-pinger.html#in-depth-analysis"},{"type":"extras","title":"Potential Failure Modes - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#potential-failure-modes"},{"type":"extras","title":"Failure of use around the codebase - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#failure-of-use-around-the-codebase"},{"type":"extras","title":"Death of the Actor - Fema Analysis On the Pinger","doc":"If the actor dies, then the only effect is that blocks won't be producted like expected.\n\nIn production this is **critical** as the chain will halt.\n\nOn a developer's testing box this is rather benign, as block production should happen on demand, rather than on intervels.","ref":"fema-analysis-pinger.html#death-of-the-actor"},{"type":"extras","title":"Full Details of the Failure modes - Fema Analysis On the Pinger","doc":"","ref":"fema-analysis-pinger.html#full-details-of-the-failure-modes"},{"type":"extras","title":"Summary Of Failures - Fema Analysis On the Pinger","doc":"| Failure States | Severity | Comment                 |\n| -------------- | -------- | ----------------------- |\n| xyz            | low      | important for operation |","ref":"fema-analysis-pinger.html#summary-of-failures"},{"type":"extras","title":"Contributing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Contributing","ref":"contributing.html"},{"type":"extras","title":"Index - Contributing","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"contributing.html#index"},{"type":"extras","title":"Contributing - Contributing","doc":"Documents in this section cover getting started and contributing back to `Anoma`.\n\nPlease feel free to contribute to these docs and improve them! For tips on how to write documents, please refer to the [Writing Documents](./contributing/writing-documents.livemd)","ref":"contributing.html#contributing"},{"type":"extras","title":"Logging","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Logging","ref":"logging.html"},{"type":"extras","title":"Index - Logging","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"logging.html#index"},{"type":"extras","title":"Logging - Logging","doc":"This document introduces the logging functionality internal to Anoma and showcases some some of its debugging features. First, let us set up a new environment.\n\n```elixir\nalias Anoma.Node.{Ordering, Mempool, Router, Storage}\nimport TestHelper.Nock\n\nstorage = %Storage{\n  qualified: AnomaTest.LoggerDoc.Qualified,\n  order: AnomaTest.LoggerDoc.Order\n}\n\nname = :loggerdoc\nsnapshot_path = [:my_special_nock_snaphsot | 0]\n\n{:ok, nodes} =\n  Anoma.Node.start_link_or_find_instance(\n    name: name,\n    use_rocks: false,\n    settings:\n      {:new_storage,\n       [\n         snapshot_path: snapshot_path,\n         storage_data: storage,\n         block_storage: :dump_blocks,\n         ping_time: :no_timer\n       ]\n       |> Anoma.Node.start_min()}\n  )\n\nnode = Anoma.Node.state(nodes)\n\n:ok\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"logging.html#logging"},{"type":"extras","title":"Logger as an Engine - Logging","doc":"The Logger in Anoma is an engine which can be used as the usual logging device via connecting to other engines. The intended use of the Logging engine is to start it alongside the node letting the other engines store its address info. So, e.g. our primary `:anoma` node launched at application startup will have a dedicated Logging engine:\n\n```elixir\nlogger = node.logger\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node.Router.Addr{\n  server: :\"Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=\",\n  id: %Anoma.Crypto.Id.Extern{\n    encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220, 144,\n      234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n    sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76, 223,\n      88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n  },\n  router: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n        198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n      sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20,\n        146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n    },\n    router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n  }\n}\n```\n\nMoreover, this address will be stored in appropriate fields of other engines such as the Executor:\n\n```elixir\nalias Anoma.Node.Router.Engine\n\nex_logger = Engine.get_state(node.executor).logger\nex_logger == logger\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\ntrue\n```\n\nAs an engine, it has its own dependencies for startup. In particular, we require the Logger having an access to:\n\n1. the Clock engine for timestamping\n2. Storage where we dump the info to\n\n```elixir\nEngine.get_state(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node.Logger{\n  clock: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Clock NztG/xI1ol8hcLhnaDft5j4nK9tJ0TcI43JiaRQET0g=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<247, 210, 98, 17, 246, 94, 217, 21, 214, 95, 6, 237, 31, 207, 149, 20, 45, 197,\n        197, 146, 40, 3, 198, 20, 242, 136, 62, 8, 172, 242, 0, 91>>,\n      sign: <<55, 59, 70, 255, 18, 53, 162, 95, 33, 112, 184, 103, 104, 55, 237, 230, 62, 39, 43,\n        219, 73, 209, 55, 8, 227, 114, 98, 105, 20, 4, 79, 72>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n          198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n        sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137,\n          20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n      },\n      router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n    }\n  },\n  storage: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Storage PFSZ/7snPaFarWcLK0dDNTlznyAo3F+G+tq1zmNfe+A=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<103, 181, 194, 163, 250, 93, 164, 234, 227, 159, 152, 54, 45, 216, 81, 68, 165, 66,\n        172, 210, 22, 27, 72, 168, 184, 202, 42, 249, 133, 43, 92, 120>>,\n      sign: <<60, 84, 153, 255, 187, 39, 61, 161, 90, 173, 103, 11, 43, 71, 67, 53, 57, 115, 159,\n        32, 40, 220, 95, 134, 250, 218, 181, 206, 99, 95, 123, 224>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208,\n          198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>,\n        sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137,\n          20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>\n      },\n      router: :\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\"\n    }\n  }\n}\n```","ref":"logging.html#logger-as-an-engine"},{"type":"extras","title":"Logging API - Logging","doc":"The Logger provides functionality to add new and request the stored info using\n\n* `add/3`\n* `get/1`\n* `get/2`\n\nThe `add` function awaits a logger address, an atom specifying the logging urgency and a message accompanying it. The engine then stores it using `Anoma.Storage.put` functionality.\n\n```elixir\nalias Anoma.Node.Logger\n\nLogger.add(logger, :info, \"This is a logger message\")\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nThe `get/1` function awaits a logger address, after which it outputs all the info that the logger has stored:\n\n```elixir\nLogger.get(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```\n\nAll elements of the stored info have the same structure: they are 2-tuples. The left element is a list. Its first element is the external ID of our logger, followed by the PID of the process that sent the message (in this case `self`), a timestamp, as well as the supplied atom. The right element is the message.\n\nGenerally it is not the user who sends the logging messages but the engines themselves. Almost every public engine API has some logging that happens during function execution:\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.ordering.server)],\n  fn ->\n    Ordering.next_order(node.ordering)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 0 AS self();\nparticipant 2 AS Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=;\nparticipant 1 AS Anoma.Node.Ordering J+SRpK9QFPQakfr7mUzFfysUulMbQ9LD+Qc2a7l1uF8=;\n0->>1: CALL: next_order\n1->>2: ADD LEVEL: info\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n1\n```\n\nWe can now use `get/2` by using both the Loger address and the address of the engine whose logging info we want to see. This fetches only the info relevant to said engine.\n\n```elixir\nLogger.get(logger, node.ordering)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<88, 234, 42, 32, 205, 162, 194, 238, 222, 188, 180, 222, 111, 108, 226, 209, 156,\n         108, 68, 14, 149, 105, 186, 130, 229, 110, 153, 63, 140, 167, 53, 116>>,\n       sign: <<39, 228, 145, 164, 175, 80, 20, 244, 26, 145, 250, 251, 153, 76, 197, 127, 43, 20,\n         186, 83, 27, 67, 210, 195, 249, 7, 54, 107, 185, 117, 184, 95>>\n     },\n     19392,\n     :info\n   ], \"Requested next order: 1\"}\n]\n```\n\nNote that instead of a PID we now see the external ID of the engine. Logger checks whether what sent the request was a registered engine or some general process which sends a message. In the former case we use the external ID of the engine, in the latter just the PID. We can similarly use `get/2` with a PID instead of an address.\n\n```elixir\nLogger.get(logger, self())\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```\n\nWhile the count of all the logging messages is now up to 2:\n\n```elixir\nLogger.get(logger)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<88, 234, 42, 32, 205, 162, 194, 238, 222, 188, 180, 222, 111, 108, 226, 209, 156,\n         108, 68, 14, 149, 105, 186, 130, 229, 110, 153, 63, 140, 167, 53, 116>>,\n       sign: <<39, 228, 145, 164, 175, 80, 20, 244, 26, 145, 250, 251, 153, 76, 197, 127, 43, 20,\n         186, 83, 27, 67, 210, 195, 249, 7, 54, 107, 185, 117, 184, 95>>\n     },\n     19392,\n     :info\n   ], \"Requested next order: 1\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.599.0>,\n     12815,\n     :info\n   ], \"This is a logger message\"}\n]\n```","ref":"logging.html#logging-api"},{"type":"extras","title":"Using the Logger - Logging","doc":"Using the above functionality the user is able to debug the system in case of errors. Here is a trivial example of that based on an existing Mempool test. Suppose the user is testing Mempool capabilities, namely count iteration for block execution. However, they forget to use the zero counter. First the user sets up the Mempool:\n\n```elixir\nkey = 555\nstorage = Ordering.get_storage(node.ordering)\nincrement = increment_counter_val(key)\nMempool.hard_reset(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nWe then reproduce the setting by incrementing the counter without incrementing using the zero counter and execute. Here we assume the uses simply did not notice that the zero counter has not been submitted.\n\n```elixir\npid_one = Mempool.tx(node.mempool, {:kv, increment}).pid\n\nMempool.execute(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\n22:25:25.390 [error] Worker failed! :error\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nWe encounter an error which is signalled by the logger. Namely our worker has failed. Let us check the appropriate worker log:\n\n```elixir\nLogger.get(logger, pid_one)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35620,\n     :error\n   ], \"Worker failed! :error\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35621,\n     :info\n   ],\n   \"Taking snapshot key :my_special_nock_snaphsot in storage %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Storage PFSZ/7snPaFarWcLK0dDNTlznyAo3F+G+tq1zmNfe+A=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<103, 181, 194, 163, 250, 93, 164, 234, 227, 159, 152, 54, 45, 216, 81, 68, 165, 66, 172, 210, 22, 27, 72, 168, 184, 202, 42, 249, 133, 43, 92, 120>>, sign: <<60, 84, 153, 255, 187, 39, 61, 161, 90, 173, 103, 11, 43, 71, 67, 53, 57, 115, 159, 32, 40, 220, 95, 134, 250, 218, 181, 206, 99, 95, 123, 224>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35582,\n     :info\n   ], \"Worker dispatched.\\n    Order id: 102439050089106441858870166176275840122\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35620,\n     :info\n   ], \"#PID<0.761.0>: making sure the snapshot is ready\"}\n]\n```\n\nHere we see that the worker has faced errors only at the end of its life-cycle. Before, it was succesfully waiting for the write ready message. Hence the user may try to probe the entire logging keyspace and notice, e.g. that there has only been one worker dispatched throughout the process:\n\n```elixir\nlogger\n|> Logger.get()\n|> Enum.filter(fn {_list, msg} ->\n  String.contains?(msg, \"Worker dispatched\")\nend)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     #PID<0.761.0>,\n     35582,\n     :info\n   ], \"Worker dispatched.\\n    Order id: 102439050089106441858870166176275840122\"}\n]\n```\n\nWe can then probe the logger to check what exact transaction has been submitted:\n\n```elixir\nLogger.get(logger, node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35608,\n     :info\n   ],\n   \"Transaction added. New pool: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 \" <> ...},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35620,\n     :info\n   ], \"Sending :write_ready to 1 processes\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35578,\n     :info\n   ],\n   \"Requested transaction fire.\\n      Executor: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Executor bMdE8VVjfHe6Cwwf7x7HPnKE4UIk0ppsTRd+3lFCMfo=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<124, 24, 139, 146, 134, 161, 98, 88, 227, 169, 92, 251, 165, 248, 140, 252, 237, 115, 81, 219, 226, 98, 33, 106, 80, 195, 115, 74, 84, 4, 91, 114>>, sign: <<108, 199, 68, 241, 85, 99, 124, 119, 186, 11, 12, 31, 239, 30, 199, 62, 114, 132, 225, 66, 36, 210, 154, 108, 77, 23, 126, 222, 81, 66, 49, 250>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}.\\n      Id : 102439050089106441858870166176275840122\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35627,\n     :info\n   ], \"Requested execution\"},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35619,\n     :info\n   ],\n   \"Producing block. Transsactions: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, \" <> ...},\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35626,\n     :info\n   ],\n   \"New state: %Anoma.Node.Mempool{logger: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Logger HjryahDk+vQ6qtFk7r6aeydM31heWNXRbSL0uhA+KmI=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220, 144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>, sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76, 223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}}, key: {[<<1, 0, 1>>, <<178, 121, 76, 200, 168, 235, 151, 217, 13, 146, 94, 167, 184, 24, 103, 4, 71, 232, 222, 187, 242, 43, 201, 206, 9, 72, 38, 141, 71, 183, 193, 79, 96, 47, 11, 197, 9, 79, 186, 87, 134, 20, 214, 119, 17, ...>>], [<<1, 0, 1>>, <<178, 121, 76, 200, 168, 235, 151, 217, 13, 146, 94, 167, 184, 24, 103, 4, 71, 232, 222, 187, 242, 43, 201, 206, 9, 72, 38, 141, 71, 183, 193, 79, 96, 47, 11, 197, 9, 79, 186, 87, 134, 20, 214, 119, ...>>, <<36, 1, 192, 242, 2, 210, 117, 50, 63, 64, 182, 132, 19, 234, 40, 110, 126, 171, 134, 180, 88, 105, 105, 47, 126, 67, 230, 51, 62, 178, 221, 247, 75, 170, 114, 47, 112, 111, 123, 98, 201, 20, 79, ...>>, <<223, 174, 98, 120, 166, 199, 34, 129, 230, 158, 40, 40, 33, 31, 249, 41, 170, 201, 126, 28, 198, 156, 91, 16, 253, 170, 10, 56, 182, 211, 191, 77, 97, 146, 141, 133, 159, 124, 136, 47, 187, 243, ...>>, <<204, 66, 196, 29, 80, 253, 242, 26, 205, 16, 230, 113, 34, 45, 70, 56, 234, 19, 31, 223, 202, 193, 40, 12, 38, 108, 131, 166, 205, 90, 133, 22, 187, 76, 37, 36, 38, 153, 233, 73, 59, ...>>, <<104, 67, 12, 187, 88, 97, 241, 255, 194, 211, 109, 188, 102, 212, 84, 123, 203, 147, 232, 40, 217, 155, 0, 7, 199, 117, 127, 22, 56, 130, 50, 229, 138, 217, 153, 5, 243, 245, 68, 53, ...>>, <<188, 187, 184, 79, 202, 69, 74, 205, 222, 203, 13, 210, 93, 28, 238, 52, 170, 124, 15, 72, 142, 36, 153, 167, 88, 93, 141, 235, 178, 245, 63, 225, 248, 31, 236, 117, 145, 193, 70, ...>>, <<35, 138, 180, 228, 184, 64, 111, 151, 24, 72, 177, 78, 7, 82, 185, 141, 129, 128, 249, 46, 61, 166, 209, 175, 202, 195, 140, 234, 161, 251, 202, 156, 95, 135, 50, 251, 104, 117, ...>>]}, topic: %Anoma.Node.Router.Addr{server: nil, id: %Anoma.Crypto.Id.Extern{encrypt: <<190, 53, 205, 235, 5, 226, 41, 27, 52, 24, 129, 130, 166, 110, 247, 96, 38, 104, 62, 8, 193, 71, 72, 220, 200, 81, 64, 249, 236, 17, 96, 89>>, sign: <<220, 94, 47, 24, 186, 196, 237, 131, 1, 55, 84, 239, 201, 26, 56, 163, 239, 46, 23, 104, 7, 183, 111, 117, 235, 229, 167, 14, 178, 32, 27, 137>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\"}, round: 1, transactions: [], block_storage: :loggerdoc_blocks, executor: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Executor bMdE8VVjfHe6Cwwf7x7HPnKE4UIk0ppsTRd+3lFCMfo=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<124, 24, 139, 146, 134, 161, 98, 88, 227, 169, 92, 251, 165, 248, 140, 252, 237, 115, 81, 219, 226, 98, 33, 106, 80, 195, 115, 74, 84, 4, 91, 114>>, sign: <<108, 199, 68, 241, 85, 99, 124, 119, 186, 11, 12, 31, 239, 30, 199, 62, 114, 132, 225, 66, 36, 210, 154, 108, 77, 23, 126, 222, 81, 66, 49, 250>>}, router: %Anoma.Node.Router.Addr{server: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKgnigMiRSSmPEgCawDGI7LHiQ=\\\", id: %Anoma.Crypto.Id.Extern{encrypt: <<119, 208, 33, 8, 239, 236, 229, 232, 138, 95, 91, 188, 195, 79, 17, 234, 79, 208, 198, 219, 11, 153, 108, 18, 6, 216, 210, 76, 227, 242, 219, 19>>, sign: <<248, 63, 8, 194, 141, 154, 218, 50, 2, 58, 25, 158, 71, 34, 160, 158, 40, 12, 137, 20, 146, 152, 241, 32, 9, 172, 3, 24, 142, 203, 30, 36>>}, router: :\\\"Anoma.Node.Router +D8Iwo2a2jICOhmeRyKg\" <> ...}\n]\n```\n\n```elixir\nlogger\n|> Logger.get(node.mempool)\n|> Enum.filter(fn {_list, msg} ->\n  String.contains?(msg, \"Transaction added\")\nend)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {[\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<230, 134, 45, 59, 48, 241, 215, 184, 53, 196, 224, 184, 103, 239, 83, 231, 220,\n         144, 234, 233, 14, 163, 59, 67, 134, 163, 174, 139, 120, 92, 220, 90>>,\n       sign: <<30, 58, 242, 106, 16, 228, 250, 244, 58, 170, 209, 100, 238, 190, 154, 123, 39, 76,\n         223, 88, 94, 88, 213, 209, 109, 34, 244, 186, 16, 62, 42, 98>>\n     },\n     %Anoma.Crypto.Id.Extern{\n       encrypt: <<253, 166, 38, 84, 229, 119, 215, 124, 49, 53, 22, 169, 126, 117, 33, 219, 26, 173,\n         225, 187, 54, 10, 32, 100, 21, 61, 121, 142, 141, 98, 107, 82>>,\n       sign: <<122, 24, 241, 113, 58, 166, 252, 185, 86, 76, 73, 43, 53, 32, 243, 170, 111, 97, 41,\n         49, 175, 182, 210, 234, 98, 20, 210, 148, 229, 140, 12, 103>>\n     },\n     35608,\n     :info\n   ],\n   \"Transaction added. New pool: [%Anoma.Transaction{transaction: {:kv, [[8, [1 | 0], [1, [1 | 555], 4, 12, [1 | 0], [0 | 6], 1, 555 | 0], 0 | 1], [[8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 118], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 238], 0 | 2], [6, [5, [1 | 1], 8, [9, 1406, 0 | 255], 9, 2, 10, [6, 0 | 958], 0 | 2], [6, [5, [1 | 0], 0 | 446], [0 | 0], 6, [0 | 3570], [1 | 0], 1 | 1], 1 | 1], 1 | 1], 1 | 1], 0 | 1], 8, [1, [[[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 5, [1 | 0], 0 | 446], 0 | 1], [[1 | 0], [8, [1, 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 28], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 181, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 58], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 44, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 118], 0 | 2], [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 9, 180, 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 238], 0 | 2], [8, [7, [0 | 7], 9, 46, 0 | 1], 9, 2, 10, [6, 0 | 478], 0 | 2], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], 6, [5, [1 | 0], 0 | 447], [1 | 0], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [8, [7, [0 | 7], 9, 91, 0 | 1], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [6, [6, [3, 0 | 6], [1 | 1], 1 | 0], [0 | 6], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [[1 | 0], [0 | 0] | 0], 0, 0, 0, 0, 0, 0 | 0], [1, 8, [[8, [7, [0 | 7], 9, 47, 0 | 1], 9, 2, 10, [6, 0 | 28], 0 | 2], [6, [6, [3, 0 | 26], [1 | 1], 1 | 0], [0 | 26], 0 | 0], [6, [6, [3, 0 | 54], [1 | 1], 1 | 0], [0 | 54], 0 | 0], [6, [6, [3, 0 | 110], [1 | 1], 1 | 0], [0 | 110], 0 | 0], [6, [5, [1 | 0], 0 | 222], [1 | 0], 6, [5, [1 | 1], 0 | 222], [1 | 1], 0 | 0], [6, [6, [3, 0 | 446], [1 | 1], 1 | 0], [0 | 446], 0 | 0], [6, [6, [3, 0 | 894], [1 | 1], 1 | 0], [0 | 894], 0 | 0], 6, [6, [3, 0 | 895], [1 | 1], 1 | 0], [0 | 895], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [8, [1 | 0], [1, 8, [8, [7, [0 | 7], 8, [9, 47, 0 | 31], 9, 2, 10, [6, 7, [0 | 3], 8, [1, 0, 0 | 0], [1, 8, [[6, [6, [3, 0 | 12], [1 | 1], 1 | 0], [0 | 12], 0 | 0], [6, [5, [1 | 0], 0 | 26], [1 | 0], 6, [5, [1 | 1], 0 | 26], [1 | 1], 0 | 0], 6, [6, [3, 0 | 27], [1 | 1], 1 | 0], [0 | 27], 0 | 0], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 2], 9, 2, 10, [6, 0 | 14], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1, [1 | 0], [0 | 0] | 0], [1, 8, [7, [1 | 0], 8, [1, 0 | 0], [1, 1 | 0], 0 | 1], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [[7, [8, [1, 0 | 0], [1, 8, [1, 0 | 0], 8, [1, 6, [6, [5, [1 | 0], 0 | 60], [6, [5, [1 | 0], 0 | 61], [1 | 0], 1 | 1], 1 | 1], [0 | 13], 9, 2, 10, [30, [8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 124], 0 | 2], 8, [8, [9, 10, 0 | 63], 9, 767, 10, [6, 7, [0 | 3], 1 | 0], 0 | 2], 9, 2, 10, [6, [7, [0 | 3], 1 | 1], 0 | 125], 0 | 2], 10, [6, [4, 0 | 12], 8, [9, 20, 0 | 511], 9, 2, 10, [6, [0 | 29], 7, [0 | 3], 8, [8, [9, 10, 0 | 63], 9, 90, 10, [6, ...], 0 | 2], 9, 2, 10, [6, [0 | 28], 7, ...], 0 | 2], 0 | 2], 0 | 1], 9, 2, 0 | 1], 0 | 1], 11, [1953718630, 1, 7891309, [0 | 7] | 0], 0 | 1], [[8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], [1, 8, [[0 | 50], 0 | 54], [1, 8, [[8, [0 | 60], 9, 2, 10, [6, 0 | 28], 0 | 2], 8, [0 | 61], 9, 2, 10, [6, 0 | 29], 0 | 2], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 0 | 1], [8, [[8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 | 14], 0 | 2], 0 | 6], 0 | 1], 8, [1 | 0], [1, 8, [0 | 6], 8, [5, [0 \" <> ...}\n]\n```\n\nAssuming the user knows the Nock code for increments and zero counters, they will be able to determine why the error occured exactly.\n\nHere we have showcased several ways in which the Logging engine can be used. It sends error messages directly to the user when encountered, stores major info re worker and engine actions, as well as allowing the user to prompt the logging messages using the usual filtering mechanisms.\n\nNote that the logging functionality is easily added into working engines and hence the contributors can readily add more detailed logging at their convenience. Similarly, the keyspace storing can be more thorought, containing more info on the sending agents. Moreover, note that the better the user is acquainted with the actual logging messages, the more efficient the debigging.","ref":"logging.html#using-the-logger"},{"type":"extras","title":"TOC","doc":"# TOC","ref":"toc.html"},{"type":"extras","title":"Index - TOC","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"toc.html#index"},{"type":"extras","title":"TOC - TOC","doc":"This notebook organizes a set of lessons to help you get started with Anoma!\n\nThis book uses livebook, it is best viewed from within it! However most sections can be viewed fine in github or your text editor.","ref":"toc.html#toc"},{"type":"extras","title":"User","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# User","ref":"user.html"},{"type":"extras","title":"Index - User","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"user.html#index"},{"type":"extras","title":"User Guide - User","doc":"Welcome to the Anoma documentation for users.\n\nThese documents contain pertinent information about your local Anoma node.","ref":"user.html#user-guide"},{"type":"extras","title":"Data","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Data","ref":"data.html"},{"type":"extras","title":"Index - Data","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"data.html#index"},{"type":"extras","title":"Where Anoma saves State - Data","doc":"Anoma follows [XDG](https://en.wikipedia.org/wiki/Freedesktop.org) conventions for state stored on the operating system:\n\n1. Database dumps and Database tables are stored in `$XDG_DATA_HOME/anoma_env`\n2. Configuration files are stored in `$XDG_CONFIG_HOME/anoma_env`","ref":"data.html#where-anoma-saves-state"},{"type":"extras","title":"Configuration Files - Data","doc":"Currently Anoma stores a file `config.toml` with minimal settings for your Anoma node.","ref":"data.html#configuration-files"},{"type":"extras","title":"Configuration Format - Data","doc":"TODO write about each field or link to a relavent section","ref":"data.html#configuration-format"},{"type":"extras","title":"Sending in a custom configuration file - Data","doc":"TODO explain how to do this","ref":"data.html#sending-in-a-custom-configuration-file"},{"type":"extras","title":"Data Files - Data","doc":"Anoma stores a few different files in the `$XDG_DATA_HOME`\n\n1. [Mnesia](https://en.wikipedia.org/wiki/Mnesia) tables backed by [RocksDB](https://en.wikipedia.org/wiki/RocksDB)\n2. Anoma dump files.\n\nThe `dump` file contains all information necessary to restore `Anoma` to the time when the `dump` command was used on `Anoma`.\n\nBeware this will overwrite the local [Mnesia](https://en.wikipedia.org/wiki/Mnesia) tables.\n\nThe Mnesia tables are created every time one runs Anoma.\n\nThese Mnesia tables contain chain information that the Anoma execution environment can query.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nTo learn more about our data format, please checkout the developer's section on [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd).","ref":"data.html#data-files"},{"type":"extras","title":"Launching with a given dump file - Data","doc":"TODO write how to send in the CLI arguments to restore a dump","ref":"data.html#launching-with-a-given-dump-file"},{"type":"extras","title":"Anoma VM interface","doc":"# Anoma VM interface","ref":"vm_interface.html"},{"type":"extras","title":"Index - Anoma VM interface","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"vm_interface.html#index"},{"type":"extras","title":"The Executor context - Anoma VM interface","doc":"The Executor context proceeds according to one of several modes:\n\n* `kv` mode: updates keys in a simple key-value store, and\n* `rm` mode: assembles resource machine transactions to be passed to the\n  resource machine context.\n\nAn additional mode is planned for the shielded resource machine, when\nintegrated; and `kv` mode is an early prototype of what will evolve into\nthe content-addressed blob storage facility.\n\n`kv` and `rm` modes share the same execution interface: they expect a Nock\n`gate`. A `gate` is a function-like object with the following form:\n\n```\n[code [sample context]]\n```\n\n`code` is a Nock formula intended to be run with the gate as subject, while\n`sample` is a placeholder for arguments to the gate. `context` contains any\nadditional code or data referenced; this includes at least the standard\nlibrary, but may be larger than it.\n\nIn both `kv` and `rm` modes, the submitted transaction is a gate, and the\nargument placed in the sample is its opaque order ID. The output expected\nis the following tuple:\n\n```\n[[read-keyspaces write-keyspaces] second-gate]\n```\n\nIn `kv` mode, `read-keyspaces` and `write-keyspaces` are subspaces of the\nkey-value store which the transaction plans to read or write, respectively.\nThe VM may use this information to place locks or otherwise prepare for\ntransaction execution. It is an error to read outside the declared\n`read-keyspaces` or write outside the declared `write-keyspaces`\n\nIn `rm` mode, `read-keyspaces` and `write-keyspaces` are always the entire\n`rm` keyspace. Every `rm` transaction updates the commitment and nullifier\ntrees.\n\nThe scry operation is illegal in the execution of the first gate, because\nthe transaction has not declared its read locks yet.\n\nThe second gate may perform the scry operation. It is more properly termed\na `trap` as it takes no arguments. However, its scries are restricted to\nthe `read-keyspaces` returned along with it.\n\nThe scry operation blocks until its read lock is released by the VM. It may\nfail, causing the whole transaction to fail, if it reads an invalid or\ndisallowed key.\n\nThe second gate's output is a list of key-value pairs to update in `kv`\nmode, and a resource machine transaction in `rm` mode.","ref":"vm_interface.html#the-executor-context"},{"type":"extras","title":"The Resource Machine context - Anoma VM interface","doc":"When the VM's resource machine implementation processes a resource\ntransaction, this includes the execution of resource logics in each\nresource. Shielded resource transactions will proceed similarly, but\nwithin the shielded VM rather than the Nock VM.\n\nA resource logic is also a gate, and the arguments it takes are the tuple\n\n```\n[self resource-transaction]\n```\n\nwhere `self` is a copy of the entire resource running the logic, and\n`resource-transaction` is the Nock serialization of the entire resource\ntransaction (which includes all resources, in the transparent resource\nmachine).\n\nIts output is a simple boolean: `0` for success, `1` for failure.","ref":"vm_interface.html#the-resource-machine-context"},{"type":"extras","title":"Gas metering - Anoma VM interface","doc":"All Nock execution is metered simply: starting with a meter value of 0,\nincrementing by 1 for each recursion back into simple Nock evaluation,\nand incrementing by a defined per-jet constant for each jet invoked.","ref":"vm_interface.html#gas-metering"},{"type":"extras","title":"Examples over Testing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Examples over Testing","ref":"examples-over-testing.html"},{"type":"extras","title":"Index - Examples over Testing","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"examples-over-testing.html#index"},{"type":"extras","title":"Intro - Examples over Testing","doc":"In complex software projects, there are a variety of automated tools employed to make sure the system works as intended. The two most popular examples are `tests` and `type systems`. As of the time of this writing, the `Anoma` codebase has embraced both of these; having a `73%` test coverage and the majority of functions with type signatures!\n\nThis article will focus on the downside of `testing` in elixir, and give a compelling argument for `examples` over testing!","ref":"examples-over-testing.html#intro"},{"type":"extras","title":"What are Examples - Examples over Testing","doc":"The word `testing` in the context of software development is widely understood, however the term `examples` does not have the same level of recognition.\n\nIn order to clarify the meaning within `Anoma`, we will take [Glamorous Toolkit](https://gtoolkit.com/)'s definition of example, as they have created a well-thought-out system that successfully replaces most `tests` with `examples`\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n[According to Glamorous Toolkit examples are](https://book.gtoolkit.com/examples-6k9vwuau8psg5ghsgb64zriih):\n\n\"a way of demonstrating how to use the system and check that it is operating correctly.\n\nThey are similar to SUnit tests in that they make assertions to confirm that the system is operating correctly, but unlike SUnit tests, which typically don't return anything, they answer an object which is useful in its own right.\"\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor the purposes of discussion, we can consider [SUnit](https://en.wikipedia.org/wiki/SUnit) and [ExUnit](https://hexdocs.pm/ex_unit/ExUnit.html) to be the same. Meaning that there are large overlaps in the practical function between `examples` and `tests`.","ref":"examples-over-testing.html#what-are-examples"},{"type":"extras","title":"Downsides of testing in Elixir - Examples over Testing","doc":"To get a feeling for what `examples` can offer the codebase, we should first discuss the downsides with how `Anoma` interacts with tests.\n\n1. Tests are not loaded into `IEx` at startup.\n2. To run tests by hand, we need to copy paste:\n   1. Imports.\n   2. `setup_all` logic.\n   3. the test up until the point we care about.\n3. Tests can't be abstracted in the test module without breaking copy and pasting.\n4. Tests can't have dialyzer run over them.\n5. `IEx` does not re-run tests on demand, one has to recompile the test after already running the tests\n6. [LSP](https://en.wikipedia.org/wiki/Language_Server_Protocol) seems to not be able to calculate references of values to tests due to them not being compiled.","ref":"examples-over-testing.html#downsides-of-testing-in-elixir"},{"type":"extras","title":"How would Examples work in Elixir? - Examples over Testing","doc":"Before we go and talk about addressing the issues with testing, let us first envision how we would go about making examples. Below are rules that we can apply to creating our very first examples.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n1. They belong in a module `example/e `. Where `module-name` is the module one is interested in testing.\n2. Any piece of logic that is relied upon by other parts, is an example.\n3. If any code spawns actors, they should either register themselves or be memoized.\n4. We should run asserts on data whenever possible.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor demonstration purposes, let us take the most common kinds of tests we have and imagine what they would look like as examples\n\n1. The first kind of test is testing non actors.\n2. The second kind of test is testing stateful actors.\n\nTests in the first category tend to care about the form of data and making assertions about said data, while the second category is more about testing the interactions between multiple actors and the final state they produce.\n\nThe translation of tests in classification `2.` into examples can be split into two phases:\n\n1. The first phase will cover translating the `setup` state as global examples. This is not perfect but maintains the same semantics as the test.\n2. The second phase will make the global setup logic specific per example, making stateful examples return the final network state.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#how-would-examples-work-in-elixir"},{"type":"extras","title":"Examplifying non Actors - Examples over Testing","doc":"A good example we can use, is a test in our `resource` test file.\n\n```elixir\ndefmodule AnomaTest.Resource do\n  test \"commitments and nullifiers\" do\n    keypair_a = Sign.new_keypair()\n    keypair_b = Sign.new_keypair()\n\n    a_r1 = new_with_npk(keypair_a.public)\n    a_r2 = new_with_npk(keypair_a.public)\n    b_r0 = new_with_npk(keypair_b.public)\n\n    # just in case\n    assert a_r1 != a_r2\n\n    c_a_r1 = commitment(a_r1)\n    c_a_r2 = commitment(a_r2)\n    c_b_r0 = commitment(b_r0)\n\n    n_a_r1 = nullifier(a_r1, keypair_a.secret)\n    n_a_r2 = nullifier(a_r2, keypair_a.secret)\n    n_b_r0 = nullifier(b_r0, keypair_b.secret)\n\n    assert c_a_r1 |> commits_to(a_r1)\n    refute c_a_r1 |> commits_to(a_r2)\n    refute c_a_r1 |> commits_to(b_r0)\n\n    refute c_a_r2 |> commits_to(a_r1)\n    assert c_a_r2 |> commits_to(a_r2)\n    refute c_a_r2 |> commits_to(b_r0)\n\n    refute c_b_r0 |> commits_to(a_r1)\n    refute c_b_r0 |> commits_to(a_r2)\n    assert c_b_r0 |> commits_to(b_r0)\n\n    assert n_a_r1 |> nullifies(a_r1)\n    refute n_a_r1 |> nullifies(a_r2)\n    refute n_a_r1 |> nullifies(b_r0)\n\n    refute n_a_r2 |> nullifies(a_r1)\n    assert n_a_r2 |> nullifies(a_r2)\n    refute n_a_r2 |> nullifies(b_r0)\n\n    refute n_b_r0 |> nullifies(a_r1)\n    refute n_b_r0 |> nullifies(a_r2)\n    assert n_b_r0 |> nullifies(b_r0)\n  end\n\n  test \"nullify with wrong key\" do\n    keypair_a = Sign.new_keypair()\n    keypair_b = Sign.new_keypair()\n\n    a_resource = new_with_npk(keypair_a.public)\n    wrong_nullifier = nullifier(a_resource, keypair_b.secret)\n\n    refute wrong_nullifier |> nullifies(a_resource)\n  end\nend\n```\n\nThe crux of this module is creating some resources, and testing that they behave properly!\n\nHowever since tests are not composable, we have to waste time recreating more resources in another test!\n\nIf we were to reimagine this test as an example it would look something like this.\n\n```elixir\ndefmodule Example.EResource do\n  # Memoize it as we want it to always be the same!\n  defmemo(keypair_a(), do: Sign.new_keypair())\n  defmemo(keypair_b(), do: Sign.new_keypair())\n\n  # new_with_npk gives new resources, so memo again\n  defmemo(a_resource(), do: new_with_npk(keypair_a().public))\n  defmemo(b_resource(), do: new_with_npk(keypair_b().public))\n  defmemo(a2_resource(), do: new_with_npk(keypair_a().public))\n\n  # Now we get interesting\n  def commit_a() do\n    commitment = commitment(a_resource())\n    assert commitment |> commits_to(a_resource())\n    refute commitment |> commits_to(b_resource())\n    commitment\n  end\n\n  def commit_a2() do\n    commitment = commitment(a2_resource())\n    assert commitment |> commits_to(a2_resource())\n    refute commitment |> commits_to(a_resource())\n    assert commitment != commit_a()\n    commitment\n  end\n\n  def commit_b() do\n    commitment = commitment(a2_resource())\n    assert commitment |> commits_to(b_resource())\n    refute commitment |> commits_to(a_resource())\n    commitment\n  end\n\n  def nullifier_a() do\n    nullifier = nullifies(a_resource(), keypair_a().private)\n    assert nullifier |> nullifies(a_resource())\n    refute nullifier |> nullifies(b_resource())\n    nullifier\n  end\n\n  def nullifier_a2() do\n    nullifier = nullifies(a_resource(), keypair_a2().private)\n    assert nullifier |> nullifies(a2_resource())\n    refute nullifier |> nullifies(a_resource())\n    assert nullifier != nullifier_a()\n    nullifier\n  end\n\n  def nullifier_b() do\n    nullifier = nullifies(b_resource(), keypair_b().private)\n    assert nullifier |> nullifies(b_resource())\n    refute nullifier |> nullifies(a_resource())\n    nullifier\n  end\n\n  def invalid_nullifier() do\n    nullifier = nullifies(a_resource(), keypair_b().private)\n    refute nullifier |> nullifies(a_resource())\n    nullifier\n  end\nend\n```\n\nAlthough this code is `5` more lines of code, it has many strong properties:\n\n1. Each component is now a top level name. Meaning we can now play with `nullifier_a` in `IEx`. No copy and pasting needed!\n2. We can add type signatures for each definition, to ensure we have type checking and writing down our own intents!\n3. We didn't need to unnecessarily generate extra keys, and resources. We can reuse them!\n4. We are writing properties about the data we wish to have.\n5. Any other example files can rely on this example file! (hint maybe our next example will use this one)\n\nPoint `4.` should be expanded upon. In a test, one is testing many things at once, but what makes examples strong is that we are denoting the dynamic properties we wish data to respect! Because we are doing this on a data basis, it becomes easy to later come back to these and add new facts to the examples.\n\nTests discourage this, as they have a singular purpose they exist for, they do not encourage good behavior!\n\nFurther, if we were to not do a 1 to 1 extraction, we could factor some of the data here to `Signature` examples as well! We will see how this principle works out in practice in the next section.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#examplifying-non-actors"},{"type":"extras","title":"Examplifying stateful code - Examples over Testing","doc":"```elixir\ndefmodule AnomaTest.Node.Executor.Worker do\n  use ExUnit.Case, async: true\n\n  setup_all do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n\n    {:ok, router, _} = Anoma.Node.Router.start()\n\n    {:ok, storage} =\n      Anoma.Node.Router.start_engine(router, Storage, storage)\n\n    {:ok, ordering} =\n      Anoma.Node.Router.start_engine(router, Ordering, table: storage)\n\n    snapshot_path = [:my_special_nock_snaphsot | 0]\n\n    env = %Nock{snapshot_path: snapshot_path, ordering: ordering}\n\n    [env: env]\n  end\n\n  test \"worker evaluates resource transaction\", %{env: env} do\n    import Anoma.Resource\n    alias Anoma.Resource.ProofRecord\n    alias Anoma.Resource.Transaction\n\n    id = System.unique_integer([:positive])\n\n    storage = Ordering.get_storage(env.ordering)\n\n    Storage.ensure_new(storage)\n    Ordering.reset(env.ordering)\n\n    keypair = Anoma.Crypto.Sign.new_keypair()\n\n    in_resource = %{\n      new_with_npk(keypair.public)\n      | label: \"space bucks\",\n        quantity: 10\n    }\n\n    nf_in = nullifier(in_resource, keypair.secret)\n    pf_in = ProofRecord.prove(in_resource)\n\n    out_resource = %{\n      new_with_npk(keypair.public)\n      | label: \"space bucks\",\n        quantity: 10\n    }\n\n    cm_out = commitment(out_resource)\n    pf_out = ProofRecord.prove(out_resource)\n\n    rm_tx = %Transaction{\n      commitments: [cm_out],\n      nullifiers: [nf_in],\n      proofs: [pf_in, pf_out],\n      delta: %{}\n    }\n\n    rm_tx_noun = Transaction.to_noun(rm_tx)\n    rm_executor_tx = [[1 | rm_tx_noun], 0 | 0]\n\n    spawn = Task.async(Worker, :run, [id, {:rm, rm_executor_tx}, env])\n    Ordering.new_order(env.ordering, [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n  end\nend\n```\n\nThis test has a few parts, one part is a `test_setup` and another part is the actual testing code itself.\n\nI will reimagine this module in two phases. The first respecting the fact that `setup_all` is unique and is efficient as it spawns only 1 network for the entire module. The second will instead make the node specific to each example that relies upon it. Returning the network as the interesting object.\n\n```elixir\ndefmodule Example.Worker.Phase1 do\n\n  defmemo router() do\n    assert {:ok, router, _} = Router.start()\n    router\n  end\n\n  def raw_storage() do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n  end\n\n  defmemo storage() do\n     {:ok, storage} = Router.start_engine(router(), Storage, raw_storage())\n     storage\n  end\n\n  defmemo ordering() do\n    {:ok, ordering} = Router.start_engine(router(), Ordering, table: storage())\n     ordering\n  end\n\n  def env() do\n   %Nock{snapshot_path: Enock.snapshot_path(), ordering: ordering}\n  end\n\n  # Let's get an unique number\n  defmemo unique_id() do\n    System.unique_integer([:positive])\n  end\n\n  def successfully_fire_trans() do\n    Storage.ensure_new(storage())\n    Ordering.reset(ordering())\n\n    spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env()])\n    Ordering.new_order(ordering(), [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n    :ok\n  end\nend\n\ndefmodule Example.ProofRecord do\n  def proved_spacebucks_a() do\n    ProofRecord.prove(Eresource.space_bucks_10_a())\n  end\n\n  def proved_spacebucks_b() do\n    ProofRecord.prove(Eresource.space_bucks_10_b())\n  end\nend\n\ndefmodule Example.Transaction do\n  def balanced_space_transaction() do\n    trans = %Transaction{\n      commitments: [EResource.commitment_space_bucks_a()]\n      nullifiers: [ERsource.nullifier_space_bucks_b()],\n      proofs: [proved_spacebucks_a(), proved_spacebucks_b()]\n    }\n    # This wans't in the original test!\n    assert verify(trans)\n    trans\n  end\n\n  def space_trans_candidate() do\n    Transaction.to_noun(balanced_space_transaction())\n    [[1 | rm_tx_noun], 0 | 0]\n  end\nend\n```\n\nNotice we ended up calling a lot of examples from `EResource`. Some of the examples already existed even without this test (we really had `spacebucks` already in the codebase! Duplicated in the `Worker` and in `Resource`).\n\nFurther most of the logic that recreates `resources` are better placed in the actual `Example.EResource` file, as they are relevant examples for someone who is looking for resources. Why would they look at the worker to see examples of the Resources? Likewise, people who are looking at the worker code, would want to look at worker logic, not resource logic!\n\nWe can see the benefits examples offer even stateful tests:\n\n1. Most of the boilerplate of creating unrelated types are confined in the proper modules!\n2. There may be an example off hand which satisfies what we want (we already had spacebucks in `EResource`)\n3. Rephrasing a test as an example doesn't lose any information. the actual example is simply not interesting!\n4. We can run the stateful tests from IEx and even pry into it without any issues!\n\nWith these benefits of mind let us see if `Phase2` can improve point `3.` a bit:\n\n```elixir\ndefmodule Example.Worker.Phase2 do\n  def router() do\n    assert {:ok, router, _} = Router.start()\n    router\n  end\n\n  def raw_storage() do\n    storage = %Storage{\n      qualified: AnomaTest.Worker.Qualified,\n      order: AnomaTest.Worker.Order\n    }\n  end\n\n  def storage(router) do\n    {:ok, storage} = Router.start_engine(router, Storage, raw_storage())\n    storage\n  end\n\n  def ordering(router, storage) do\n    {:ok, ordering} = Router.start_engine(router, Ordering, table: storage)\n    ordering\n  end\n\n  def env(ordering) do\n    %Nock{snapshot_path: Enock.snapshot_path(), ordering: ordering}\n  end\n\n  def network() do\n    router = router()\n    storage = storage(router)\n    %Node{router: router, ordering: ordering(router, storage), storage: storage}\n  end\n\n  # Let's get an unique number\n  defmemo unique_id() do\n    System.unique_integer([:positive])\n  end\n\n  def successfully_fire_trans() do\n    net = network()\n    env = env(net.ordering)\n    spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env])\n    Ordering.new_order(net.ordering, [Order.new(0, id, spawn.pid)])\n\n    send(spawn.pid, {:write_ready, 0})\n    assert :ok == Task.await(spawn)\n    net\n  end\nend\n```\n\nIn Phase2 we abstracted out some examples, so that they are no longer standalone examples.\n\nSadly `storage`, `router`, `env` and `ordering` are no longer examples, but are generator functions for the data we care about. (maybe we can restore this somehow!)\n\nHowever, notice that the return of `sucessfully_fire_trans/0`, now returns the network!\n\nThis means that if we wanted, we can use this environment for further tests. Such as making sure nullifiers don't insert twice\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\ndef failed_trans() do\n  net = succesfully_fire_trans()\n  env = env(net.ordering)\n  spawn = Task.async(Worker, :run, [id, {:rm, space_trans_candidate()}, env])\n  Ordering.new_order(net.ordering, [Order.new(0, id, spawn.pid)])\n  assert :error == Task.await(spawn)\n  for nullifier <- space_trans_candidate().nullifiers do\n    assert in_nullifer_set(env, nullifier)\n  end\n  net\nend\n```\n\nBesides reuse we get the following advantages in `Phase2`:\n\n1. If we had visualization tooling, we can take the result of `successfully_fire_trans/0` and view all the views of the data. Meaning that if we made tooling that charts simulated latency, connected node graphs, successful and failed transactions, we would be able to chart them all and visually see the difference between this one and `failed_trans/0`.\n2. We can inspect the state of the network querying for new facts we did not know about before. And consider if any facts are interesting enough to assert that the property holds in the particular example.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"examples-over-testing.html#examplifying-stateful-code"},{"type":"extras","title":"Temporary Setbacks - Examples over Testing","doc":"One small annoyance, is that in order to run the tests, we have to currently by hand put the examples in a test file to make sure they are ran.\n\nThis can be offset by a macro that scrapes the examples modules and automatically registers the tests. So this is not a hard issue for the `example` style.","ref":"examples-over-testing.html#temporary-setbacks"},{"type":"extras","title":"Addressing testing issues - Examples over Testing","doc":"Now that we have a concrete idea of what `examples` look like, let us see how they fix our problems with tests:\n\n1. Tests are not loaded into `IEx` at startup.\n   * They are in the lib folder, they are loaded!\n2. To run tests by hand, we need to copy paste:\n   * No copy and pasting required, we can pry and avoid copy and paste!\n3. Tests can't be abstracted in the test module without breaking copy and pasting.\n   * We can abstract as much as we want\n4. Tests can't have dialyzer run over them.\n   * We can run dialyzer and even type our examples!\n5. `IEx` does not re-run tests on demand, one has to recompile the test after already running the tests\n   * We can re-run the example whenever we want\n6. [LSP](https://en.wikipedia.org/wiki/Language_Server_Protocol) seems to not be able to calculate references of values to tests due to them not being compiled.\n   * LSP should work as it's compiled like everything else.","ref":"examples-over-testing.html#addressing-testing-issues"},{"type":"extras","title":"Outstanding questions - Examples over Testing","doc":"The most straight forward strategy would be:\n\n1. Take each test module and convert it to tests.\n2. Once most of the modules are done, convert all stateful tests into `phase2`.\n\nHowever there are open questions:\n\n1. How slow is node setup? Will `phase2` make tests run longer than 2 seconds (unacceptable)?\n2. How long until we have a macro that auto registers the examples so they can be ran with `mix test`?\n3. How will our usage of `examples` evolve over time?\n4. How to deal with tests that make socket files then deletes them after all is done? Will Phase2 make this question obsolete?\n5. Can the process be improved? [One of the Authors of GT has a paper about converting `JUnit` to `JExample`. This can probably inform our own transition and ideas on creating examples](https://scg.unibe.ch/archive/masters/Haen09a.pdf)","ref":"examples-over-testing.html#outstanding-questions"},{"type":"extras","title":"Git","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Git","ref":"git.html"},{"type":"extras","title":"Index - Git","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"git.html#index"},{"type":"extras","title":"Git - Git","doc":"Git is a decent version control(VC) system, however there are ways to\nmake the VC process a lot smoother.\n\nThis document is best viewed from within liveview, as the charts do not render on github currently.","ref":"git.html#git"},{"type":"extras","title":"Terminology - Git","doc":"* `topic` - this is any branch that serves to fix some problem in the\n  codebase\n\n* `feature` - some new concept to the codebase. Many topics can serve\n  to fulfill one feature.\n\n* `release` - A release of the code. This is a git `tag` on `main`\n  that signifies a new version of the software. This typically bumps\n  base to the latest release as well\n\n* `base` - the base branch one should base work off of\n\n* `main` - sometimes called `master`, is the branch that prepares for\n  a release.\n\n* `next` - a branch that has a superset of features that will be\n  included in the next release\n\n* `maint` - a maintnance branch that will be updated if bugs are found\n\n* `integreation branch` - a topic that merges a bunch of other topics","ref":"git.html#terminology"},{"type":"extras","title":"Naming conventions - Git","doc":"Name your topic like `name/feature` to avoid clashing with other\npeople's topics.\n\nThere are some standard branches that do not follow this pattern but\nthose are described in the `Terminology` section of this document","ref":"git.html#naming-conventions"},{"type":"extras","title":"General Principles - Git","doc":"These are some general principles which should help maintainers easily\nintegrate your code, and have your work help out other devs on the\ncodebase.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#general-principles"},{"type":"extras","title":"Do not include unrelated changes into your commits - Git","doc":"* For example, if you see some unrelated bug in the same file as your\n  own, don't fix it in your general commit, make a new topic based on\n  when the bug was introduced and merge that into your topic if it\n  impacts your topic.\n\n* This makes reviewing much easier as the reviewer can read your\n  commit message and see changes only related to that included\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#do-not-include-unrelated-changes-into-your-commits"},{"type":"extras","title":"Make topics early and often! - Git","doc":"This allows your work to be incrementally integrated into a\nrelease. If you put all your work into one topic, bug fixes and all,\nthen the following will occur\n\n1. The changes will not be reviewed properly\n\n   * On big projects with tight deadlines, sometimes some feature\n     *X* is wanted. However if *X* is a single topic with a messy\n     history, the only options are either to scrap the feature or\n     accept it as is poor code in all.\n   * If this was properly split up parts of *X* could be merged\n     now, with the more controversial features being held up in\n     *next*, without having to sacrifice the quality of the\n     codebase.\n\n2. Other team members can not share similar work\n\n   * Often a lot of different tasks, may find the same\n     deficiencies in the codebase.\n\n   * For a real example, let's take the following commit and topic\n\n     ```example\n     802ab9e * anoma/mariari/nock-testing-file Move the helper functions\n     73bfd7d * v0.3.0\n      2 files changed, 44 insertions(+), 34 deletions(-)\n     lib/test_helper/nock.ex | 43 +++++++++++++++++++++++++++++++++++++++++++\n     test/nock_test.exs      | 35 +----------------------------------\n     ```\n\n     Here we find that we `mariari` moved some testing functions from\n     `test/` to `lib/`, as elixir tests don't share code in the best\n     way. This allows other files in `test/` to reuse the same\n     functions that were previously found in `test/nock_test.exs`.  In\n     fact there are multiple topics that ended up using this. Both the\n     executor topic and worker topic\n\n     * `8de0c7e anoma/mariari/worker`\n       * `1d6bc99 anoma/mariari/executor`\n\n     both needed this. Since the worker relies upon the executor,\n     they both don't merge in this topic separately, but if they\n     were separate they would want to share this change.\n\n* If these changes were orchestrated by different people, then\n  they would have made this change twice! Meaning that in the git\n  history the work has been done in different commits! This means\n  that when it comes time to merge in work, there will be a\n  conflict between these two. Rather than being able to reuse\n  other's work and save other devs time, this will come up when\n  reviewers read the code, with unrelated changes, or when the\n  maintainers try to merge things together and find annoying\n  conflicts\n\n1. Work can not be incrementally included\n2. Others might just do the work before you\n\n* If one is too slow on finishing their topic and making it one big\n  commit, then someone else might redo the same work and put it up\n  for review, but instead of them reusing your code, they wrote it\n  from scratch, wasting both your time and their time.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#make-topics-early-and-often"},{"type":"extras","title":"Base topics on base - Git","doc":"Basing code on `main` has the following errors:\n\n1. Code merged in main before a release may turn out to have issues\n2. Git merges and conflict resolutions lead to spurious base points\n3. Other topics can not reuse your code\n4. Useless temporal history is had\n\nBasing on someone's topic that you require and will merge in anyways\nis fine.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#base-topics-on-base"},{"type":"extras","title":"Code merged in main before a release may turn out to have issues - Git","doc":"Imagine main has the following history\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout base\nmerge Topic-Y id: \"52b44a6\"\n```\n\nand your code hapens to be base on 52b44a6, then the history will look something like:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'my-cool-feature'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout my-cool-feature\nmerge Topic-Y id: \"52b44a6: main merge feature-y\"\ncommit id: \"7dabf44\"\n```\n\nLater before a release, we find out that *Topic-Y* has issues, and any\ncode that is based on *Topic-Y* will have to sit this release\nout. Normally to check for this, the protocol is quite simple we just:\n\n1. Do not include any topics that are based on *Topic-Y* or merges\n   *Topic-Y* into the release\n2. Pull any topic based on *Topic-Y* from `main`\n\nbecomes muddied, as if one's topic was based on `main` after *Topic-Y*\nis in, then it's unclear if that topic is unaffected.\n\nThus *my-cool-feature* may be cut from the release, even if it was\nperfectly fine and did not rely on *Topic-Y*.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#code-merged-in-main-before-a-release-may-turn-out-to-have-issues"},{"type":"extras","title":"Git merges and conflict resolutions lead to spurious base points - Git","doc":"Further, if we have two topics *my-feature-x* and *my-feature-y* based\non `main`, then the history would look something like this\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch main\nbranch ray/mnesia-attach\ncommit id: \"97bef7\"\ncheckout main\nmerge ray/mnesia-attach id: \"13b3e4a\"\n\n\ncheckout base\nbranch proper-topic\ncommit id: \"8087564: add a new feature\"\n\ncheckout main\nbranch topic-x\ncommit id: \"bc4b2a1: new cool feature\"\n\ncheckout main\nmerge proper-topic id: \"2dd991a\"\n\ncheckout main\nbranch topic-y\ncommit id: \"546a8f9: add feature: conflicts X!\"\n\ncheckout main\nmerge topic-x id: \"90d91e7\"\nmerge topic-y id: \"0438922\"\n```\n\nIn a textual form this looks like:\n\n```\n0438922 *   main Merge branch 'topic-y'\n        |\\\n546a8f9 | * topic-y Added a feature that conflcits with X!\n90d91e7 * |   Merge branch 'topic-x'\n        |\\ \\\n        | |/\n        |/|\nbc4b2a1 | * topic-x Added a cool feature\n2dd991a * |   Merge branch 'proper-topic'\n        |\\ \\\n        | |/\n        |/|\n8087564 | * proper-topic Add a new feature\n13b3e4a * |   Merge branch 'ray/mnesia-attach'\n        |\\ \\\n        | |/\n        |/|\n97b6ef7 | * ray/mnesia-attach mnesia:\n        |/\n73bfd7d * v0.3.0 base\n\n```\n\nWhen *topic-x* and *topic-y* have a conflict, the shared base of their base is\n\n```bash\n4 taichi@Gensokyo:~/Documents/Work/Repo/anoma-all git:main: % git merge-base topic-x topic-y\n13b3e4a215ea6222a1b1092ad242d3fa31e7040b\n```\n\nwhich is `13b3e4a * | Merge branch 'ray/mnesia-attach'` and not\n`73bfd7d * v0.3.0 anoma/base`, meaning that when a conflict is shown\nin the merge `0438922`, then the diff from a 3 way diff will show the\nmnesia changes, potentially making it unclear to others way the\npotentially issues may be.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#git-merges-and-conflict-resolutions-lead-to-spurious-base-points"},{"type":"extras","title":"Other topics can not reuse your code - Git","doc":"It is a bad idea to base code on `main`, as `main` contains random\nmerged topics before a release. This makes it so other topics who wish\nto use yours also has to merge all the random topics on `main`.\n\nThis is easy to see with the following example:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'simple-config'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n```\n\nHere we have a topic `major-changes` that makes all sorts of changes,\nand since we based our code off main, these are all included in\nsimple-config-change.\n\nHowever imagine we wish to overhaul the configuration a bit\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\ncommit id: \"f098de0: Basic config changes\"\n```\n\nNow if we wish to merge in `simple-config-change` we have\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\n\nbranch simple-config\ncheckout configuration-upgrade\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\n\ncheckout configuration-upgrade\ncommit id: \"f098de0: Basic config changes\"\n\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n\ncheckout configuration-upgrade\nmerge simple-config id: \"f6230df\"\n```\n\nBesides having a spurious main merged into our topic now, we are\nforced to deal with `major-changes` causing various conflicts with\nyour topic, making this merge untenable.\n\nMeaning that this code has to be recreated in `configuration-upgrade`\ninstead of reusing `simple-config-change`, fixing the problem in 2\nplaces, and having a conflict when it comes time for a release.\n\n<!-- livebook:{\"break_markdown\":true} -->","ref":"git.html#other-topics-can-not-reuse-your-code"},{"type":"extras","title":"Useless temporal history is had - Git","doc":"As we can see in the previous examples, when we base off of `main`, we\nend up in a scenario, where the date in which someone is branching is\nbaked into the code. As maintainers we don't care about when the code\nwas made, just the fact that it was. Thus this is a bit of history\nthat simply adds noise\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#useless-temporal-history-is-had"},{"type":"extras","title":"Merge other people's topics into yours - Git","doc":"If you need some work that is already merged into `next` or `main`,\nsimply merge that topic into yours! Since the bases are well situated,\nyou will only deal with reasonable conflicts that you should have\ncontext for.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#merge-other-people-s-topics-into-yours"},{"type":"extras","title":"Base bug fixes on the commit that introduced the bug - Git","doc":"Basing a bug fix on when the bug is introduced is superior than basing\nit on the latest release, as this means that it can be merged into any\n`maint` branches we may have.\n\nFor example:\n\n```\n73bfd7d * v0.3.0 Anoma 0.3.0\n...\n10f8636 * v0.2.0 Anoma 0.2.0\n...\n34fcd78 * v0.1.0 Release v0.1.0\n```\n\nif a bug was found in a topic between `v0.1.0` and `v0.2.0`, and we\nbased it on when the bug was found we can merge it on `v0.2.0` and\nhave `v0.2.1` release from there. And have a `v0.3.1` release as well.\n\n```\n2373834 *   v0.2.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n10f8636 * | v0.2.0 Anoma 0.2.0\n```\n\n```\n19c6f03 *   v0.3.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n73bfd7d * | v0.3.0 Anoma 0.3.0\n```\n\nnotice how we can merge this in with no conflicts!","ref":"git.html#base-bug-fixes-on-the-commit-that-introduced-the-bug"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-1.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"hoon-1.html#index"},{"type":"extras","title":"Hoon - Hoon","doc":"Currently the quickest way to write resource logics is to have Hoon\nsetup and working. Checkout the [Hoon section for more information](../hoon.livemd)","ref":"hoon-1.html#hoon"},{"type":"extras","title":"IEx","doc":"# IEx","ref":"iex.html"},{"type":"extras","title":"Index - IEx","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"iex.html#index"},{"type":"extras","title":"Running multiple IEX's in the same Image/Environments - IEx","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\nMIX_ENV=test iex --sname b@localhost --cookie anoma -S mix\n# open a new terminal\nMIX_ENV=test iex --remsh b@localhost --sname c@localhost --cookie anoma -S mix\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis also allows you to connect from [livebook](https://livebook.dev)\nby using the above cookie `anoma` under the `runtime` config of\nlivebook.","ref":"iex.html#running-multiple-iex-s-in-the-same-image-environments"},{"type":"extras","title":"Mnesia Vs Actor State","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Mnesia Vs Actor State","ref":"mnesia-vs-actor-state.html"},{"type":"extras","title":"Index - Mnesia Vs Actor State","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"mnesia-vs-actor-state.html#index"},{"type":"extras","title":"Where should state be stored - Mnesia Vs Actor State","doc":"One interesting thing about our system is that in the [user data](./../user/data.livemd) section of our documentation we talk about how Anoma's state is stored in [RocksDB](https://en.wikipedia.org/wiki/RocksDB) tables on disc. And that we have some kind of `dump` format that goes along with the tables.\n\nThe `dump` format stores 2 kinds of information:\n\n1. Actor State\n2. [Mnesia](https://en.wikipedia.org/wiki/Mnesia) State\n\nAs discussed in the [user data documentation](./../user/data.livemd), loading a `dump` file overwrites the DB. However what we did not cover is what the differences are between [Mnesia](https://en.wikipedia.org/wiki/Mnesia) storage and Actor storage.","ref":"mnesia-vs-actor-state.html#where-should-state-be-stored"},{"type":"extras","title":"Mnesia Storage - Mnesia Vs Actor State","doc":"The philosophy for what is stored in Mnesia should be: \"Is this something the user should be able to query and write code over\". Since Anoma is a distributed operating system project, many of the answers should be yes. The user should be able to make full fledged progrmas on Anoma and extend the system.","ref":"mnesia-vs-actor-state.html#mnesia-storage"},{"type":"extras","title":"Actor Storage - Mnesia Vs Actor State","doc":"Actor storage on the other hand are for things we don't wish the user to be able to query. Thus implementaiton details about the execution should be omitted from user visible storage, and would be better served stored on the Actor.\n\nA good example of this is the old ordering logic.\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  typedstruct do\n    field(:table, Router.Addr.t())\n    field(:next_order, non_neg_integer(), default: 1)\n    field(:hash_to_order, %{key() => non_neg_integer()}, default: %{})\n    field(:logger, Router.Addr.t(), enforce: false)\n  end\n```\n\nIn this example, we store things like specific order information, the live router addresses for storage and for the logger. None of this is relevant to the users and are just coincidental with how we wrote the system.","ref":"mnesia-vs-actor-state.html#actor-storage"},{"type":"extras","title":"Observer","doc":"<!-- livebook:{\"file_entries\":[{\"name\":\"2024-01-08-172805_1016x497_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-173044_1845x1082_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174448_1283x720_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174522_1420x684_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174628_443x186_scrot.png\",\"type\":\"attachment\"},{\"name\":\"Application_view.jpg\",\"type\":\"attachment\"}],\"persist_outputs\":true} -->\n\n# Observer","ref":"observer.html"},{"type":"extras","title":"Index - Observer","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"observer.html#index"},{"type":"extras","title":"How To use Observer - Observer","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:","ref":"observer.html#how-to-use-observer"},{"type":"extras","title":"Viewing Anoma - Observer","doc":"One can view Anoma by going to the Applications view of the Observer pane and clicking on anoma\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/Application_view.jpg)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis view is quite nice because if we spawn a process, we can see it attach\n\n```elixir\nalias Anoma.Storage\nalias Anoma.Node.Storage.Communicator, as: Scom\nalias Anoma.Node.Executor.Communicator, as: Ccom\nalias Anoma.Node.Mempool.Communicator, as: Mcom\nimport TestHelper.Nock\n\nstorage = %Anoma.Storage{\n  qualified: Anoma.Qualified,\n  order: Anoma.Order\n}\n\nname = :anoma\nsnapshot_path = [:my_special_nock_snaphsot | 0]\nnode = Anoma.Node.com_names(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mcom.tx(node.mempool, zero).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.4479.0>\n```\n\nThen we can see this same process as a child to one of the pools\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-172805_1016x497_scrot.png)","ref":"observer.html#viewing-anoma"},{"type":"extras","title":"Looking at Mnesia Tables - Observer","doc":"One can go to the Table view, and click view to turn it from `ets` tables to `mnesia` tables.\n\nNow you should be able to see this:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174522_1420x684_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nIf we click on a table like the one highlighted we can see the values in the table\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174448_1283x720_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nClick on the data inside of here gives us an inspector pane of the data\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174628_443x186_scrot.png)","ref":"observer.html#looking-at-mnesia-tables"},{"type":"extras","title":"Style Guide","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Style Guide","ref":"style-guide.html"},{"type":"extras","title":"Index - Style Guide","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"style-guide.html#index"},{"type":"extras","title":"Structural Rules - Style Guide","doc":"A module is **documented** if\n\n* It has nonempty module documentation.\n* All of its public functions capable of having documentation have nonempty documentation.\n* All of its public functions capable of having types assigned have assigned types.\n* All types have type documentation.\n\n#### Rule 1.1\n\nAny module which is specified under the Node directory ought to be **documented**.\n\n#### Rule 1.2\n\nAny public function which is used in a public function by a module specified under the Node directory ought to have nonempty documentation.\n\n#### Rule 1.3\n\nDocumentation should be given in first person.\n\n#### Rule 1.4\n\nIf `foo` uses `bar` in the same module in the Node dir then `foo` is placed higher than `bar` in the module.\n\nExceptions might exist but should be noted explicitly in PR and commit messages.\n\n#### Rule 1.5 (CQRS)\n\nIf `foo` uses Router or GenServer functionality, it should be a `call` if and only if either\n\n1. The underlying state is unchanged by calling `foo`\n2. There are synchronizaton requirements that `foo` has to fullfill.\n\n#### Rule 1.6\n\nIf `foo` uses `call` functionality then the corresponding `handle_call` shall have body\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n{:reply, do_foo(...), state}\n```\n\nwith `do_foo` implementing core logic.\n\nIf `foo` has synchronization requirements, the return of `do_foo` should only contain information regarding the\nsuccess or failure of the operation.\n\n#### Rule 1.7\n\nEvery actor module should have mandatory `Public RPC API`, `GenServer Behavior`, and `GenServer Implementation` sections with following formatting:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                      Public RPC API                      #\n  ############################################################\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                    Genserver Behavior                    #\n  ############################################################\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  ############################################################\n  #                  Genserver Implementation                #\n  ############################################################\n```\n\nwhere\n\n* `Public RPC API` contains public functions using `call` or `cast` functionality\n* `GenServer Behavior` contains all `handle_call` and `handle_cast` functions\n* `GenServer Implementation` contains all functions explicitly used in the `GenServer Behavior` sections.\n\nExtra functions can be contained in the latter section or can further be separated into `Helper` functions.","ref":"style-guide.html#structural-rules"},{"type":"extras","title":"Module Documentation - Style Guide","doc":"#### Rule 2.1\n\nModule documentation starts with stating its core purpose in one sentence followed by a new line. If it is related to an Engine X mentioned in the specs, specify that it is an implementation.\n\n* `I am the Storage Engine implementing the Local Key Value Storage Engine.`\n* `I am the Dumper Engine.` (in case the names match)\n* `I am the Blah module which implements foo functionality.`\n\n#### Rule 2.2\n\nModule documentation ought to have an API section separated by a `","ref":"style-guide.html#module-documentation"},{"type":"extras","title":"Public API` line followed by a line: `I have the following public functionality:` followed by a list of functions or subsections of lists of functions. All public module functions should appear in this section. - Style Guide","doc":"A subsection named `Section Name` should be formatted as `#### Section Name` followed by a short description of the section and a list of functions.\n\nThe format for the list is: if a module has public function `foo` of `n` entries we list it as ``` - `foo/n` ```.  Every line - except those in the function list - should be separated by a newline. Functions should be grouped by argument number with fewer argument numbers on top.\n\nIf subsections were used yet not all functions feature in their lists, the rest of the functions should appear in the `#### Other` subsection placed at the end.\n\n* ```","ref":"style-guide.html#public-api-line-followed-by-a-line-i-have-the-following-public-functionality-followed-by-a-list-of-functions-or-subsections-of-lists-of-functions-all-public-module-functions-should-appear-in-this-section"},{"type":"extras","title":"Public API - Style Guide","doc":"I have the following public functionality:\n\n  #### Transaction Functions\n\n  - `new_transaction/3`\n  - `fire_new_transaction/3`\n  - `new_transaction/4`\n  - `fire_new_transaction/4`\n\n  #### Other\n\n  - `snapshot/1`\n  - `subscribe/2`\n  ```","ref":"style-guide.html#public-api"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  defmodule Anoma.Node.Clock do\n    @moduledoc \"\"\"\n    I am the Clock module implementing the Local Wall Clock Engine.\n\n    I provide info on the time elapsed in milliseconds after the node launched\n    and the epoch from which it has been calculated using monotonic time.\n\n    The current implementation launches the epoch by asking for the system\n    monotonic time at the point of an Anoma node launch. This is recommended\n    as all my public API uses system monotonic time to give measurements.","ref":"style-guide.html#example"},{"type":"extras","title":"Public API - Style Guide","doc":"I have the following public functionality:\n\n    - `get_time/1`\n    - `get_epoch/1`\n    \"\"\"\n```","ref":"style-guide.html#public-api"},{"type":"extras","title":"Type Documentation - Style Guide","doc":"#### Rule 3.1\n\nThe type documentation should start with stating the purpose of the type in one sentence.\n\n* ``` I control options for `launch_min/2` ```\n* `I am the type of the Executor Engine`\n\n#### Rule 3.2\n\nEvery product type documentation should have a `","ref":"style-guide.html#type-documentation"},{"type":"extras","title":"Fields` section followed by a list of field atoms with their descriptions. - Style Guide","doc":"The list should be formatted as follows:\n\nGiven a field `:field` we list it as ``` - `:field` - ``` followed by a short description. This is followed by a sentence `Enforced: bool` where `bool` is either `true` or `false`. If it has a default value, should be also followed by `Default: value`.\n\n* ```","ref":"style-guide.html#fields-section-followed-by-a-list-of-field-atoms-with-their-descriptions"},{"type":"extras","title":"Fields - Style Guide","doc":"- `:intents_topic` - The address of the intents topic to which the engine broadcasts.\n  - `:intents` - The set of intents to be solved. Default: `MapSet.new/0`\n  - `:logger` - The address of the Logger Engine used for logging. Enforced: false.\n  ```\n\n#### Rule 3.3\n\nEvery sum type documentation should have an `","ref":"style-guide.html#fields"},{"type":"extras","title":"Options` section followed by a list of field atoms with their descriptions. - Style Guide","doc":"The list should be formatted as follows:\n\nGiven an option `:option` we list it as ``` - `:option` - ``` followed by a short description.\n\n* ```","ref":"style-guide.html#options-section-followed-by-a-list-of-field-atoms-with-their-descriptions"},{"type":"extras","title":"Options - Style Guide","doc":"- `:use_rocksdb` - See `t:Anoma.Node.configuration/0` for more\n  information.\n  - `:supervisor` - This flag determine if we use a supervisor and if\n  so what options. See `t:Supervisor.option/0 ` for supervisor options.\n  - `:testing` - This flag notes if we are testing the node. This gets\n    fed directly into the type `t:Anoma.Node.configuration/0` for\n    `Anoma.Node.start_link/1`. Please consult the\n    `t:Anoma.Node.configuration/0` documentation for the full effect\n    this has on the node.\n  ```","ref":"style-guide.html#options"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  typedstruct do\n    @typedoc \"\"\"\n    I am the type of the Pinger Engine.\n\n    I store minimal info required to ask the mempool to execute, namely the\n    mempool address and the time specified by the user.\n\n    - `:mempool` - The Mempool Engine address which is called to execute.\n    - `:time` - The time that should be elapsed between the calls to\n                execute or an atom saying that no timer should be set.\n                Default: `:no_timer`\n    \"\"\"\n\n    field(:mempool, Router.Addr.t())\n    field(:time, non_neg_integer() | atom(), default: :no_timer)\n  end\n\n  @typedoc \"\"\"\n  I control options for `launch_min/2`.","ref":"style-guide.html#example"},{"type":"extras","title":"Options - Style Guide","doc":"- `:use_rocksdb` - See `t:Anoma.Node.configuration/0` for more\n  information.\n  - `:supervisor` - This flag determine if we use a supervisor and if\n  so what options. See `t:Supervisor.option/0 ` for supervisor options.\n  - `:testing` - This flag notes if we are testing the node. This gets\n    fed directly into the type `t:Anoma.Node.configuration/0` for\n    `Anoma.Node.start_link/1`. Please consult the\n    `t:Anoma.Node.configuration/0` documentation for the full effect\n    this has on the node.\n  \"\"\"\n  @type launch_option ::\n          {:use_rocksdb, boolean()}\n          | {:supervisor, [Supervisor.option()]}\n          | {:testing, boolean()}\n```","ref":"style-guide.html#options"},{"type":"extras","title":"Function Documentation - Style Guide","doc":"#### Rule 4.1\n\nThe function documentation should begin with stating its purpose in one sentence. If the function is an implementation of a specs-related function, it should mention this by name.\n\n* `I am delete_key function, implementing DeleteValueKVStorage functionality.`\n* `Given a server S and time T, I change the timer set for the struct\n  connected to S setting it to T.`\n\n#### Rule 4.2\n\nIf a documented function has functions of same arity in the same module which pattern match arguments differently, they should be listed in a `","ref":"style-guide.html#function-documentation"},{"type":"extras","title":"Pattern-Match Variations` section in the following format: - Style Guide","doc":"If function `foo` has a variation `foo(x1, ... , xn)` where `x1,...,xn` are some Elixir object capable of being pattern-matched to, we present it in a list as `- foo(x1, ... ,xn) -` followed by a short description.\n\nIf the arguments are not pattern-matched, provide the variable names as in the definition.\n\n* ```","ref":"style-guide.html#pattern-match-variations-section-in-the-following-format"},{"type":"extras","title":"Pattern-Matching Variations - Style Guide","doc":"- `init(%Clock{})` - I initialize the Engine with the given state.\n\n  - `init(args)` - I expect a keylist and check for the :start key then\n                   launch the Clock with said setting.\n  ```\n\n#### Rule 4.3\n\nAny function application which a non-constant output and an appropriate EModule example, it should have a reference to the appropriate example function in the codebase.","ref":"style-guide.html#pattern-matching-variations"},{"type":"extras","title":"Example - Style Guide","doc":"<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  @doc \"\"\"\n  I am the initialization function of the Clock Engine.","ref":"style-guide.html#example"},{"type":"extras","title":"Pattern-Matching Variations - Style Guide","doc":"- `init(%Clock{})` - I initialize the Engine with the given state.\n\n  - `init(args)` - I expect a keylist and check for the :start key then\n                   launch the Clock with said setting.\n  \"\"\"\n  def init(%Clock{} = state) do\n    {:ok, state}\n  end\n\n  @spec init(list({:start, integer()})) :: {:ok, Clock.t()}\n  def init(args) do\n    {:ok, %Clock{start: args[:start]}}\n  end\n```","ref":"style-guide.html#pattern-matching-variations"},{"type":"extras","title":"Testing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Testing","ref":"testing.html"},{"type":"extras","title":"Index - Testing","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"testing.html#index"},{"type":"extras","title":"Testing - Testing","doc":"Testing is important for the Anoma Project.\n\nThese series of documents cover how best to traverse tests throughout the project.","ref":"testing.html#testing"},{"type":"extras","title":"Running Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Running Tests","ref":"running-tests.html"},{"type":"extras","title":"Index - Running Tests","doc":"1. [Toc](./../../toc.livemd)\n2. [User](./../../user.livemd)\n   1. [Data](./../../user/data.livemd)\n3. [Contributing](./../../contributing.livemd)\n   1. [Understanding Any Module](./../../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../../contributing/style-guide.livemd)\n   3. [Writing Documents](./../../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../../contributing/examples-over-testing.livemd)\n   5. [Git](./../../contributing/git.livemd)\n   6. [Hoon](./../../contributing/hoon.livemd)\n   7. [Iex](./../../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../../contributing/observer.livemd)\n   10. [Testing](./../../contributing/testing.livemd)\n       1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n5. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n6. [Analysis](./../../analysis.livemd)\n   1. [Fema Analysis Pinger](./../../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../../logging.livemd)\n8. [Vm_interface](./../../vm_interface.livemd)","ref":"running-tests.html#index"},{"type":"extras","title":"Intent - Running Tests","doc":"This document is aimed at allowing any developer to run tests in a more ergonomic way than simply running:\n\n```shell\n% mix test\n```\n\nNamely, this document covers running tests inside `IEX` and being able to do so on demand.","ref":"running-tests.html#intent"},{"type":"extras","title":"Setting up IEX - Running Tests","doc":"To Run tests within IEx. One simply calls `Mix.Tasks.Test.run/1` within their IEX session.\n\nHowever attempting to do this by default will result in the following error:\n\n```shell\n iex --sname mariari --cookie mariari -S mix\n```\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n````\n** (Mix.Error) \"mix test\" is running in the \"dev\" environment. If you are running tests from within another command, you can either:\n\n  1. set MIX_ENV explicitly:\n\n      MIX_ENV=test mix test.another\n\n  2. set the :preferred_envs for \"def cli\" in your mix.exs:\n\n      def cli do\n        [preferred_envs: [\"test.another\": :test]]\n      end\n\n    (mix 1.15.5) lib/mix.ex:577: Mix.raise/2\n    (mix 1.15.5) lib/mix/tasks/test.ex:486: Mix.Tasks.Test.do_run/3\n    #cell:nsl6gqly4w45ei6b:1: (file)\n    ```\n````\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThe error text hints at a suggestion on how to solve the problem.\n\n```shell\nMIX_ENV=iex iex --sname mariari --cookie mariari -S mix\n```\n\nI recommend using the `iex` environment over the `test` environment that is shwon in the error, as in the `Anoma` project, we set the `test` environment to have `Config.config/2` to have the following settings:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\nconfig :logger,\n  level: :error\n```\n\nWhich means that some logging details you may care about may not be reported to you by default.\n\nNow that we have the environment setup if we try running this again we get:\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\nFinished in 0.00 seconds (0.00s async, 0.00s sync)\n0 failures\n\nRandomized with seed 670138\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nRunning the command has a few effects:\n\n1. It behaves the same as `mix test` running every single test in the project.\n2. It loads in the test modules, meaning we now have access to all modules in `AnomaTest`.\n3. `ExUnit` is now started up, meaning we can run tests with `ExUnit.run/0` now.\n\nFor larger projects `1.` may be prohibitive as tests may take quite a while to run!","ref":"running-tests.html#setting-up-iex"},{"type":"extras","title":"Running Individual Modules For the First Time - Running Tests","doc":"To run an individual module, one simply needs to invoke the `ExUnit` framework themselves.\n\nA good example of this at play is the following example:\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\niex(mariari@YU-NO)1> ExUnit.start\n:ok\niex(mariari@YU-NO)2> c \"test/node/mempool_test.exs\"\n[AnomaTest.Node.Mempool]\niex(mariari@YU-NO)3> ExUnit.run\n\n14:46:45.846 [error] Worker failed! :error\n\n14:46:45.849 [error] Worker failed! :error\n.....\nFinished in 0.3 seconds (0.3s async, 0.00s sync)\n5 tests, 0 failures\n\nRandomized with seed 670138\n%{total: 5, failures: 0, excluded: 0, skipped: 0}\n```\n\nWe can see here that I've started up ExUnit with `ExUnit.start/0`, then I've manually compiled the module I wanted to run `c ...` and then I ran `ExUnit.run/0`.\n\nThe side effect of running tests this way is that only `AnomaTest.Node.Mempool` is in scope. The other tests are not.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThe behavior of `ExUnit.run/0` is quite configurable, see `ExUnit.configure/1` for a lot of options on filtering what tests are run.","ref":"running-tests.html#running-individual-modules-for-the-first-time"},{"type":"extras","title":"ReRunning Tests - Running Tests","doc":"One may be surprised at the first time they try to rerun tests, as they will run into the following anomaly:\n\n```elixir\nMix.Tasks.Test.run([])\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\nFinished in 0.00 seconds (0.00s async, 0.00s sync)\n0 failures\n\nRandomized with seed 670138\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nNo tests were run again! This can be rather annoying as we often make changes to code and wish to see if they break certain tests!\n\nA way around this is by recompiling the given module then running again\n\n```iex\niex 7> r AnomaTest.Node.Mempool\nwarning: redefining module AnomaTest.Node.Mempool (current version defined in memory)\n  test/node/mempool_test.exs:1: AnomaTest.Node.Mempool (module)\n\n{:reloaded, [AnomaTest.Node.Mempool]}\niex(mariari@YU-NO)8> Mix.Tasks.Test.run([])\n\n14:58:09.255 [error] Worker failed! :error\n\n14:58:09.256 [error] Worker failed! :error\n.....\nFinished in 0.3 seconds (0.3s async, 0.00s sync)\n5 tests, 0 failures\n```","ref":"running-tests.html#rerunning-tests"},{"type":"extras","title":"Running individual tests - Running Tests","doc":"In the Writing tests document we layout a guideline that shows how to write tests that can easily be ran in the repl over and over.\n\nThanks to this design, running individual tests is quite simple!\n\nAll one has to do is follow these simple instructions:\n\n1. copy the Imports from the test file one sees\n2. copy all code within the `setup_all`\n3. (optional) import `ExUnit.Assertions`\n4. run the tets by hand.\n\n```elixir\ndefmodule AnomaTest.LiveBook.Example do\n  use ExUnit.Case, async: true\n\n  import TestHelper.Nock\n\n  setup_all do\n    name = :hi\n\n    [name: name]\n  end\n\n  test \"first\", %{} do\n    assert 2 == 2\n  end\n\n  test \"logic\", %{name: name} do\n    fi = :erlang.atom_to_binary(name)\n    assert fi == fi\n  end\n\n  describe \"group\" do\n    test \"second\", %{name: name} do\n      assert name == name\n    end\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nwarning: unused import TestHelper.Nock\n  documentation/contributing/testing/running-tests.livemd#cell:nzkdwbfnnuijteho:4\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Example, <<70, 79, 82, 49, 0, 0, 16, ...>>, {:\"test group second\", 1}}\n```\n\nIf we take `AnomaTest.LiveBook.Example` as our exmaple, then we can run the individual tests like the following.\n\n```elixir\n# Copy the imports\nimport TestHelper.Nock\n\n# Copy the setup_all\n\nname = :hi\n\n[name: name]\n\n# Now run the test\n\nAnomaTest.LiveBook.Example.\"test first\"(%{name: name})\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nTest names are odd in that they are not simple atoms, they are typically the word `test` then the string name given to the test. Hence `test \"first\"` became `AnomaTest.LiveBook.Example.\"test first\"/1`.\n\nTo run the group, we need to prepend the group name as well.\n\n```elixir\nAnomaTest.LiveBook.Example.\"test group second\"(%{name: name})\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nWhat is very nice about this setup is that we can run the tests piecewise by copy and pasting the logic to the point that we care about. For example let us run the `AnomaTest.LiveBook.Example.\"test logic\"/1` test by hand.\n\n```elixir\nfi = :erlang.atom_to_binary(name)\n\nassert fi == fi\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nerror: undefined function assert/1 (there is no such import)\n  documentation/contributing/testing/running-tests.livemd#cell:6wdtc4fkrz3iatat:3\n\n```\n\nThe assert code fails as we forgot to import `ExUnit.Assertions`. If we import this file then the entire copy and paste will run!\n\n```elixir\nimport ExUnit.Assertions\nfi = :erlang.atom_to_binary(name)\n\nassert fi == fi\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\ntrue\n```\n\nThis is very useful in debugging, as we may have a test that is composed of `n` steps, and we may wish to run it partially up until some known state, then modify the code live.\n\nThis means that instead of having to rerun tests from scractch over and over again like in Rust or CPP, you can effectively have all the state of the test live in your repl, and change specific code you wish to test, and simply run the command that fails and see how your code changes affect any particular given state.","ref":"running-tests.html#running-individual-tests"},{"type":"extras","title":"Conclusion - Running Tests","doc":"Running tests in Elixir is nice and somewhat simple!\n\nWe have covered how to:\n\n1. Run tests within `IEX`\n2. re-running tests in `IEX`\n3. running individual tests fully\n4. Running individual tests partially","ref":"running-tests.html#conclusion"},{"type":"extras","title":"Writing Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Writing Tests","ref":"writing-tests.html"},{"type":"extras","title":"Index - Writing Tests","doc":"1. [Toc](./../../toc.livemd)\n2. [User](./../../user.livemd)\n   1. [Data](./../../user/data.livemd)\n3. [Contributing](./../../contributing.livemd)\n   1. [Understanding Any Module](./../../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../../contributing/style-guide.livemd)\n   3. [Writing Documents](./../../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../../contributing/examples-over-testing.livemd)\n   5. [Git](./../../contributing/git.livemd)\n   6. [Hoon](./../../contributing/hoon.livemd)\n   7. [Iex](./../../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../../contributing/observer.livemd)\n   10. [Testing](./../../contributing/testing.livemd)\n       1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n5. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n6. [Analysis](./../../analysis.livemd)\n   1. [Fema Analysis Pinger](./../../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../../logging.livemd)\n8. [Vm_interface](./../../vm_interface.livemd)","ref":"writing-tests.html#index"},{"type":"extras","title":"Conventions - Writing Tests","doc":"Since the [figuring out](./../../contributing/understanding-any-module.livemd) page demonstrates that well laid out test files are the key to understanding how modules work, it is important to write tests so this can always be achieved.\n\nThe following sections will lay out how we can achieve this.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#conventions"},{"type":"extras","title":"Make sure names from the test matches setup_all - Writing Tests","doc":"```elixir\nExUnit.start()\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Nam do\n  use ExUnit.Case\n\n  setup_all do\n    special = 3\n    [special: special]\n  end\n\n  test \"this is acceptable\", %{special: special} do\n    assert special == 3\n  end\n\n  test \"this test is not acceptable\", %{special: spec} do\n    assert spec == 3\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Nam, <<70, 79, 82, 49, 0, 0, 14, ...>>,\n {:\"test this test is not acceptable\", 1}}\n```\n\nIf this convention is not followed, then the user can not simply be\ncopy and paste the lines to figure out how to use the module.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#make-sure-names-from-the-test-matches-setup_all"},{"type":"extras","title":"Write setup_all to not crash on reevaluation - Writing Tests","doc":"```elixir\ndefmodule AnomaTest.LiveBook.NoCrash do\n  use ExUnit.Case\n\n  setup_all do\n    name = :intent_example\n\n    unless Process.whereis(name) do\n      Anoma.Node.Intent.init(name)\n    end\n\n    [intent_pool: name]\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nwarning: Anoma.Node.Intent.init/1 is undefined (module Anoma.Node.Intent is not available or is yet to be defined)\n  documentation/contributing/testing.livemd#cell:qbrtwwd53rvqgtpz:8: AnomaTest.LiveBook.NoCrash.__ex_unit_setup_all_0/1\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.NoCrash, <<70, 79, 82, 49, 0, 0, 11, ...>>,\n {:__ex_unit_setup_all_0, 1}}\n```\n\n* Here we check if the process is running. This way if it is\n  already in IEX we simply don't disturb it but rename it to point\n  to the correct one we wish to operate over.\n* If we did not do this check the other commands may fail and IEX\n  may not be trapped to continue.\n* `mix test` will not catch this\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#write-setup_all-to-not-crash-on-reevaluation"},{"type":"extras","title":"Try to make tests idempotent - Writing Tests","doc":"Let us demonstrate this point, by making a simple queue service.\n\n```elixir\ndefmodule Queue do\n  use GenServer\n\n  def init(_init) do\n    {:ok, :queue.new()}\n  end\n\n  def start_link(arg) do\n    GenServer.start_link(__MODULE__, arg, name: arg)\n  end\n\n  def reset(queue) do\n    GenServer.cast(queue, :reset)\n  end\n\n  def enqueue(queue, name) do\n    GenServer.cast(queue, {:enqueue, name})\n  end\n\n  def pop(queue) do\n    GenServer.call(queue, :pop)\n  end\n\n  def handle_cast(:reset, _pool) do\n    {:noreply, :queue.new()}\n  end\n\n  def handle_cast({:enqueue, val}, pool) do\n    {:noreply, :queue.cons(val, pool)}\n  end\n\n  def handle_call(:pop, _from, queue) do\n    {:reply, :queue.get_r(queue), :queue.drop_r(queue)}\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, Queue, <<70, 79, 82, 49, 0, 0, 18, ...>>, {:handle_call, 3}}\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Idempotent do\n  use ExUnit.Case\n\n  setup_all do\n    name = :queue_name\n\n    unless Process.whereis(name) do\n      Queue.start_link(name)\n    end\n\n    [queue: name]\n  end\n\n  test \"reset\", %{queue: name} do\n    # Make sure we get reliable results!\n    Queue.reset(name)\n    Queue.enqueue(name, 5)\n    Queue.enqueue(name, 4)\n    assert 5 == Queue.pop(name)\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Idempotent, <<70, 79, 82, 49, 0, 0, 15, ...>>, {:\"test reset\", 1}}\n```\n\nHere before getting values from the queue, we make sure it's fresh by resetting it.\n\nIn the `Queue` case it's contrived, however a lot of genservers in the codebase work like this!\n\nSomething important to note is that `mix test` will not catch this!\n\nSo please try to keep tests isolated from each other.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#try-to-make-tests-idempotent"},{"type":"extras","title":"Try to Name Values - Writing Tests","doc":"For debugging purposes, it is best to name values, and so you can rerun values on command, or help the debugging process.","ref":"writing-tests.html#try-to-name-values"},{"type":"extras","title":"Understanding any code in Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Understanding any code in Anoma","ref":"understanding-any-module.html"},{"type":"extras","title":"Index - Understanding any code in Anoma","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"understanding-any-module.html#index"},{"type":"extras","title":"Figuring out what a module does - Understanding any code in Anoma","doc":" good start is by calling `h` on the module from within one's IEX\ninstance.\n\n```elixir\nrequire IEx.Helpers\nimport IEx.Helpers\n# the above two lines are not requried for the REPL!\nh(Anoma.Node)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\n                                   Anoma.Node\n\nI act as a registry for Anoma Nodes","ref":"understanding-any-module.html#figuring-out-what-a-module-does"},{"type":"extras","title":"Required Arguments - Understanding any code in Anoma","doc":" name - name for this process\n   snapshot_path : [atom() | 0]\n     A snapshot location for the service (used in the worker)\n\n   storage : Anoma.Storage.t() - The Storage tables to use\n   block_storage - a location to store the blocks produced","ref":"understanding-any-module.html#required-arguments"},{"type":"extras","title":"Optional Arguments - Understanding any code in Anoma","doc":" jet : Nock.jettedness() - how jetted the system should be\n   old_storage : boolean - states if the storage should be freshly made\n     by default it is false","ref":"understanding-any-module.html#optional-arguments"},{"type":"extras","title":"Registered names - Understanding any code in Anoma","doc":"","ref":"understanding-any-module.html#registered-names"},{"type":"extras","title":"Created Tables - Understanding any code in Anoma","doc":" storage.qualified\n   storage.order\n   block_storage\n```\n\nHowever, this typically doesn't show off how one uses said\nmodule. Thankfully, the codebase is setup in such a way that one can\nalways interactively play with any given module.\n\nThis is done by simply checking out the tests folder, and finding the\nmodule you wish to learn to learn about.\n\nFor example, let us learn about the mempool. In the codebase currently\nthis can be found here:\n\n* `test/node/mempool_test.exs`,\n\nnote that even if this gets out of date, you should be able to do this with any file!\n\nThe first thing one can do to run things interactively is by taking\nall the imports of the file and running it locally\n\nIn this case I input the following from the file into IEX.\n\nI also make sure to include an extra `import ExUnit.Assertions` so\nthat assertions can be copied and pasted to IEX\n\n```elixir\n# output redacted for length\nalias Anoma.Storage\nalias Anoma.Node.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\n\nimport TestHelper.Nock\n\nimport ExUnit.Assertions\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nExUnit.Assertions\n```\n\nAfter the imports are done, then we copy the `setup_all` if this section\nexists\n\n```elixir\n# setup_all do\nstorage = %Anoma.Storage{\n  qualified: AnomaTest.Mempool.Qualified,\n  order: AnomaTest.Mempool.Order\n}\n\nname = :mempool\nsnapshot_path = [:my_special_nock_snaphsot | 0]\n\nnode = Anoma.Node.state(name)\n\nunless Process.whereis(:mempool_mempool_com) do\n  Anoma.Node.start_link(\n    name: name,\n    snapshot_path: snapshot_path,\n    storage: storage,\n    block_storage: :mempool_blocks\n  )\nend\n\nnode\n# end\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node{\n  logger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Logger 0UFKnKepVKxm8B1uH/QkoKh0hLuVQ8TrRGf+4dFY+Zw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<49, 47, 91, 248, 87, 123, 100, 79, 0, 37, 176, 239, 240, 27, 218, 11, 63, 251, 170,\n        244, 75, 20, 116, 142, 149, 64, 1, 81, 42, 139, 210, 44>>,\n      sign: <<209, 65, 74, 156, 167, 169, 84, 172, 102, 240, 29, 110, 31, 244, 36, 160, 168, 116,\n        132, 187, 149, 67, 196, 235, 68, 103, 254, 225, 209, 88, 249, 156>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  clock: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Clock qoWUQLrfe8KstPBZsIN9e6Escpvdu5LbUUCS1SoGVYw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<141, 195, 214, 28, 18, 243, 25, 172, 222, 0, 152, 202, 137, 215, 147, 57, 71, 196,\n        13, 93, 148, 71, 58, 222, 4, 173, 137, 126, 228, 55, 181, 48>>,\n      sign: <<170, 133, 148, 64, 186, 223, 123, 194, 172, 180, 240, 89, 176, 131, 125, 123, 161, 44,\n        114, 155, 221, 187, 146, 219, 81, 64, 146, 213, 42, 6, 85, 140>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  pinger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Pinger QeQQ09SN+5MeUCoc5hrKec7jJhKcrtSt+g879DFP0aY=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<98, 214, 175, 27, 239, 163, 208, 126, 208, 197, 212, 140, 32, 152, 249, 1, 180,\n        245, 181, 143, 171, 251, 99, 160, 21, 174, 16, 128, 35, 100, 227, 75>>,\n      sign: <<65, 228, 16, 211, 212, 141, 251, 147, 30, 80, 42, 28, 230, 26, 202, 121, 206, 227, 38,\n        18, 156, 174, 212, 173, 250, 15, 59, 244, 49, 79, 209, 166>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  mempool_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<111, 103, 214, 144, 51, 40, 198, 132, 2, 11, 19, 47, 228, 153, 121, 250, 201, 147,\n        248, 105, 164, 121, 218, 177, 11, 155, 204, 208, 20, 202, 55, 12>>,\n      sign: <<248, 79, 247, 60, 208, 85, 198, 79, 222, 145, 122, 214, 201, 141, 145, 255, 218, 208,\n        168, 250, 173, 25, 37, 111, 214, 134, 93, 99, 36, 0, 154, 28>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  mempool: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Mempool KNPB2ijsWnfve4L8Iuq434po8eFCJNK+EvKQ4Vd2Tqw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<167, 148, 18, 166, 207, 244, 170, 202, 95, 3, 187, 9, 217, 157, 97, 177, 208, 76,\n        163, 136, 148, 60, 160, 248, 68, 61, 142, 67, 47, 229, 82, 30>>,\n      sign: <<40, 211, 193, 218, 40, 236, 90, 119, 239, 123, 130, 252, 34, 234, 184, 223, 138, 104,\n        241, 225, 66, 36, 210, 190, 18, 242, 144, 225, 87, 118, 78, 172>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  executor_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<250, 161, 209, 10, 200, 171, 194, 37, 114, 235, 167, 193, 45, 245, 92, 157, 121,\n        106, 195, 86, 139, 58, 214, 217, 105, 181, 51, 76, 178, 55, 240, 37>>,\n      sign: <<188, 255, 80, 242, 172, 114, 141, 55, 239, 90, 234, 3, 38, 172, 76, 203, 220, 62, 127,\n        225, 249, 184, 214, 101, 227, 76, 95, 88, 235, 190, 14, 58>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  executor: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Executor zdsJtoPjG67QStGoPdiqdjF8wYg5J8Op5i1Bx9V2HCc=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<161, 173, 246, 156, 52, 73, 176, 104, 173, 192, 224, 111, 212, 231, 14, 136, 230,\n        151, 241, 237, 239, 180, 127, 69, 59, 149, 86, 210, 133, 246, 106, 20>>,\n      sign: <<205, 219, 9, 182, 131, 227, 27, 174, 208, 74, 209, 168, 61, 216, 170, 118, 49, 124,\n        193, 136, 57, 39, 195, 169, 230, 45, 65, 199, 213, 118, 28, 39>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  ordering: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Ordering oCXn2nJdaIIF+wTv8PreeZ56RXH6TKNVH2Vk+EP4FzI=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<137, 234, 55, 245, 216, 126, 69, 133, 161, 185, 181, 4, 138, 160, 234, 238, 82,\n        157, 113, 175, 169, 23, 67, 177, 90, 99, 60, 94, 0, 237, 51, 53>>,\n      sign: <<160, 37, 231, 218, 114, 93, 104, 130, 5, 251, 4, 239, 240, 250, 222, 121, 158, 122,\n        69, 113, 250, 76, 163, 85, 31, 101, 100, 248, 67, 248, 23, 50>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  router: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n        128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n      sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n        24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  }\n}\n```\n\nFrom here we can run any tests in the file by copying those as well!\n\nWhat is even better is that we can copy parts of tests to setup an\narea to play with the code to figure out what is going well with our\nother tools.\n\nThis is a great way for learning any API in the codebase as you can\nget hands on what each function and message does.\n\n```elixir\n# test \"successful process\", %{node: node} do\nkey = 555\nstorage = Ordering.get_storage(node.ordering)\nincrement = increment_counter_val(key)\nzero = zero_counter(key)\n\n:ok =\n  Router.call(\n    node.router,\n    {:subscribe_topic, node.executor_topic, :local}\n  )\n\nMempool.hard_reset(node.mempool)\n\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n\nMempool.execute(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nFurther since the data is live, we can use tools like `:observer` to\nview the processes, and see general state dumping commands.\n\nFor databases I've found that `Anoma.Mnesia` is a good tool along with\n`:observer` for seeing what is currently in database table.","ref":"understanding-any-module.html#created-tables"},{"type":"extras","title":"Writing Documents","doc":"<!-- livebook:{\"file_entries\":[{\"name\":\"writing-docs-configure-system.png\",\"type\":\"attachment\"},{\"name\":\"writing-docs-kroki.png\",\"type\":\"attachment\"},{\"name\":\"writing-docs-smart-box.png\",\"type\":\"attachment\"}],\"persist_outputs\":true} -->\n\n# Writing Documents","ref":"writing-documents.html"},{"type":"extras","title":"Index - Writing Documents","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"writing-documents.html#index"},{"type":"extras","title":"The writing from within Anoma - Writing Documents","doc":"One of the more important parts of the Anoma project is understanding how the codebase works, and how it evolves.\n\nA good way to start on this process is by reading and writing documentation and making visual tools to better solidify knowledge for oneself and others.\n\nTo better do this, the codebase as a few levels of documentations:\n\n1. The specs (link TBA)\n2. These livebook documents\n3. Module level documentation\n\n`1.` is what specifies what `Anoma` is abstractly.\n\n`2.` serves the purpose of general knowledge transfer. Some documents serve to provide newcomers with information about various parts of Anoma's development process, others provide visual presentations to various parts of the codebase, while even others provide indepth analys of the codebase.\n\n`3.` is documents regarding module and function specifics. This is often augmented by `2.` for better context and examples.","ref":"writing-documents.html#the-writing-from-within-anoma"},{"type":"extras","title":"Making a new document - Writing Documents","doc":"To create a new document, it is simple as creating a new `.livemd` file in the folder location you wish it to be organized under.\n\nThus a file at `documentation/contributing/testing/foo.livemd` would be organized under the section `contribution/testing/`.\n\nThe file can either be made in livebook itself, or via the host operating system.","ref":"writing-documents.html#making-a-new-document"},{"type":"extras","title":"Connect to Anoma - Writing Documents","doc":"One should connect the document to a locally running IEX instance of Anoma.\n\nThis let's you take advantage of the pre-installed `kino` tools, and lets you generate documentation/diagrams over real Anoma Code.\n\nThis can be achieved by click on runtime settings:\n\n \n \n \n\nFrom here, click on configure and connect it to your running Anoma instance.","ref":"writing-documents.html#connect-to-anoma"},{"type":"extras","title":"Making diagrams - Writing Documents","doc":"Diagrams are an import piece of documentation.\n\nAll the standard livebook tools can be used, but Anoma has some extra dependencies that can help creating documentation.\n\nNamely under, the `+Smart` section, we can generate out various kinds of documents:\n\n![](files/writing-docs-smart-box.png)\n\nThe diagram will give you [Kroki diagrams](https://kroki.io/), and the UI will look something like this:\n\n![](files/writing-docs-kroki.png)\n\nHowever currently, due to a bug, writing text in the `Diagram source` will not change the generated diagram.\n\nIt is important to click the pencil icon, and edit it by hand.","ref":"writing-documents.html#making-diagrams"},{"type":"extras","title":"Generating the index - Writing Documents","doc":"To have an Index for a document, one must have a section named `Index`.\n\nOnce one has the `Index`, one can generate it by running `mix toc` or `make docs`.\n\nBecause livebook does not pull the files for changes, you may have to close the book and open it back up to have the relevant sections be up to date.\n\n<!-- livebook:{\"branch_parent_index\":5} -->","ref":"writing-documents.html#generating-the-index"},{"type":"extras","title":"Controlling the index sections - Writing Documents","doc":"To control the order of the index, the project has a file that controls the ordering.\n\n```elixir\n\"doc_order.exs\" |> File.read!() |> IO.puts()\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n[\n  {\"documentation\",\n   [\n     {\"toc\", []},\n     {\"contributing\",\n      [\n        {\"understanding-any-module\", []},\n        {\"writing-documents\", []}\n      ]},\n     {\"visualization\", []},\n     {\"hoon\", []}\n   ]}\n]\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\nThis is a priority list of documents, so the higher up a document is, the higher it will be presented in the `index`.\n\nRunning `mix toc` takes this into account. Note that to make sure your changes are reflected, run **mix clean** to make sure the wanted order is generated.","ref":"writing-documents.html#controlling-the-index-sections"},{"type":"extras","title":"Visualizing Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Visualizing Anoma","ref":"visualization.html"},{"type":"extras","title":"Index - Visualizing Anoma","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"visualization.html#index"},{"type":"extras","title":"Note on this section - Visualizing Anoma","doc":"This section provides extra visual diagrams on various components of\nAnoma, and serves to give an intuitive understanding on how Anoma\nworks.","ref":"visualization.html#note-on-this-section"},{"type":"extras","title":"The Actors","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# The Actors","ref":"actors.html"},{"type":"extras","title":"Index - The Actors","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"actors.html#index"},{"type":"extras","title":"An overview of Anoma - The Actors","doc":"A good overview of Actors can be seen by looking at the supervision tree of Anoma itself.\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```","ref":"actors.html#an-overview-of-anoma"},{"type":"extras","title":"Mempool - The Actors","doc":"A good view of visualizing Anoma can be seen through running the\nmempool, as it orchastrates the other actors in Anoma to act\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFirst we will create a transaction and see how that changes the base supervision tree before executing\n\n```elixir\nalias Anoma.Node.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\nimport TestHelper.Nock\n\nname = :anoma\nnode = Anoma.Node.state(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.438.0>\n```\n\nThe previous evaluations PID can be seen in the diagram below!\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```\n\nNow let us see what happens between the actors when we run the mempool\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn ->\n    Mempool.execute(node.mempool)\n  end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 3 AS code_server;\nparticipant 7 AS mnesia_locker;\nparticipant 6 AS mnesia_tm;\nparticipant 8 AS Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=;\nparticipant 2 AS Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=;\nparticipant 4 AS Anoma.Node.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=;\nparticipant 1 AS Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=;\nparticipant 0 AS self();\nparticipant 5 AS #35;PID<0.438.0>;\n0->>1: CALL: execute\n1->>2: ADD LEVEL: info\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>4: CALL: next_order\n4->>1: INFO: tuple\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>2: ADD LEVEL: info\n1->>4: CALL: new_order\n4->>1: INFO: tuple\n1->>2: ADD LEVEL: info\n1->>5: INFO: write_ready\n1->>2: ADD LEVEL: info\n1->>6: INFO: tuple\n6->>1: INFO: mnesia_tm\n1->>7: INFO: tuple\n7->>1: INFO: mnesia_locker\n1->>7: INFO: release_tid\n1->>6: INFO: delete_transaction\n1->>2: ADD LEVEL: info\n1->>2: ADD LEVEL: info\n1->>8: CAST: cast\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nAs we can see, we get a fairly solid overview of what actors sent what messages\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe can also see what processes startup when we start an execution\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn -> Mempool.tx(node.mempool, {:kv, increment_counter_val(555)}).pid() end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.1147.0>\n```\n\n```elixir\nKino.Process.render_seq_trace(\n  :all,\n  fn -> Anoma.Node.Logger.add(node.logger, :info, \"help\") end,\n  message_label: &Anoma.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"actors.html#mempool"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-2.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Toc](./toc.livemd)\n2. [User](./user.livemd)\n   1. [Data](./user/data.livemd)\n3. [Contributing](./contributing.livemd)\n   1. [Understanding Any Module](./contributing/understanding-any-module.livemd)\n   2. [Style Guide](./contributing/style-guide.livemd)\n   3. [Writing Documents](./contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./contributing/examples-over-testing.livemd)\n   5. [Git](./contributing/git.livemd)\n   6. [Hoon](./contributing/hoon.livemd)\n   7. [Iex](./contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./contributing/observer.livemd)\n   10. [Testing](./contributing/testing.livemd)\n       1. [Running Tests](./contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n4. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n5. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n6. [Analysis](./analysis.livemd)\n   1. [Fema Analysis Pinger](./analysis/fema-analysis-pinger.livemd)\n7. [Logging](./logging.livemd)\n8. [Vm_interface](./vm_interface.livemd)","ref":"hoon-2.html#index"},{"type":"extras","title":"About This Guide - Hoon","doc":"This guide hopefully serves you to be able to reason about the nock\ncode in Anoma. It is written for a non Hoon audience, so if you are\nfamiliar with Hoon, you may find use in the Nock code as there is a\nbig emphesis on nock itself, rather than just Hoon. If you are not\nfamiliar with Hoon, this merely shows you how to use the\n[Urbit](https://urbit.org/) environment to aid Nock code.\n\nA good general guide to Hoon can be found [At the Hoon School](https://developers.urbit.org/guides/core/hoon-school).\nHopefully the documention here serves as a good companion piece for\nanyone interested in Nock, Hoon, or Anoma.","ref":"hoon-2.html#about-this-guide"},{"type":"extras","title":"Calling","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Calling","ref":"calling.html"},{"type":"extras","title":"Index - Calling","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"calling.html#index"},{"type":"extras","title":"Calling Conventions - Calling","doc":"For this section, it is assumed that one is comfortable with the techniques outlined in the [dumping guide](./dumping.livemd), in particular familiarity with:\n\n1. [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar)\n2. [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis)\n\nis had, if one is uncomfortable with what is shown here, it would be a good idea to skim back over the [dumping guide](./dumping.livemd) for more information.\n\nWith that disclaimer out of the way, let us talk about calling conventions.","ref":"calling.html#calling-conventions"},{"type":"extras","title":"Basic Nock Calls - Calling","doc":"There are a few ways to call Nock functions, recall that the structure of a functions look like this:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThus if we wish to call our code example, the most basic way is by invoking nock `9`. Continuing our example from above, let us see the most basic call of it.\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 0 1]\n777\n```\n\nTo better understand what the `9` is doing let us ask us the nock structure of it\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]]\n```\n\nHere we can see the `9` takes 2 arguments, a `p=2` and a `q=[0 1]` argument.\n\nThe `q=[0 1]` argument goes off first. The point of this is to determine what module/layer (called an [core](https://developers.urbit.org/reference/glossary/core) in hoon) the particular function (called a [gate](https://developers.urbit.org/reference/glossary/gate) in hoon) belongs to.\n\nFrom here the `p=2` is the location of the function/[gate](https://developers.urbit.org/reference/glossary/gate).\n\nIn our example we know the function is indexed at 2, so thus we simply call the logic with the environment it's defined inside, meaning we simply get out the `6`th index which we have observed above is 777\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n`[9 2 0 1]` isn't too interesting on it's own, all we have managed to do, is make fancy default values.\n\nHowever, since the logic we are running indexs into the sample, all we have to do is fine a formula that replaces the sample with the desired value\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 10 [6 1 888] 0 1]\n888\n> ;;  nock  [9 2 10 [6 1 888] 0 1]\n[%9 p=2 q=[%10 p=[p=6 q=[%1 p=888]] q=[%0 p=1]]]\n```\n\nAbove we do exactly that, all it took was adding a simple `10 [6 1 888]`, however let us analyze what this does.\n\n`%10` is better known as replace at axis, the axis is the first value of `[6 1 888]` which in this case is position `6`. We then run the formula `[1 888]` which is simply saying return the constant `888`, then `10` finishes and replaced position `6` with the result, giving the logic located at `2` (I.E. `[0 6]`) the new sample to run against.\n\nSince the `%9`'s `q=...` has the replaced value, this ends up being the context for the `p=2` to run inside, and thus we have a computation that is effectively:\n\n```hoon\n> .*  [[0 6] 888 999] [9 2 0 1]\n888\n```\n\nWe will in the next section see how Hoon functions are defined, as they give further detail in how we use instruction `9`.","ref":"calling.html#basic-nock-calls"},{"type":"extras","title":"Hoon Gates: What are they really? - Calling","doc":"Something interesting is comparing the `9` described here to [dumping the indicies found in the dumping guide](./dumping.livemd#dumping-indexing-offsets).\n\nNamely we saw:\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nWhat is incongruous, is that we described `9` as calling a function, but in the dumping section, we make it seem like it's effectively only doing indexing to bring the name ready to be called.\n\nThis all has to do with how hoon stores nock functions, they do something quite clever.\n\nInstead of just storing the function as code itself, it stores it similarly to this\n\n```hoon\n[[1 [[0 6] 777 999]] 666 909]\n```\n\nWhere we store a nock function that evaluates to the code, the `1` instruction is simply that, when we evaluate this form we get\n\n```hoon\n> .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]\n[[0 6] 777 999]\n```\n\nfor which we can now call it\n\n```hoon\n> .*  .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]  [9 2 0 1]\n777\n```\n\nIn this case, it doesn't do much, but it makes sense if we look at a real example.\n\n```hoon\n> .*  add:anoma  [0 2]\n[ 6\n  [5 [1 0] 0 12]\n  [0 13]\n  9\n  2\n  10\n  [6 [8 [9 342 0 7] 9 2 10 [6 0 28] 0 2] 4 0 13]\n  0\n  1\n]\n```\n\nOn this example I want to focus on the `dec` call `[8 [9 342 0 7] 9 2 10 ...]`. We know this is dec, as we already know it's offset inside layer 1 is `342`, but it's located at `7` as we've pushed `add` with its sample to the tree, making layer 1's index go to 7 (see the [section on how indicies change](./dumping.livemd#how-index-of-layers-change)) relative to `add`.\n\nWhat is very interesting, is that since the [gate](https://developers.urbit.org/reference/glossary/gate) evaluates to the nock function we wish, we can follow it up with the simple `[9 2 10 [6 ...] 0 ...]` pattern we found before.\n\nMeaning that we have decoupled indexing with calling. If Hoon did not do this, then we are in an awkward position that the `[9 342 0 7]` somehow has to get `0 7` index before running the application change `0 28`, complicating the formula. Making it a simple constant function allows the formulas to stay manageable.\n\nSome other minor notes. The call: `[9 2 10 [6 0 28] 0 2]` ends with `0 2` instead of `0 1` because we have bushed with `8`, more on this later.\n\nWe will continue to expand this in the next section, but first let us learn how to evaluate code in the context of Anoma as the standard environment.","ref":"calling.html#hoon-gates-what-are-they-really"},{"type":"extras","title":"Evaluating Calls in The Anoma Context - Calling","doc":"For actually writing code for Anoma, the dump of dec that we saw:\n\n```\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nwould not actually run in the Anoma standard library. This is because it is assuming the current environment which has the Hoon standard library.\n\n```hoon\n> .*  anoma  [7 [0 46] 9 342 0 15]\ndojo: hoon expression failed\n```\n\nRather than by hand editing the `7 [0 46]` out, we can instead tell Hoon that the context of the computation is in Anoma, and this is done through [tisgar(=>)](https://developers.urbit.org/reference/hoon/rune/tis#-tisgar).\n\nA good example can be seen here:\n\n```hoon\n> =>  anoma  !=(dec)\n[9 342 0 15]\n```\n\nWhich gives us the correct computation to run dec on Anoma.\n\n```hoon\n> =>  anoma  .*  .  [9 342 0 15]\n[ [ 6\n    [5 [1 0] 0 6]\n...\n:: dec core emitted\n\n> =>  anoma  .*  .*  .  [9 342 0 15]  [9 2 10 [6 1 777] 0 1]\n776\n```","ref":"calling.html#evaluating-calls-in-the-anoma-context"},{"type":"extras","title":"What a Hoon function call actually does - Calling","doc":"So far this document has only outlined calling Hoon functions by hand, but what does the cannonical application form generate?\n\n```hoon\n> =>  anoma  (dec 3)\n2\n```\n\nWell we can ask [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) what this expression means\n\n```hoon\n> =>  anoma  !=((dec 3))\n[8 [9 342 0 15] 9 2 10 [6 7 [0 3] 1 3] 0 2]\n> ;;  nock  =>  anoma  !=((dec 3))\n[ %8\n  p=[%9 p=342 q=[%0 p=15]]\n  q=[%9 p=2 q=[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[%0 p=2]]]\n]\n```\n\nLet us break down this expression\n\n1. `[%8 p=[9 342 ...] q=[9 2 ...]]`\n   * `8` simply does a push on subject, with the `p` getting consed onto the environment. We've seen this `p` before, it is simply the formula for `dec`.\n   * Thus after the `p` we have `[dec anoma]` filling the environment\n   * This is now the context for the `q=`\n2. `[%9 p=2 q=[%10 ...]]`\n   * We've seen this `[9 2 10 [6 ...] ...]` call before, like before the function within the current layer is located at 2. However what is different is the specifics of the `q`\n3. `[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[0 2]]`\n   * This 10 is a replace at axis 6 like we have seen before, but let us note the `q=[0 2]`.\n   * Most example's we've seen have been `[0 1]`, this example has a `[0 2]` as the first `%8` pushed the `dec` function onto the environment, meaning that the function we wish to replace `6` of is really at index 2!\n   * An important note is that this rule expands to a replace where the `q` and `p` are ran on the original environment.\n   * This means that `q=[%7 ...]` gets to run in the environment where the surrounding environment still exists\n4. `[%7 p=[%0 p=3] q=[%1 p=3]]`\n   * Here are where things get interesting, `%7` is simply composition, thus `p` is ran on the environment then `q` is.\n   * This is important because the `p=[%0 p=3]` simply restores the original environment\n     ```hoon\n     > .*  999  [8 [1 1] 0 1]\n     [1 999]\n     > .*  999  [8 [1 1] 0 3]\n     999\n     ```\n   * Meaning that computation `q` can be ran as if the `%8` never happened.\n   * The Hoon compiler is sometimes smart and will optimize out the `%7`\n5. `[%1 p=3]`\n   * We simply put 3 as the argument\n   * Dec now runs with 3 as we expect.\n\nThus as we can see, the calling convention of Hoon is not very complicated, and is mostly sensible about trying to preserve the environments things are called in.","ref":"calling.html#what-a-hoon-function-call-actually-does"},{"type":"extras","title":"Paramarterized Modules: Or How Gates are just Cores - Calling","doc":"A common occurence in our standard library is the use of paramartized modules. However something interesting to note is that on the [gate](https://developers.urbit.org/reference/glossary/gate) documentation, it mentions\n\n> A [gate](https://developers.urbit.org/reference/glossary/gate) is [core](https://developers.urbit.org/reference/glossary/core) with one arm named $ (buc). They are often called Hoon functions because they have many of the same properties of functions from other programming languages.\n\nMeaning that every time we have been calling `add` we've really been calling a module with a function named $ inside\n\n```hoon\n> =>  anoma  $:add\n0\n```\n\nThus the calling conventions we've discussed above are exactly the same for modules!\n\nLet us look at the `lsh` function for confirmation\n\n```hoon\n> =>  anoma  !=(block)  ::  layer 4\n[9 10 0 1]\n> =>  anoma  !=(lsh:block)\n[7 [9 10 0 1] 9 90 0 1]\n> =>  anoma  !=((lsh:block 3 4))\n[8 [7 [9 10 0 1] 9 90 0 1] 9 2 10 [6 [7 [0 3] 1 3] 7 [0 3] 1 4] 0 2]\n```\n\nWe can see here that block is located at index `10` inside of the anoma environment. Also note the `9` call, we are calling block to bring it to the front!\n\nnext we check `lsh` which is located `90` within it, nothing out of the ordinary. We use `%7` to compose the indexing into the structure, which is reasonable.\n\nWhen we call `lsh` on `3` and `4` the result is exactly like we expect, we generate out the `%8` call that we disected above.\n\nSo we can already call the `lsh` function as if no paramartized was had. This makes sense as we know that each [gate](https://developers.urbit.org/reference/glossary/gate) has a sample that it takes if no substitution is had.\n\nNow let us replace the default block value with `999` (note you don't want to run this, it'll be too slow)\n\n```hoon\n> =>  anoma  !=((~(lsh block 999) 3 4))\n[ 8\n  [8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]\n  9\n  2\n  10\n  [6 [7 [0 3] 1 3] 7 [0 3] 1 4]\n  0\n  2\n]\n```\n\nThe only difference that was had was in in  `[8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]`. The rest of the formula stayed the same.\n\nHowever looking at this change, this should not be very shocking, as we have analyzed with the function above, we are simply pushing `block` to the front of the env with the `[8 [9 10 0 1] ...]`, leaing the environment being `[block anoma]`, then we simply wish to call `90` where `lsh` is located with the `6` index of the `block` environment being set to `999`.\n\nNote the `6` index is a gate's argument which we can see with this call:\n\n```hoon\n> =>  anoma  !=(block-size:block)\n[7 [9 10 0 1] 0 6]\n```\n\nThen we simply compute the rest of `lsh` with the default value being 999. Using a non large number we can see how this changes the results.\n\n```hoon\n> =>  anoma  (~(lsh block 1) 3 4)\n256\n> =>  anoma  (~(lsh block 0) 3 4)\n32\n> =>  anoma  (lsh:block 3 4)\n32\n```","ref":"calling.html#paramarterized-modules-or-how-gates-are-just-cores"},{"type":"extras","title":"Dumping","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Dumping\n\n```elixir\nMix.install([\n  {:kino_vega_lite, \"~> 0.1.10\"}\n])\n```","ref":"dumping.html"},{"type":"extras","title":"Index - Dumping","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"dumping.html#index"},{"type":"extras","title":"Dumping Nock - Dumping","doc":"Given a functioning Hoon environment with Anoma loaded, we can now start [dumping](https://en.wikipedia.org/wiki/Core_dump) various data in the environment.\n\nThis guide hopefully serves as a good way to give you the tools needed to [dump](https://en.wikipedia.org/wiki/Core_dump) anything for yourself.","ref":"dumping.html#dumping-nock"},{"type":"extras","title":"Dumping Functions - Dumping","doc":"[Dumping](https://en.wikipedia.org/wiki/Core_dump) any [Hoon gate](https://developers.urbit.org/reference/glossary/gate) is relatively easy.\n\nHowever, first we need to learn how to get Hoon to let us use Nock properly. A good way is by reading the [dot(.)](https://developers.urbit.org/reference/hoon/rune/dot) section, as [runes](https://developers.urbit.org/reference/hoon/rune) starting with `.` deal with nock operations.\n\nIn particular we wish to focus on [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar), which deals with calling nock on some expression.\n\nWe won't go into detail about calling functions in this section, however there is another section that focuses solely on how to call functions and how it works in Nock.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nSpeaking of functions, we should know just a few things about the layout of functions, and their important indicies.\n\nFunctions in Hoon are laid out as the following:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\nWith some basics out of the way, let us get to [dumping](https://en.wikipedia.org/wiki/Core_dump) hoon functions!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe shall dump the most basic of functions, decrement!\n\nWe can do this simply by bringing decrement to the front of the environment, and getting it in the function form of `[function sample environment]` we saw before. We can do this by simply stating the name of the function we wish, and then get the function out of it by getting the second index!\n\nNote that Hoon uses `function:module` (`f:mn:...:m1`) form.\n\n```nock\n.*  dec:anoma  [0 2]\n[6 [5 [1 0] 0 6] [0 0] 8 [1 0] 8 [1 6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1] 9 2 0 1]\n```\n\nThe logic here doesn't particularly matter, but here we have the nock definiton of decrement, which is wonderful!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis can be done to any function, regardless of how nested the modules are\n\n```hoon\n> .*  lsh:block:anoma  [0 2]\n[ 8\n  [9 4 0 255]\n  9\n  2\n  10\n  [6 [0 29] 7 [0 3] 8 [9 4 0 31] 9 2 10 [6 7 [0 3] 8 [9 4 0 255] 9 2 10 [6 [7 [0 3] 9 182 0 7] 0 28] 0 2] 0 2]\n  0\n  2\n]\n```","ref":"dumping.html#dumping-functions"},{"type":"extras","title":"Casting to Nock, a useful tool - Dumping","doc":"A good way to visualize the dump, is by casting the result to nock\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]\n```\n\nthe `p`'s and `q`'s are arguments and the `%9` and `%0` are the nock instructions being ran.\n\nFrom here, the [instruction set can be consluted for the meaning of any particular instruction](https://developers.urbit.org/reference/nock/definition#instructions).\n\n```hoon\n> ;;  nock  .*  dec.anoma  [0 2]\n[ %6\n  p=[%5 p=[%1 p=0] q=[%0 p=6]]\n  q=[%0 p=0]\n  r=[%8 p=[%1 p=0] q=[%8 p=[%1 p=[6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1]] q=[%9 p=2 q=[%0 p=1]]]]\n]\n```","ref":"dumping.html#casting-to-nock-a-useful-tool"},{"type":"extras","title":"Dumping Types - Dumping","doc":"Types in Hoon are just functions!\n\nA good example can be found by looking at the resource-type\n\n```hoon\n> .*  resource:resource-machine  [0 2]\n[ 8\n  [ [8 [7 [0 7] 9 47 0 1] 9 2 10 [6 0 28] 0 2]\n    [6 [6 [3 0 26] [1 1] 1 0] [0 26] 0 0]\n    [6 [6 [3 0 54] [1 1] 1 0] [0 54] 0 0]\n    [6 [6 [3 0 110] [1 1] 1 0] [0 110] 0 0]\n    [6 [5 [1 0] 0 222] [1 0] 6 [5 [1 1] 0 222] [1 1] 0 0]\n    [6 [6 [3 0 446] [1 1] 1 0] [0 446] 0 0]\n    [6 [6 [3 0 894] [1 1] 1 0] [0 894] 0 0]\n    6\n    [6 [3 0 895] [1 1] 1 0]\n    [0 895]\n    0\n    0\n  ]\n  8\n  [5 [0 14] 0 2]\n  0\n  6\n]\n```\n\nThis however does not show how to dump the structure of a type well enough, however this can be fixed by simply just calling it!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\ncalling a type leads to something like this\n\n```hoon\n> (resource:resource-machine)\n[   logic\n  < 1|xpg\n    [ [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n        proofs=it(#4)\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n          proofs\n        it( ^#4\n          [   logic\n            < 1|xpg\n              [ [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                ?(%.y %.n)\n              ]\n            >\n            label=@t\n            quantity=@\n            data=@\n            eph=?(%.y %.n)\n            nonce=@\n            npk=@\n            rseed=@\n          ]\n        )\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      ?(%.y %.n)\n    ]\n  >\n  label=''\n  quantity=0\n  data=0\n  eph=%.y\n  nonce=0\n  npk=0\n  rseed=0\n]\n```\n\nWhich just gives the default values. If the result is hard to read, then no problem, just forget the type information!\n\n```\n> `*`(resource:resource-machine)\n[[[0 15] [0 0 0 0 0 0 0] [0 0 0 0 0 0 0] 0] 0 0 0 0 0 0 0]\n```\n\nHere we simply jsut cast it to the any type, forgetting all information, and we can now see the format of the empty resource.","ref":"dumping.html#dumping-types"},{"type":"extras","title":"Dump Modules - Dumping","doc":"Dumping modules is the same as dumping functions, it's just a matter that one's terminal will be flooded\n\n```hoon\n> .*  resource-machine  [0 2]\n[ [1 0]\n...\n  0\n  1\n]\n```\n\nThus feel free to dump away. This is only useful when trying to copy this to the Elixir codebase.","ref":"dumping.html#dump-modules"},{"type":"extras","title":"Dumping Hoon for Elixir - Dumping","doc":"Since Anoma itself runs Nock and not Hoon, we have to take the Hoon code we have and include it in Elixir somehow.\n\nThis process isn't particular difficult, and we can do it by simply using the tools we've learned in this document.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor example, it's not uncommon when the standard library that test indicies are not out of date and need to be updated, or maybe we define out a new hoon function for testing.\n\nIn these scenarios, there is a very easy way to update the code.\n\nLet us look at the fibonacci example in Elixir\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n# can be found in https://github.com/anoma/anoma/blob/base/lib/test_helper/nock.ex\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 255] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 255] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm, sample | logics_core()]\n  end\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nHere we have some just plain old nock string representing the function, and we append the context to it via normal Elixir. We do this to save space, as we really don't want to dump the entire `Nock.logics_core/0` for every simple function.\n\nOn the Hoon side we just run this to get the proper new logic\n\n```hoon\n> .*  fib:tests  [0 2]\n[ 8\n  [1 1 0]\n  8\n  [ 1\n    6\n    [5 [0 30] 1 0]\n    [0 13]\n    9\n    2\n    10\n    [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n    10\n    [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n    0\n    1\n  ]\n  9\n  2\n  0\n  1\n]\n```\n\nand then replace the old logic with the new code.\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm,, sample | logics_core()]\n  end\n```\n\nThe process is the same for the code in `Nock`, just dump the `[0 2]` index of the module and replace the string with the result you get in your terminal.","ref":"dumping.html#dumping-hoon-for-elixir"},{"type":"extras","title":"Dumping Indexing Offsets - Dumping","doc":"The tools that we have explored so far only deal with dumping definitions, however they do not explain where these functions are stored in the environment.\n\nThat is where [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) comes handy.\n\n[zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) simply gives us the hoon expression of the argument handed to it.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nLet us start off simple with [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis), let us look at what saying `anoma` actually does.\n\n```hoon\n> !=(anoma)\n[0 46]\n```\n\nInteresting, we can see that saying anoma, indexs into the current environment by `46`. The current environment in Hoon can be conjured with `.`.\n\n```hoon\n> !=(.)\n[0 1]\n```\n\nWith this knowledge in hand, we can verify that anoma really is at index 46!\n\n```hoon\n> =(.*(. [0 46]) anoma)\n%.y\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow that we know how to get the index for names like anoma, what about trying to get the index of a function like `dec` inside of the anoma environment.\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n> ;;  nock  !=(dec:anoma)\n[%7 p=[%0 p=46] q=[%9 p=342 q=[%0 p=15]]]\n```\n\nHere it's a bit more complicated to let us break it down step by step.\n\n1. `[%7 p=[%0 p=46] q=...]`\n   * In the section where we are calling `%7`.\n   * This has the effect of just trying to get anoma to be the subject of the following `q` computation.\n2. Now at `q=[%9 p=342 q=[%0 p=15]]` we are running this on anoma itself.\n   * `%9` is rather basic, trying to call the given index `p` at arm `q`.\n   * In our case, `dec` is located at index `342` inside of arm at the layer/module located at `[0 15]`.\n   * `[0 15]` is really layer 1 in the source code and is properly documented as such\n\n```hoon\n~%  %one  +  ~\n|%\n++  dec  ::  +342\n  ~/  %dec\n  |=  a=@\n  ?<  =(0 a)\n  =|  b=@\n  |-  ^-  @\n  ?:  =(a +(b))  b\n  $(b +(b))\n\n```\n\nThus, it's not very complicated, thus in the form\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nall we have to pay attention to is the `342` and the `15`, some more examples show this off well\n\n```hoon\n> !=(dec:anoma) ::  index 342 at layer 1\n[7 [0 46] 9 342 0 15]\n> !=(add:anoma) ::  index 20 at layer 1\n[7 [0 46] 9 20 0 15]\n> !=(trap:anoma) ::  index 20 at layer 2\n[7 [0 46] 9 20 0 7]\n> !=(unit:anoma) ::  index 42 at layer 2\n[7 [0 46] 9 42 0 7]\n```\n\nHere for any non nested module we can see the layers and indexs quite plainly!\n\n<!-- livebook:{\"branch_parent_index\":7} -->","ref":"dumping.html#dumping-indexing-offsets"},{"type":"extras","title":"How Index of Layers Change - Dumping","doc":"The hoon environment is a binary tree. Included below is an extended diagram that we will use for our explanation.\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n3 --> 6\n3 --> 7\n7 --> 14\n7 --> 15\n15 --> 30\n15 --> 31\n```\n\nWhenever, a layer is made in hoon, we should think of it as pushed onto the env. So for Anoma the layers can be seen like this\n\n```mermaid\nstateDiagram-v2\nlayer_four --> code_in_layer_four\nlayer_four --> layer_three\nlayer_three --> code_in_layer_three\nlayer_three --> layer_two\nlayer_two --> code_in_layer_two\nlayer_two --> layer_one\nlayer_one --> code_in_layer_one\nlayer_one --> 0_3_99\n```\n\nIf we pushed layer 5, then everything shifts, layer 1 moves from 15 to 31.\n\nThus the indexing works on a rather simple formula that can be read about: [here](https://oeis.org/A000918). The code is not exactly this formula, but below we will show how it shapes up.\n\n```elixir\nseries = 1..5 |> Enum.map(fn i -> 2 ** i - 1 end)\nindicies = 1..5\nmy_data = %{series: series, indicies: indicies}\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%{series: [1, 3, 7, 15, 31], indicies: 1..5}\n```\n\n<!-- livebook:{\"attrs\":\"eyJjaGFydF90aXRsZSI6IkluZGV4aW5nIFNlcmllcyIsImhlaWdodCI6MzAwLCJsYXllcnMiOlt7ImFjdGl2ZSI6dHJ1ZSwiY2hhcnRfdHlwZSI6ImJhciIsImNvbG9yX2ZpZWxkIjpudWxsLCJjb2xvcl9maWVsZF9hZ2dyZWdhdGUiOm51bGwsImNvbG9yX2ZpZWxkX2JpbiI6bnVsbCwiY29sb3JfZmllbGRfc2NhbGVfc2NoZW1lIjpudWxsLCJjb2xvcl9maWVsZF90eXBlIjpudWxsLCJkYXRhX3ZhcmlhYmxlIjoibXlfZGF0YSIsImdlb2RhdGFfY29sb3IiOiJncmVlbiIsImxhdGl0dWRlX2ZpZWxkIjoiYSIsImxvbmdpdHVkZV9maWVsZCI6ImIiLCJ4X2ZpZWxkIjoiaW5kaWNpZXMiLCJ4X2ZpZWxkX2FnZ3JlZ2F0ZSI6bnVsbCwieF9maWVsZF9iaW4iOm51bGwsInhfZmllbGRfc2NhbGVfdHlwZSI6bnVsbCwieF9maWVsZF90eXBlIjoicXVhbnRpdGF0aXZlIiwieV9maWVsZCI6InNlcmllcyIsInlfZmllbGRfYWdncmVnYXRlIjpudWxsLCJ5X2ZpZWxkX2JpbiI6bnVsbCwieV9maWVsZF9zY2FsZV90eXBlIjpudWxsLCJ5X2ZpZWxkX3R5cGUiOiJxdWFudGl0YXRpdmUifV0sInZsX2FsaWFzIjoiRWxpeGlyLlZlZ2FMaXRlIiwid2lkdGgiOjIwMH0\",\"chunks\":null,\"kind\":\"Elixir.KinoVegaLite.ChartCell\",\"livebook_object\":\"smart_cell\"} -->\n\n```elixir\nVegaLite.new(width: 200, height: 300, title: \"Indexing Series\")\n|> VegaLite.data_from_values(my_data, only: [\"indicies\", \"series\"])\n|> VegaLite.mark(:bar)\n|> VegaLite.encode_field(:x, \"indicies\", type: :quantitative)\n|> VegaLite.encode_field(:y, \"series\", type: :quantitative)\n```","ref":"dumping.html#how-index-of-layers-change"},{"type":"extras","title":"Setting up Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Setting up Hoon","ref":"setting-up.html"},{"type":"extras","title":"Index - Setting up Hoon","doc":"1. [Toc](./../toc.livemd)\n2. [User](./../user.livemd)\n   1. [Data](./../user/data.livemd)\n3. [Contributing](./../contributing.livemd)\n   1. [Understanding Any Module](./../contributing/understanding-any-module.livemd)\n   2. [Style Guide](./../contributing/style-guide.livemd)\n   3. [Writing Documents](./../contributing/writing-documents.livemd)\n   4. [Examples Over Testing](./../contributing/examples-over-testing.livemd)\n   5. [Git](./../contributing/git.livemd)\n   6. [Hoon](./../contributing/hoon.livemd)\n   7. [Iex](./../contributing/iex.livemd)\n   8. [Mnesia Vs Actor State](./../contributing/mnesia-vs-actor-state.livemd)\n   9. [Observer](./../contributing/observer.livemd)\n   10. [Testing](./../contributing/testing.livemd)\n       1. [Running Tests](./../contributing/testing/running-tests.livemd)\n       2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n4. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n5. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n6. [Analysis](./../analysis.livemd)\n   1. [Fema Analysis Pinger](./../analysis/fema-analysis-pinger.livemd)\n7. [Logging](./../logging.livemd)\n8. [Vm_interface](./../vm_interface.livemd)","ref":"setting-up.html#index"},{"type":"extras","title":"Getting a Good Hoon environment - Setting up Hoon","doc":"A good starting point is to read [Hoon's docs on environment](https://developers.urbit.org/guides/core/environment)\n\nIt's good to follow it until the section \"Mount a desk\"\n\nFrom here we can setup the environment quite nicely\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```hoon\n|merge %anoma our %base\n|mount %anoma\n```\n\nFrom here we want to remove all the uneeded files, get it to the following state:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\n8 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n mar\n  hoon.hoon\n  mime.hoon\n  noun.hoon\n  txt-diff.hoon\n  txt.hoon\n sys.kelvin\n\n2 directories, 6 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nwith `sys.kelvin` having only `[%zuse 412]`\n\nNow that we have our minimal state, we can symlink in the files in\nhttps://github.com/anoma/anoma/tree/base/hoon\n\ninto `lib`. It should now look something like this\n\n```bash\n9 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n lib\n  anoma.hoon -> .../hoon/anoma.hoon\n  logics.hoon -> .../hoon/logics.hoon\n  resource-machine.hoon -> .../hoon/resource-machine.hoon\n  tests.hoon -> .../hoon/tests.hoon\n mar\n  hoon.hoon\n  mime.hoon\n  noun.hoon\n  txt-diff.hoon\n  txt.hoon\n sys.kelvin\n\n3 directories, 10 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow we can mount our anoma code into hoon\n\n```hoon\n> |commit %anoma\n>=\n> =anoma -build-file /=anoma=/lib/anoma/hoon\n> =resource-machine -build-file /=anoma=/lib/resource-machine/hoon\n> =logics -build-file /=anoma=/lib/logics/hoon\n> =tests -build-file /=anoma=/lib/tests/hoon\n```\n\nFrom here, the hoon environment is ready to be used and it should work just as Anoma uses Nock.","ref":"setting-up.html#getting-a-good-hoon-environment"}],"content_type":"text/markdown","producer":{"name":"ex_doc","version":[48,46,51,52,46,50]}}